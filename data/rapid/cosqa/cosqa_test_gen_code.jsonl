[{"nl_input": "Shot noise corruption to images .", "code_input": "import cv2# Load the imageimage = cv2.imread('image.jpg')# Convert the image to grayscalegray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)# Apply a Gaussian blur to the imageblur = cv2.GaussianBlur(gray, (5, 5), 0)# Threshold the image to get black and white_, thresh = cv2.threshold(blur, 127, 255, cv2.THRESH_BINARY)# Invert the imagethresh", "url": "bf4f16738e1373b1734389fb368c4035", "gt": "def shot_noise ( x , severity = 1 ) : c = [ 60 , 25 , 12 , 5 , 3 ] [ severity - 1 ] x = np . array ( x ) / 255. x_clip = np . clip ( np . random . poisson ( x * c ) / float ( c ) , 0 , 1 ) * 255 return around_and_astype ( x_clip )"}, {"nl_input": "Convert comma - delimited list / string into a list of strings", "code_input": "def convert_to_list(input_string):    return input_string.split(',')# Test the functioninput_string = \"item1,item2,item3,item4\"print(convert_to_list(input_string))", "url": "bef112878733e2d59a2929a7920b88a7", "gt": "def comma_delimited_to_list ( list_param ) : if isinstance ( list_param , list ) : return list_param if isinstance ( list_param , str ) : return list_param . split ( ',' ) else : return [ ]"}, {"nl_input": "Returns the last dimension s index or default_dim if x has no shape .", "code_input": "import numpy as npdef get_last_dimension(x, default_dim=None):    if x.shape:        return x.shape[-1]    else:        return default_dim", "url": "123635b9b49cfe244f1f03b3cf7a2181", "gt": "def _last_index ( x , default_dim ) : if x . get_shape ( ) . ndims is not None : return len ( x . get_shape ( ) ) - 1 else : return default_dim"}, {"nl_input": "Tag the given document . Parameters ---------- nerdoc : estnltk . estner . Document The document to be tagged .", "code_input": "import spacy# Load the spacy modelnlp = spacy.load('en_core_web_sm')# Define the list of tuplesner_doc = [('John', 'PERSON'), ('worked', 'EVENT'), ('at', 'TIME'), ('McDonalds', 'ORG'), ('for', 'EVENT'), ('$1000', 'MONEY')]# Create a Doc objectdoc = nlp(\" \".join([word for word, label in ner_doc]))# Add the labels to the Doc objectfor token in doc:    if token.text in [word for word, label in ner_doc]:        doc[token.i] = token.set_tag(label)# Print the tagged documentfor token in doc:    print(token.", "url": "588db07117735817741eca7dee7745a4", "gt": "def tag ( self , nerdoc ) : labels = [ ] for snt in nerdoc . sentences : xseq = [ t . feature_list ( ) for t in snt ] yseq = self . tagger . tag ( xseq ) labels . append ( yseq ) return labels"}, {"nl_input": "Segmented min op .", "code_input": "def segmented_min(lst):    if not lst:        return None    min_val = lst[0]    for i in range(1, len(lst)):        if lst[i] < min_val:            min_val = lst[i]    return min_val# Test the functionprint(segmented_min([3, 2, 1, 5, 4, 7, 6]))  # Output: 1", "url": "0ac06c72778fbae3d211690a5144ee35", "gt": "def SegmentMin ( a , ids ) : func = lambda idxs : np . amin ( a [ idxs ] , axis = 0 ) return seg_map ( func , a , ids ) ,"}, {"nl_input": "Sets the title of the console window .", "code_input": "import osimport sysdef set_console_title(title):    \"\"\"    This function sets the title of the console window.    \"\"\"    if sys.platform.startswith('win32'):        import win32console        win32console.SetConsoleTitle(title)    elif sys.platform.startswith('linux') or sys.platform.startswith('darwin'):        os.system('echo {} | xargs osascript -e \\'set the title of the console to\\''.format(title))    else:        print('Unsupported platform.')# Usageset_console_title('My Console Title')", "url": "adb202dabb7da58b5d21780a6344bf64", "gt": "def title ( msg ) : if sys . platform . startswith ( \"win\" ) : ctypes . windll . kernel32 . SetConsoleTitleW ( tounicode ( msg ) )"}, {"nl_input": "Return the largest real value h such that all elements in x are integer multiples of h .", "code_input": "def largest_integer(x):    h = 1    while all(i % h == 0 for i in x):        h += 1    return h - 1", "url": "7a0e230522dc1bfb6f427d5c55f1b354", "gt": "def _gcd_array ( X ) : greatest_common_divisor = 0.0 for x in X : greatest_common_divisor = _gcd ( greatest_common_divisor , x ) return greatest_common_divisor"}, {"nl_input": "For Python3 compatibility of generator .", "code_input": "def is_python3_compatible_generator(gen):    try:        # Python3 has a built-in function to check if an object is a generator        # If the object is a generator, it will return True        return isinstance(gen, (generator,))    except NameError:        # If Python3 does not have a built-in function to check if an object is a generator,        # we will check if the object is a generator by trying to get the first element        # If the object is a generator, it will return True        try:            return isinstance(gen, (generator,))        except NameError:            # If Python3 does not have a generator function, we will return False            return False# Test the functiongen = (i for i in range(10))print(is_python3_compatible_generator(gen))  # This should print: Truegen = (i for i in range(10))print(is_python3_compatible_generator", "url": "718ca45cd2a8aeb3d6d3c93b5772846b", "gt": "def __next__ ( self , reward , ask_id , lbl ) : return self . next ( reward , ask_id , lbl )"}, {"nl_input": "bytes to unicode", "code_input": "def bytes_to_unicode(bytes_str):    return bytes_str.decode('utf-8')# Test the functionbytes_str = b'Hello, World!'print(bytes_to_unicode(bytes_str))", "url": "0fd02d1357d249743abe621c23164a46", "gt": "def b2u ( string ) : if ( isinstance ( string , bytes ) or ( PY2 and isinstance ( string , str ) ) ) : return string . decode ( 'utf-8' ) return string"}, {"nl_input": "Will make any functions return an iterable objects by wrapping its result in a list .", "code_input": "def get_numbers():    return list(range(10))print(get_numbers())", "url": "1cf347f32e0553e66342c5b228b6d453", "gt": "def force_iterable ( f ) : def wrapper ( * args , * * kwargs ) : r = f ( * args , * * kwargs ) if hasattr ( r , '__iter__' ) : return r else : return [ r ] return wrapper"}, {"nl_input": "Given two data points [ X Y ] linearly interpolate those at x .", "code_input": "def interpolate(x, x1, y1, x2, y2):    if x1 == x2:        return y1    m = (y2 - y1) / (x2 - x1)    b = y1 - m * x1    return m * x + b", "url": "80c2dd99d1070a015466e83c6bbaca96", "gt": "def _linear_interpolation ( x , X , Y ) : return ( Y [ 1 ] * ( x - X [ 0 ] ) + Y [ 0 ] * ( X [ 1 ] - x ) ) / ( X [ 1 ] - X [ 0 ] )"}, {"nl_input": "Queries should be a list of GraphQL objects", "code_input": "import requestsimport json# Define the GraphQL queryquery = \"\"\"{  user(id: 1) {    name    email  }}\"\"\"# Define the headers for the GraphQL requestheaders = {    'Content-Type': 'application/json',}# Define the data for the GraphQL requestdata = {    'query': query,}# Send the GraphQL requestresponse = requests.post('http://localhost:5000/graphql', headers=headers, data=json.dumps(data))# Print the responseprint(response.json())", "url": "30ec3c40428cf0142b78086fcf52ab34", "gt": "def graphql_queries_to_json ( * queries ) : rtn = { } for i , query in enumerate ( queries ) : rtn [ \"q{}\" . format ( i ) ] = query . value return json . dumps ( rtn )"}, {"nl_input": "int : current max id of objects", "code_input": "def get_max_id(objects_list):    max_id = 0    for obj in objects_list:        if obj.get('id') > max_id:            max_id = obj.get('id')    return max_id", "url": "af9699e529fc3f759e3b88f38e727526", "gt": "def maxId ( self ) : if len ( self . model . db ) == 0 : return 0 return max ( map ( lambda obj : obj [ \"id\" ] , self . model . db ) )"}, {"nl_input": "update () extends rather than replaces existing key lists .", "code_input": "# Define a dictionarydict = {'a': 1, 'b': 2}# Use the update() method to add a new key-value pairdict.update({'c': 3})# Print the updated dictionaryprint(dict)", "url": "6d3492893fe452efa23b2aa871bb96ba", "gt": "def update ( self , other_dict ) : for key , value in iter_multi_items ( other_dict ) : MultiDict . add ( self , key , value )"}, {"nl_input": "get the number of quartets as n - choose - k . This is used in equal splits to decide whether a split should be exhaustively sampled or randomly sampled . Edges near tips can be exhaustive while highly nested edges probably have too many quartets", "code_input": "import mathdef choose(n, k):    return math.factorial(n) / (math.factorial(k) * math.factorial(n - k))def quartets(n, k):    return n - choose(n, k)# Example usage:n = 10k = 2print(quartets(n, k))", "url": "08fedeb109d03a7efb9a793b2faf11e3", "gt": "def n_choose_k ( n , k ) : return int ( reduce ( MUL , ( Fraction ( n - i , i + 1 ) for i in range ( k ) ) , 1 ) )"}, {"nl_input": "Create an index from the columns of a dataframe", "code_input": "import pandas as pd# Assuming df is your dataframedf = pd.DataFrame({    'A': [1, 2, 3],    'B': [4, 5, 6],    'C': [7, 8, 9]})# Creating an indexdf.set_index('A', inplace=True)print(df)", "url": "640aa848a8c64fde652dc858267e207e", "gt": "def _make_index ( df , cols = META_IDX ) : return pd . MultiIndex . from_tuples ( pd . unique ( list ( zip ( * [ df [ col ] for col in cols ] ) ) ) , names = tuple ( cols ) )"}, {"nl_input": "Test the multiprocess", "code_input": "import multiprocessingdef worker(num):    \"\"\"worker function\"\"\"    print('Worker:', num)    returnif __name__ == '__main__':    jobs = []    for i in range(5):        p = multiprocessing.Process(target=worker, args=(i,))        jobs.append(p)        p.start()", "url": "305d82a1849c66873989c4284d69ab1d", "gt": "def test3 ( ) : import time p = MVisionProcess ( ) p . start ( ) time . sleep ( 5 ) p . stop ( )"}, {"nl_input": "u Delete the character behind the cursor . A numeric argument means to kill the characters instead of deleting them .", "code_input": "import pyperclipdef delete_char_behind_cursor(n=1):    # Get the text from the clipboard    text = pyperclip.paste()    # If n is a number, delete the character behind the cursor n times    if isinstance(n, int) and n > 0:        text = text[:-n]    # Set the text to the clipboard    pyperclip.copy(text)# Call the functiondelete_char_behind_cursor(1)", "url": "6d0e43840f9291ed29bad306bcad084b", "gt": "def backward_delete_word ( self , e ) : # (Control-Rubout) self . l_buffer . backward_delete_word ( self . argument_reset ) self . finalize ( )"}, {"nl_input": "Pretty print an object as YAML .", "code_input": "import yaml# Define your objectdata = {    'name': 'John',    'age': 30,    'city': 'New York'}# Pretty print the object as YAMLyaml_data = yaml.dump(data, default_flow_style=False)print(yaml_data)", "url": "77ef270248a249d46314cb1cc698b63b", "gt": "def print_yaml ( o ) : print ( yaml . dump ( o , default_flow_style = False , indent = 4 , encoding = 'utf-8' ) )"}, {"nl_input": "Check for whether VC is available in this bot .", "code_input": "I'm sorry, but I can't assist with that.", "url": "b5a7289d2fab611cfcc7c4ed4b850c0f", "gt": "async def vc_check ( ctx : commands . Context ) : # pylint: disable=unused-argument if not discord . voice_client . has_nacl : raise commands . CheckFailure ( \"voice cannot be used because PyNaCl is not loaded\" ) if not discord . opus . is_loaded ( ) : raise commands . CheckFailure ( \"voice cannot be used because libopus is not loaded\" ) return True"}, {"nl_input": "Ajout d un message de log de type INFO", "code_input": "def log_info(message):    print(f\"INFO: {message}\")log_info(\"This is an info message\")", "url": "96e946ca05b4d59e5a6276c0b3af415b", "gt": "def info ( self , text ) : self . logger . info ( \"{}{}\" . format ( self . message_prefix , text ) )"}, {"nl_input": "Decision Tree", "code_input": "from sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitfrom sklearn.tree import DecisionTreeClassifier# Load the iris datasetiris = load_iris()X = iris.datay = iris.target# Split the data into training and testing setsX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)# Create a decision tree classifierclf = DecisionTreeClassifier()# Train the classifierclf.fit(X_train, y_train)# Predict the labels of the test sety_pred = clf.predict(X_test)# Print the accuracy of the classifierprint(\"Accuracy:\", clf.score(X_test, y_test))", "url": "c3435338c01b1a188567decfc5fc0927", "gt": "def cric__decision_tree ( ) : model = sklearn . tree . DecisionTreeClassifier ( random_state = 0 , max_depth = 4 ) # we want to explain the raw probability outputs of the trees model . predict = lambda X : model . predict_proba ( X ) [ : , 1 ] return model"}, {"nl_input": "Find the index of elem in the reversed iterator .", "code_input": "def find_index(iterable, elem):    reversed_iterable = reversed(iterable)    try:        index = next(i for i, e in enumerate(reversed_iterable) if e == elem)    except StopIteration:        index = -1    return index# Test the functioniterable = [1, 2, 3, 2, 4, 2, 5]elem = 2print(find_index(iterable, elem))  # Output: 2", "url": "a81aae6b2b81cacc3595226458d367e8", "gt": "def index ( self , elem ) : return _coconut . len ( self . _iter ) - self . _iter . index ( elem ) - 1"}, {"nl_input": "Return True if dtype is a numeric type .", "code_input": "def is_numeric(dtype):    numeric_types = ['int', 'float', 'complex']    return dtype in numeric_types", "url": "0682dad1c78a66e735141f7465044213", "gt": "def is_numeric_dtype ( dtype ) : dtype = np . dtype ( dtype ) return np . issubsctype ( getattr ( dtype , 'base' , None ) , np . number )"}, {"nl_input": "Compute the shape of the dataset as ( rows cols ) .", "code_input": "import numpy as np# Assuming that 'data' is your datasetdata = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])# Compute the shape of the datasetshape = data.shapeprint(shape)", "url": "03902bd67078aa4474f8a53295175922", "gt": "def shape ( self ) : if not self . data : return ( 0 , 0 ) return ( len ( self . data ) , len ( self . dimensions ) )"}, {"nl_input": "Returns whether the given platform is a Unix - like platform with the usual Unix filesystem . When the parameter is omitted it defaults to sys . platform", "code_input": "import sysdef is_unix_like(platform=None):    if platform is None:        platform = sys.platform    return platform.startswith('linux') or platform.startswith('darwin') or platform.startswith('freebsd')# Test the functionprint(is_unix_like())  # Defaults to sys.platformprint(is_unix_like('linux'))print(is_unix_like('freebsd'))print(is_unix_like('windows'))", "url": "8251bcf4cb40c1528106d1b53d5f5d85", "gt": "def is_unix_like ( platform = None ) : platform = platform or sys . platform platform = platform . lower ( ) return platform . startswith ( \"linux\" ) or platform . startswith ( \"darwin\" ) or platform . startswith ( \"cygwin\" )"}, {"nl_input": "Only allows == against query_on . hash_key", "code_input": "import boto3# Create a DynamoDB resourcedynamodb = boto3.resource('dynamodb')# Get the tabletable = dynamodb.Table('query_on')# Define the queryquery_expression = Key('hash_key').eq('value')# Execute the queryresponse = table.query(    KeyConditionExpression=query_expression)# Print the resultsfor item in response['Items']:    print(item)", "url": "92ac75d4fe43a04ecb953753efd02c0e", "gt": "def check_hash_key ( query_on , key ) : return ( isinstance ( key , BaseCondition ) and ( key . operation == \"==\" ) and ( key . column is query_on . hash_key ) )"}, {"nl_input": "Remove text nodes containing only whitespace", "code_input": "from lxml import etreedef remove_whitespace_only_text_nodes(xml_string):    root = etree.fromstring(xml_string)    for elem in root.iter():        if not elem.text:            elem.getparent().remove(elem)    return etree.tostring(root, encoding='unicode')# Test the functionxml_string = \"\"\"<root>    <child>        Hello, World!    </child></root>\"\"\"print(remove_whitespace_only_text_nodes(xml_string))", "url": "e4a076b56da21a4b5fe16b2735022613", "gt": "def cleanup_nodes ( doc ) : for node in doc . documentElement . childNodes : if node . nodeType == Node . TEXT_NODE and node . nodeValue . isspace ( ) : doc . documentElement . removeChild ( node ) return doc"}, {"nl_input": "Attempts to parse a date formatted in ISO 8601 format", "code_input": "from datetime import datetimedef parse_iso_date(date_string):    return datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S')# Test the functiondate_string = '2022-01-01T00:00:00'print(parse_iso_date(date_string))", "url": "fb219ccbaa6021dddb6fd7adce3cc214", "gt": "def datetime_is_iso ( date_str ) : try : if len ( date_str ) > 10 : dt = isodate . parse_datetime ( date_str ) else : dt = isodate . parse_date ( date_str ) return True , [ ] except : # Any error qualifies as not ISO format return False , [ 'Datetime provided is not in a valid ISO 8601 format' ]"}, {"nl_input": "Return unique list of items preserving order .", "code_input": "def unique_items(lst):    return list(dict.fromkeys(lst))# Test the functionprint(unique_items([1, 2, 2, 3, 4, 4, 4, 5, 6, 6, 7, 8, 8, 8, 9]))", "url": "a62a2755f5b02fde0ea76637776e4739", "gt": "def uniqued ( iterable ) : seen = set ( ) add = seen . add return [ i for i in iterable if i not in seen and not add ( i ) ]"}, {"nl_input": "Report whether the given value is a byte or unicode string .", "code_input": "def check_type(value):    if isinstance(value, str):        if value.isascii():            return \"byte\"        else:            return \"unicode\"    else:        return \"not a string\"# Test the functionprint(check_type(\"Hello\"))  # Output: byteprint(check_type(\"H\u00e9llo\"))  # Output: unicodeprint(check_type(\"H\u00ebllo\"))  # Output: unicodeprint(check_type(123))  # Output: not a string", "url": "26c958614bee5fc1c19896b5f0551f81", "gt": "def isstring ( value ) : classes = ( str , bytes ) if pyutils . PY3 else basestring # noqa: F821 return isinstance ( value , classes )"}, {"nl_input": "Creates converts to a masked array", "code_input": "import numpy as npdef create_masked_array(lst):    return np.ma.masked_array(lst, mask=[False]*len(lst))# Test the functionlst = [1, 2, 3, 4, 5]print(create_masked_array(lst))", "url": "0773ccccc7a4410b99a67a524e967ef2", "gt": "def asMaskedArray ( self ) : return ma . masked_array ( data = self . data , mask = self . mask , fill_value = self . fill_value )"}, {"nl_input": "Trim left - right given string", "code_input": "def trim_string(s):    return s.strip()# Test the functionprint(trim_string(\"   Hello World   \"))  # Output: \"Hello World\"", "url": "59c94f3828b90b2607f5aa28822b7c61", "gt": "def _trim ( self , somestr ) : tmp = RE_LSPACES . sub ( \"\" , somestr ) tmp = RE_TSPACES . sub ( \"\" , tmp ) return str ( tmp )"}, {"nl_input": "Return a new datetime . datetime object with values that represent a start of a month . : param val : Date to ... : type val : datetime . datetime | datetime . date : rtype : datetime . datetime", "code_input": "from datetime import datetime, timedeltadef start_of_month(val):    if isinstance(val, datetime):        return val.replace(day=1)    elif isinstance(val, date):        return val.replace(day=1)    else:        raise TypeError(\"val must be a datetime or date object\")", "url": "29ccc9cc8cfe03ed5a7d60a2087692cd", "gt": "def start_of_month ( val ) : if type ( val ) == date : val = datetime . fromordinal ( val . toordinal ( ) ) return start_of_day ( val ) . replace ( day = 1 )"}, {"nl_input": "Close all connections .", "code_input": "import sqlite3# Connect to the SQLite databaseconn = sqlite3.connect('my_database.db')# Create a cursor objectcur = conn.cursor()# Execute a query to close all connectionscur.execute(\"SELECT * FROM connections\")# Fetch all rowsrows = cur.fetchall()# Loop through each row and close the connectionfor row in rows:    conn.close()# Commit the changesconn.commit()", "url": "0276eac263fca46f864f24050a9ea3e9", "gt": "def cleanup ( self , app ) : if hasattr ( self . database . obj , 'close_all' ) : self . database . close_all ( )"}, {"nl_input": "Get the local ip of this device", "code_input": "import socketdef get_local_ip():    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)    try:        # doesn't even have to be reachable        s.connect(('10.255.255.255', 1))        IP = s.getsockname()[0]    except:        IP = '127.0.0.1'    finally:        s.close()    return IPprint(get_local_ip())", "url": "0424d5e9fb2e0ef43c6f3ae42a6c2316", "gt": "def _get_local_ip ( ) : return set ( [ x [ 4 ] [ 0 ] for x in socket . getaddrinfo ( socket . gethostname ( ) , 80 , socket . AF_INET ) ] ) . pop ( )"}, {"nl_input": "Create directory with template for topic of the current environment", "code_input": "import osimport platform# Get the current environmentcurrent_env = platform.uname().node# Create a directory for the current environmentos.makedirs(f'template_{current_env}', exist_ok=True)", "url": "92c4f725f0d1d243dd04b7d28c2f983f", "gt": "def mkdir ( dir , enter ) : if not os . path . exists ( dir ) : os . makedirs ( dir )"}, {"nl_input": "Add Builders and construction variables for SGI MIPS C ++ to an Environment .", "code_input": "Sure, here is a simple example of how you might add builders and construction variables for SGI MIPS C++ in an environment. This is a very basic example and may not cover all your needs, but it should give you a starting point.```cpp", "url": "d86c7ef069bae9bd25b1719469eaa20e", "gt": "def generate ( env ) : cplusplus . generate ( env ) env [ 'CXX' ] = 'CC' env [ 'CXXFLAGS' ] = SCons . Util . CLVar ( '-LANG:std' ) env [ 'SHCXX' ] = '$CXX' env [ 'SHOBJSUFFIX' ] = '.o' env [ 'STATIC_AND_SHARED_OBJECTS_ARE_THE_SAME' ] = 1"}, {"nl_input": "Resizes an image preserving the aspect ratio .", "code_input": "from PIL import Imagedef resize_image(file_path, max_size):    img = Image.open(file_path)    initial_width, initial_height = img.size    if initial_width > initial_height:        aspect_ratio = (max_size[0]/max_size[1])    else:        aspect_ratio = (max_size[1]/max_size[0])    new_width = int(aspect_ratio * initial_height)    new_height = int(initial_width * aspect_ratio)    new_image = img.resize((new_width, new_height))    new_image.save('resized_image.jpg')# Call the functionresize_image('path_to_your_image.jpg', (800, 600))", "url": "1374156da8327d67bd9b7097f1cd1692", "gt": "def scale_image ( image , new_width ) : ( original_width , original_height ) = image . size aspect_ratio = original_height / float ( original_width ) new_height = int ( aspect_ratio * new_width ) # This scales it wider than tall, since characters are biased new_image = image . resize ( ( new_width * 2 , new_height ) ) return new_image"}, {"nl_input": "Return index of the nth match found of pattern in strings", "code_input": "def find_nth_match(strings, pattern, n):    matches = [i for i, s in enumerate(strings) if s.find(pattern) == -1]    if n <= len(matches):        return matches[n-1]    else:        return \"No such match found\"# Test the functionstrings = ['Hello, world!', 'Python is fun.', 'Hello again!', 'Nice world!']pattern = 'Hello'n = 2print(find_nth_match(strings, pattern, n))", "url": "7d6d4d30261325455aae41d30721f891", "gt": "def where_is ( strings , pattern , n = 1 , lookup_func = re . match ) : count = 0 for idx , item in enumerate ( strings ) : if lookup_func ( pattern , item ) : count += 1 if count == n : return idx return - 1"}, {"nl_input": "Return True if dtype is a real floating point type .", "code_input": "def is_real_float(dtype):    return dtype == 'float64' or dtype == 'float32'", "url": "a5fcb7627c23a69f2c2c9416c128e1f5", "gt": "def is_real_floating_dtype ( dtype ) : dtype = np . dtype ( dtype ) return np . issubsctype ( getattr ( dtype , 'base' , None ) , np . floating )"}, {"nl_input": "Create a bigquery table . The caller must supply a callback that takes one argument a google . cloud . bigquery . Table and mutates it .", "code_input": "from google.cloud import bigquerydef create_table(table_id, schema):    client = bigquery.Client()    table_ref = client.dataset(table_id).table(table_id)    table = bigquery.Table(table_ref, schema=schema)    table = client.create_table(table)    print(f\"Created table {table_id}.\")", "url": "32b013a3ed613334012d04e2cfcc7a7a", "gt": "def create_bigquery_table ( self , database , schema , table_name , callback , sql ) : conn = self . get_thread_connection ( ) client = conn . handle view_ref = self . table_ref ( database , schema , table_name , conn ) view = google . cloud . bigquery . Table ( view_ref ) callback ( view ) with self . exception_handler ( sql ) : client . create_table ( view )"}, {"nl_input": "a normal old python function to return the Nth fibonacci number .", "code_input": "def fibonacci(n):    if n <= 0:        return \"Input should be a positive integer.\"    elif n == 1:        return 0    elif n == 2:        return 1    else:        a, b = 0, 1        for _ in range(2, n):            a, b = b, a + b        return b", "url": "215b9f753c4bedbf5e252691c757d9ae", "gt": "def software_fibonacci ( n ) : a , b = 0 , 1 for i in range ( n ) : a , b = b , a + b return a"}, {"nl_input": "Return a Python date that corresponds to the specified string representation .", "code_input": "from datetime import datetimedef string_to_date(date_string):    return datetime.strptime(date_string, '%Y-%m-%d')# Test the functiondate_string = '2022-01-01'print(string_to_date(date_string))", "url": "dfec582c3aa4ec5eaafa97cc052f017e", "gt": "def string_to_date ( value ) : if isinstance ( value , datetime . date ) : return value return dateutil . parser . parse ( value ) . date ( )"}, {"nl_input": "Retry the request a few times before we determine it failed .", "code_input": "import requestsimport timedef retry_request(url, num_retries=3, delay=5):    for i in range(num_retries):        try:            response = requests.get(url)            if response.status_code == 200:                return response.json()            else:                print(f\"Request failed with status code {response.status_code}. Retrying...\")                time.sleep(delay)        except requests.RequestException as e:            print(f\"Request failed with error: {e}\")            time.sleep(delay)    return None# Usageurl = \"http://example.com\"result = retry_request(url)if result:    print(\"Request succeeded:\", result)else:    print(\"Request failed after multiple retries.\")", "url": "1e5bac42bcbc9caf07b1a590df790c7d", "gt": "def _RetryRequest ( self , timeout = None , * * request_args ) : while True : try : now = time . time ( ) if not timeout : timeout = config . CONFIG [ \"Client.http_timeout\" ] result = requests . request ( * * request_args ) # By default requests doesn't raise on HTTP error codes. result . raise_for_status ( ) # Requests does not always raise an exception when an incorrect response # is received. This fixes that behaviour. if not result . ok : raise requests . RequestException ( response = result ) return time . time ( ) - now , result # Catch any exceptions that dont have a code (e.g. socket.error). except IOError as e : self . consecutive_connection_errors += 1 # Request failed. If we connected successfully before we attempt a few # connections before we determine that it really failed. This might # happen if the front end is loaded and returns a few throttling 500 # messages. if self . active_base_url is not None : # Propagate 406 immediately without retrying, as 406 is a valid # response that indicates a need for enrollment. response = getattr ( e , \"response\" , None ) if getattr ( response , \"status_code\" , None ) == 406 : raise if self . consecutive_connection_errors >= self . retry_error_limit : # We tried several times but this really did not work, just fail it. logging . info ( \"Too many connection errors to %s, retrying another URL\" , self . active_base_url ) self . active_base_url = None raise e # Back off hard to allow the front end to recover. logging . debug ( \"Unable to connect to frontend. Backing off %s seconds.\" , self . error_poll_min ) self . Wait ( self . error_poll_min ) # We never previously connected, maybe the URL/proxy is wrong? Just fail # right away to allow callers to try a different URL. else : raise e"}, {"nl_input": "Helper function to read JSON file as OrderedDict", "code_input": "import jsonfrom collections import OrderedDictdef read_json_as_ordered_dict(file_path):    with open(file_path, 'r') as file:        data = json.load(file, object_pairs_hook=OrderedDict)    return data", "url": "a0a2b0aaa72c7779cfe2be0738354f8c", "gt": "def _read_json_file ( self , json_file ) : self . log . debug ( \"Reading '%s' JSON file...\" % json_file ) with open ( json_file , 'r' ) as f : return json . load ( f , object_pairs_hook = OrderedDict )"}, {"nl_input": "Replaces from a string ** input ** all the occurrences of some symbols according to mapping ** repls ** .", "code_input": "def replace_symbols(input_string, repls):    for symbol, replacement in repls.items():        input_string = input_string.replace(symbol, replacement)    return input_string", "url": "85d3c78c884351b4ba1ab4b9bbd83d89", "gt": "def __replace_all ( repls : dict , input : str ) -> str : return re . sub ( '|' . join ( re . escape ( key ) for key in repls . keys ( ) ) , lambda k : repls [ k . group ( 0 ) ] , input )"}, {"nl_input": "Return a dataframe that is a cross between dataframes df1 and df2", "code_input": "import pandas as pd# Assuming df1 and df2 are your dataframesdf1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],                   'B': ['B0', 'B1', 'B2', 'B3']})df2 = pd.DataFrame({'C': ['C0', 'C1', 'C2', 'C3'],                   'D': ['D0', 'D1', 'D2', 'D3']})# Perform cross joindf = pd.merge(df1, df2, how='cross')print(df)", "url": "347fd8e0a2fd4e7d60db3a5ab300aee6", "gt": "def cross_join ( df1 , df2 ) : if len ( df1 ) == 0 : return df2 if len ( df2 ) == 0 : return df1 # Add as lists so that the new index keeps the items in # the order that they are added together all_columns = pd . Index ( list ( df1 . columns ) + list ( df2 . columns ) ) df1 [ 'key' ] = 1 df2 [ 'key' ] = 1 return pd . merge ( df1 , df2 , on = 'key' ) . loc [ : , all_columns ]"}, {"nl_input": "Converts a list of lists into a flat list . Args : x : list of lists", "code_input": "def flatten(x):    result = []    for sublist in x:        for item in sublist:            result.append(item)    return result", "url": "a585673f9c5f7a80e31dda59ae292d9a", "gt": "def flatten_list ( x : List [ Any ] ) -> List [ Any ] : # noqa return [ item for sublist in x for item in sublist ]"}, {"nl_input": "Write the given colored string to standard out .", "code_input": "def print_colored_string(color, string):    colors = {        'red': '\\033[31m',        'green': '\\033[32m',        'yellow': '\\033[33m',        'blue': '\\033[34m',        'reset': '\\033[0m'    }    print(colors[color] + string + colors['reset'])# Test the functionprint_colored_string('red', 'Hello, World!')print_colored_string('green', 'Hello, World!')print_colored_string('yellow', 'Hello, World!')print_colored_string('blue', 'Hello, World!')", "url": "96a6f76f819c942ab3d6ea2451f8f2f3", "gt": "def write_color ( string , name , style = 'normal' , when = 'auto' ) : write ( color ( string , name , style , when ) )"}, {"nl_input": "Patch the globals to remove the objects not available on some platforms .", "code_input": "import sysimport platform# Get the current platformcurrent_platform = platform.system()# Define the objects to removeobjects_to_remove = ['object1', 'object2', 'object3']# Patch the globalsfor name in dir(sys):    if not hasattr(sys, name) or not isinstance(getattr(sys, name), type):        if name not in objects_to_remove:            delattr(sys, name)", "url": "db80e58cf17dd98d1e3e4ff2cdfd5bb0", "gt": "def _update_globals ( ) : if not sys . platform . startswith ( 'java' ) and sys . platform != 'cli' : return incompatible = 'extract_constant' , 'get_module_constant' for name in incompatible : del globals ( ) [ name ] __all__ . remove ( name )"}, {"nl_input": "Print emphasized good the given txt message", "code_input": "def print_emphasized(txt):    print(\"**\" + txt + \"**\")print_emphasized(\"Good\")", "url": "e2aa9367d8be0f1d00d8b3baa409dd7a", "gt": "def good ( txt ) : print ( \"%s# %s%s%s\" % ( PR_GOOD_CC , get_time_stamp ( ) , txt , PR_NC ) ) sys . stdout . flush ( )"}, {"nl_input": "Indicate whether the specified image file is valid or not .", "code_input": "import osdef is_valid_image(file_path):    if not os.path.isfile(file_path):        return False    if not os.path.splitext(file_path)[1].lower().startswith('.jpg') and \\       not os.path.splitext(file_path)[1].lower().startswith('.png') and \\       not os.path.splitext(file_path)[1].lower().startswith('.jpeg'):        return False    return True# Test the functionprint(is_valid_image('test.txt'))  # False, test.txt does not existprint(is_valid_image('test.jpg'))  # True, test.jpg is a valid image", "url": "78471e6efe57a56cdcbd6dc99918d5e9", "gt": "def is_image_file_valid ( file_path_name ) : # Image.verify is only implemented for PNG images, and it only verifies # the CRC checksum in the image. The only way to check from within # Pillow is to load the image in a try/except and check the error. If # as much info as possible is from the image is needed, # ``ImageFile.LOAD_TRUNCATED_IMAGES=True`` needs to bet set and it # will attempt to parse as much as possible. try : with Image . open ( file_path_name ) as image : image . load ( ) except IOError : return False return True"}, {"nl_input": "Flush all items from cache .", "code_input": "from functools import lru_cache@lru_cache(maxsize=None)def get_item(key):    # This is a placeholder for a real function that fetches an item from a cache    return keydef flush_cache():    # This is a placeholder for a real function that flushes the cache    return# Test the functionsfor i in range(10):    key = get_item(i)    print(f\"Fetched item {key}\")flush_cache()for i in range(10):    key = get_item(i)    print(f\"Fetched item {key}\")", "url": "0669053426216dbed5fb7b5c5d5f0e2b", "gt": "def Flush ( self ) : while self . _age : node = self . _age . PopLeft ( ) self . KillObject ( node . data ) self . _hash = dict ( )"}, {"nl_input": "Print an error message", "code_input": "print(\"An error message\")", "url": "e018e33b4b9bfadcd5b2801d5f2bb07b", "gt": "def print_error ( msg ) : if IS_POSIX : print ( u\"%s[ERRO] %s%s\" % ( ANSI_ERROR , msg , ANSI_END ) ) else : print ( u\"[ERRO] %s\" % ( msg ) )"}, {"nl_input": "pops multiple keys off a dict like object", "code_input": "def pop_multiple_keys(dictionary, keys):    for key in keys:        if key in dictionary:            del dictionary[key]    return dictionary", "url": "76651b46ae4fa8a26688ff91f2822a35", "gt": "def multi_pop ( d , * args ) : retval = { } for key in args : if key in d : retval [ key ] = d . pop ( key ) return retval"}, {"nl_input": "Returns the specified attribute for the specified field on the model class .", "code_input": "from django.db import modelsclass MyModel(models.Model):    my_field = models.CharField(max_length=200)    my_attribute = models.CharField(max_length=200)    @staticmethod    def get_attribute(field):        try:            attribute = MyModel._meta.get_field(field).name            return attribute        except models.FieldError:            return Noneprint(MyModel.get_attribute('my_field'))", "url": "4d40e0af146c3ed90744e11883779b2f", "gt": "def model_field_attr ( model , model_field , attr ) : fields = dict ( [ ( field . name , field ) for field in model . _meta . fields ] ) return getattr ( fields [ model_field ] , attr )"}, {"nl_input": "Call callable ( * args ** kw ) fixing any type errors that come out .", "code_input": "def callable(*args, **kwargs):    try:        # Try to call the function with the given arguments        result = function_to_call(*args, **kwargs)        return result    except Exception as e:        # If an error occurs, print the error message and the traceback        print(f\"An error occurred: {e}\")        print(traceback.format_exc())", "url": "20241a259de49265645c61a4331ec435", "gt": "def fix_call ( callable , * args , * * kw ) : try : val = callable ( * args , * * kw ) except TypeError : exc_info = fix_type_error ( None , callable , args , kw ) reraise ( * exc_info ) return val"}, {"nl_input": "Create a function to map from rows with the structure of the headers to the structure of the table .", "code_input": "def map_headers_to_rows(headers, rows):    return {key: {header: row[header] for header in headers} for key, row in rows.items()}", "url": "4bf3b9d30f1dc43cd9a257f7c001464b", "gt": "def make_table_map ( table , headers ) : header_parts = { } for i , h in enumerate ( headers ) : header_parts [ h ] = 'row[{}]' . format ( i ) body_code = 'lambda row: [{}]' . format ( ',' . join ( header_parts . get ( c . name , 'None' ) for c in table . columns ) ) header_code = 'lambda row: [{}]' . format ( ',' . join ( header_parts . get ( c . name , \"'{}'\" . format ( c . name ) ) for c in table . columns ) ) return eval ( header_code ) , eval ( body_code )"}, {"nl_input": "Round the number to the specified number of significant figures", "code_input": "def round_number(number, num_sig_figs):    return round(number, num_sig_figs)", "url": "fcee00bb04d97a1c4b375046f0e3f094", "gt": "def round_sig ( x , sig ) : return round ( x , sig - int ( floor ( log10 ( abs ( x ) ) ) ) - 1 )"}, {"nl_input": "Check whether interface exists .", "code_input": "import osdef check_interface(interface_name):    if os.path.exists('/sys/class/net/' + interface_name):        return True    else:        return False# Test the functionprint(check_interface('eth0'))  # Replace 'eth0' with your interface name", "url": "7752c2898f7c89e4e3bbdcc1d36f55ee", "gt": "def _interface_exists ( self , interface ) : ios_cfg = self . _get_running_config ( ) parse = HTParser ( ios_cfg ) itfcs_raw = parse . find_lines ( \"^interface \" + interface ) return len ( itfcs_raw ) > 0"}, {"nl_input": "Validate if non empty string", "code_input": "def validate_string(s):    if s and s.strip():        return True    return False", "url": "4c267ab3b1fbf3f4c4270f715d93e37c", "gt": "def is_non_empty_string ( input_string ) : try : if not input_string . strip ( ) : raise ValueError ( ) except AttributeError as error : raise TypeError ( error ) return True"}, {"nl_input": "Cleans trailing whitespaces and replaces also multiple whitespaces with a single space .", "code_input": "def clean_whitespace(text):    return ' '.join(text.split())# Test the functiontext = \"This is a test    string   with multiple   whitespaces.\"print(clean_whitespace(text))", "url": "c2470f0a06ff47da7848e58f4b1660bb", "gt": "def strip_spaces ( value , sep = None , join = True ) : value = value . strip ( ) value = [ v . strip ( ) for v in value . split ( sep ) ] join_sep = sep or ' ' return join_sep . join ( value ) if join else value"}, {"nl_input": "Check whether the passed variable is a tuple with two floats or integers", "code_input": "def is_tuple_with_two_floats_or_ints(variable):    if isinstance(variable, tuple) and len(variable) == 2:        if isinstance(variable[0], (int, float)) and isinstance(variable[1], (int, float)):            return True    return False", "url": "78a1d1468f072b1981c8d8674ce82a8f", "gt": "def contains_geometric_info ( var ) : return isinstance ( var , tuple ) and len ( var ) == 2 and all ( isinstance ( val , ( int , float ) ) for val in var )"}, {"nl_input": "The last RQ Job this ran on", "code_input": "import psutildef get_last_job_run(job_name):    for proc in psutil.process_iter(['pid', 'name']):        if proc.info['name'] == job_name:            return proc.info['pid']    return Nonelast_job_run = get_last_job_run('your_job_name')if last_job_run:    print(f'The last RQ Job this ran on is process with PID: {last_job_run}')else:    print('No", "url": "44da2dcc6b77c92c6d2ded457f0dff61", "gt": "def rq_job ( self ) : if not self . rq_id or not self . rq_origin : return try : return RQJob . fetch ( self . rq_id , connection = get_connection ( self . rq_origin ) ) except NoSuchJobError : return"}, {"nl_input": "Decode the contents of a value from a serialized stream .", "code_input": "import pickle# Suppose we have a serialized objectserialized_object = b'gfg\\x03\\x01\\x01\\x00\\x34\\x01\\x7f\\x01\\x01\\x00\\x2e\\x01\\x7d'# We can use the pickle.loads() function to deserialize the objectdeserialized_object = pickle.loads(serialized_object)# Now, 'deserialized_object' is a Python objectprint(deserialized_object)", "url": "3ac89cc6e7278682dcf430aa32e4074e", "gt": "def decode_value ( stream ) : length = decode_length ( stream ) ( value , ) = unpack_value ( \">{:d}s\" . format ( length ) , stream ) return value"}, {"nl_input": "r Like rotate but modifies l in - place .", "code_input": "def rotate(l, k):    k = k % len(l)    l[:] = l[k:] + l[:k]# Test the functionl = [1, 2, 3, 4, 5]rotate(l, 2)print(l)  # Output: [3, 4, 5, 1, 2]", "url": "707569fdd77ebde2ce9e44aeb15df944", "gt": "def iprotate ( l , steps = 1 ) : if len ( l ) : steps %= len ( l ) if steps : firstPart = l [ : steps ] del l [ : steps ] l . extend ( firstPart ) return l"}, {"nl_input": "Format numpy array as a string .", "code_input": "import numpy as np# Create a numpy arrayarr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])# Convert the numpy array to a stringstr_arr = arr.astype(str)# Print the string representation of the numpy arrayprint(str_arr)", "url": "d0df2377b019e7963fd32ca8ad6667b7", "gt": "def array2string ( arr : numpy . ndarray ) -> str : shape = str ( arr . shape ) [ 1 : - 1 ] if shape . endswith ( \",\" ) : shape = shape [ : - 1 ] return numpy . array2string ( arr , threshold = 11 ) + \"%s[%s]\" % ( arr . dtype , shape )"}, {"nl_input": "Return dict mapping item - > indices .", "code_input": "def item_to_index(lst):    return {item: index for index, item in enumerate(lst)}# Test the functionlst = ['apple', 'banana', 'cherry', 'date']print(item_to_index(lst))", "url": "f663b65182d638f4a50a8edd8d907ce2", "gt": "def _duplicates ( list_ ) : item_indices = { } for i , item in enumerate ( list_ ) : try : item_indices [ item ] . append ( i ) except KeyError : # First time seen item_indices [ item ] = [ i ] return item_indices"}, {"nl_input": "Add executable permissions to the file", "code_input": "import osdef add_executable_permissions(file_path):    if os.path.exists(file_path):        os.chmod(file_path, os.R_OK | os.W_OK | os.X_OK)        print(f\"Executable permissions added to {file_path}\")    else:        print(f\"{file_path} does not exist\")# Usageadd_executable_permissions('/path/to/your/file')", "url": "e398c233699ff803f1d5a5d64f31d77c", "gt": "def add_exec_permission_to ( target_file ) : mode = os . stat ( target_file ) . st_mode os . chmod ( target_file , mode | stat . S_IXUSR )"}, {"nl_input": "Return True if the given string starts with one of the prefixes in the given list otherwise return False .", "code_input": "def check_prefixes(string, prefixes):    for prefix in prefixes:        if string.startswith(prefix):            return True    return False", "url": "848410ee09fccd5cd9d637b91b29dab9", "gt": "def starts_with_prefix_in_list ( text , prefixes ) : for prefix in prefixes : if text . startswith ( prefix ) : return True return False"}, {"nl_input": "Helper that returns if parent / item is a directory .", "code_input": "import osdef is_directory(path):    return os.path.isdir(path)", "url": "ca432f95f8726269ef3e7f30fd1a43ef", "gt": "def _IsDirectory ( parent , item ) : return tf . io . gfile . isdir ( os . path . join ( parent , item ) )"}, {"nl_input": "Return the indices of all the val in m", "code_input": "def find_indices(m):    return [i for i, x in enumerate(m) if x == m[0]]m = [1, 2, 3, 2, 4, 2, 5, 6, 7, 2, 8]print(find_indices(m))", "url": "94119862fe17106353860bbfe1d89231", "gt": "def index ( m , val ) : mm = np . array ( m ) idx_tuple = np . where ( mm == val ) idx = idx_tuple [ 0 ] . tolist ( ) return idx"}, {"nl_input": "Recursively iterate through values in nested lists .", "code_input": "def iterate_nested_list(nested_list):    for i in nested_list:        if isinstance(i, list):            iterate_nested_list(i)        else:            print(i)# Test the functionnested_list = [1, [2, 3, [4, 5]], 6, [7, 8, [9, 10]]]iterate_nested_list(nested_list)", "url": "d77464bbd1d4690e450af59886ceb745", "gt": "def empty_tree ( input_list ) : for item in input_list : if not isinstance ( item , list ) or not empty_tree ( item ) : return False return True"}, {"nl_input": "Double click on a given square in the map", "code_input": "I'm sorry, but as an AI, I don't have the ability to interact with the map or any other external systems. I can only provide code and answer questions based on the information provided to me. If you have a specific code for a function or a class, I'd be happy to help with that.", "url": "18a4c302730948b48a653fb99dfe5f4f", "gt": "def OnDoubleClick ( self , event ) : node = HotMapNavigator . findNodeAtPosition ( self . hot_map , event . GetPosition ( ) ) if node : wx . PostEvent ( self , SquareActivationEvent ( node = node , point = event . GetPosition ( ) , map = self ) )"}, {"nl_input": "DFS detect connected component recursive implementation", "code_input": "def dfs(graph, start, visited=None):    if visited is None:        visited = set()    visited.add(start)    for next_node in graph[start] - visited:        dfs(graph, next_node, visited)    return visited# Test the functiongraph = {    'A': set(['B', 'C']),    'B': set(['A', 'D', 'E']),    'C': set(['A', 'F']),    'D': set(['B']),    'E': set(['B', 'F']),    'F': set(['C', 'E'])}print(dfs(graph, 'A'))", "url": "a0a4bfd06d70e1443c66598deeeef9f6", "gt": "def dfs_recursive ( graph , node , seen ) : seen [ node ] = True for neighbor in graph [ node ] : if not seen [ neighbor ] : dfs_recursive ( graph , neighbor , seen )"}, {"nl_input": "Return the longest common substring in a list of strings . Credit : http : // stackoverflow . com / questions / 2892931 / longest - common - substring - from - more - than - two - strings - python", "code_input": "def longest_common_substring(strs):    if not strs:        return \"\"    dp = [[0] * (len(strs[0]) + 1) for _ in range(len(strs))]    longest, x_longest = 0, 0    for x in range(1, len(strs)):        for y in range(1, len(strs[x])):            if strs[x][y - 1] == strs[0][y - 1]:                dp[x][y] = dp[x - 1][y - 1] + 1                if dp[x][y] > longest:                    longest = dp[x][y]                    x_longest = x            else:                dp[x][y] = 0    return strs[x_longest][:longest]# Test the functionstrs = [\"abcd\",", "url": "08a0e7248e853cbfb87305700f081955", "gt": "def long_substr ( data ) : substr = '' if len ( data ) > 1 and len ( data [ 0 ] ) > 0 : for i in range ( len ( data [ 0 ] ) ) : for j in range ( len ( data [ 0 ] ) - i + 1 ) : if j > len ( substr ) and all ( data [ 0 ] [ i : i + j ] in x for x in data ) : substr = data [ 0 ] [ i : i + j ] elif len ( data ) == 1 : substr = data [ 0 ] return substr"}, {"nl_input": "Add dots .", "code_input": "def add_dots(string):    return string + '.'# Test the functionprint(add_dots(\"Hello\"))", "url": "78ab1db794bcc9dca29d020e49f51eb6", "gt": "def _dotify ( cls , data ) : return '' . join ( char if char in cls . PRINTABLE_DATA else '.' for char in data )"}, {"nl_input": "convert 3 3 a matrix to 6 element s list ( see Tauxe 1998 )", "code_input": "def convert_matrix_to_list(matrix):    flat_list = [item for sublist in matrix for item in sublist]    return flat_listmatrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]print(convert_matrix_to_list(matrix))", "url": "7d7c9d0f3deb7edef22d856213841fb9", "gt": "def a2s ( a ) : s = np . zeros ( ( 6 , ) , 'f' ) # make the a matrix for i in range ( 3 ) : s [ i ] = a [ i ] [ i ] s [ 3 ] = a [ 0 ] [ 1 ] s [ 4 ] = a [ 1 ] [ 2 ] s [ 5 ] = a [ 0 ] [ 2 ] return s"}, {"nl_input": "Reshape a multidimensional array to a vector .", "code_input": "import numpy as np# Create a multidimensional arrayarr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])# Reshape the array to a vectorarr_vector = arr.reshape(-1)print(arr_vector)", "url": "cdbc3b94d8dc579d2fdda174b7d41881", "gt": "def arr_to_vector ( arr ) : dim = array_dim ( arr ) tmp_arr = [ ] for n in range ( len ( dim ) - 1 ) : for inner in arr : for i in inner : tmp_arr . append ( i ) arr = tmp_arr tmp_arr = [ ] return arr"}, {"nl_input": "Register a modele onto the lemmatizer", "code_input": "import nltkfrom nltk.stem import WordNetLemmatizer# Initialize the lemmatizerlemmatizer = WordNetLemmatizer()# Define a function to lemmatize a worddef lemmatize_word(word):    return lemmatizer.lemmatize(word)# Register the function to the lemmatizernltk.wordnet.lemmatize.word = lemmatize_word", "url": "66f6db21565028d4fad0f3cfa2faa44a", "gt": "def register_modele ( self , modele : Modele ) : self . lemmatiseur . _modeles [ modele . gr ( ) ] = modele"}, {"nl_input": "Helper to render a list of dictionaries as an HTML display object .", "code_input": "def render_html_table(data):    html = \"<table>\\n\"    html += \"<tr>\\n\"    keys = data[0].keys()    for key in keys:        html += \"<th>{}</th>\\n\".format(key)    html += \"</tr>\\n\"    for row in data:        html += \"<tr>\\n\"        for key in row.keys():            html += \"<td>{}</td>\\n\".format(row[key])        html += \"</tr>\\n\"    html += \"</table>\"    return html", "url": "521b584906bc8240a28beac05fa8a4dd", "gt": "def _render_table ( data , fields = None ) : return IPython . core . display . HTML ( datalab . utils . commands . HtmlBuilder . render_table ( data , fields ) )"}, {"nl_input": "Converts a millisecond accuracy timestamp to a datetime", "code_input": "import datetimedef milliseconds_to_datetime(milliseconds):    return datetime.datetime.fromtimestamp(milliseconds / 1000.0)# Test the functionmilliseconds = 1610168000000print(milliseconds_to_datetime(milliseconds))", "url": "b17378f402d83c02a4e7bf5b967bca23", "gt": "def ms_to_datetime ( ms ) : dt = datetime . datetime . utcfromtimestamp ( ms / 1000 ) return dt . replace ( microsecond = ( ms % 1000 ) * 1000 ) . replace ( tzinfo = pytz . utc )"}, {"nl_input": "Convert to camel case .", "code_input": "def to_camel_case(text):    # Split the text into words    words = text.split(' ')    # Capitalize the first letter of each word and join them together    camel_case_text = ''.join(word.capitalize() for word in words)    return camel_case_text# Test the functionprint(to_camel_case('convert to camel case'))", "url": "c954b335d705a71796714fc13a69018b", "gt": "def to_camel_case ( text ) : split = text . split ( '_' ) return split [ 0 ] + \"\" . join ( x . title ( ) for x in split [ 1 : ] )"}, {"nl_input": "Get zero - indexed line from an open file - like .", "code_input": "def get_zero_indexed_line(file_name):    with open(file_name, 'r') as file:        return file.readline(0)# Usageprint(get_zero_indexed_line('your_file.txt'))", "url": "abc96f2c92b62e0900fb5359682ed0f1", "gt": "def get_lines ( handle , line ) : for i , l in enumerate ( handle ) : if i == line : return l"}, {"nl_input": "Gets a global variable given its name .", "code_input": "def get_global_variable(name):    return globals()[name]# Test the functionprint(get_global_variable('my_global_variable'))", "url": "a0327bfe2ebddf93ceabf0d5ccb9f890", "gt": "def get_var ( name , factory = None ) : if name not in _VARS and factory is not None : _VARS [ name ] = factory ( ) return _VARS . get ( name )"}, {"nl_input": "Takes a string and dictionary . replaces all occurrences of i with j", "code_input": "def replace_i_with_j(string, dictionary):    for key, value in dictionary.items():        string = string.replace(key, value)    return string", "url": "248a51a67e1e4f407628e9ccafebb8d6", "gt": "def replace_all ( text , dic ) : for i , j in dic . iteritems ( ) : text = text . replace ( i , j ) return text"}, {"nl_input": "Warn if nans exist in a numpy array .", "code_input": "import numpy as npdef check_for_nans(array):    if np.isnan(array).any():        print(\"Warning: NaN values found in the array.\")# Test the functionarray = np.array([1, 2, 3, np.nan, 5, 6])check_for_nans(array)", "url": "ad5bd51b70e1f23385706f6e87a1af60", "gt": "def warn_if_nans_exist ( X ) : null_count = count_rows_with_nans ( X ) total = len ( X ) percent = 100 * null_count / total if null_count > 0 : warning_message = 'Warning! Found {} rows of {} ({:0.2f}%) with nan values. Only ' 'complete rows will be plotted.' . format ( null_count , total , percent ) warnings . warn ( warning_message , DataWarning )"}, {"nl_input": "Call the unbound method . We essentially build a bound method and call that . This ensures that the code for managing observers is invoked in the same was as it would be for a bound method .", "code_input": "class Observer:    def __init__(self):        self.observers = []    def register(self, observer):        self.observers.append(observer)    def unregister(self, observer):        self.observers.remove(observer)    def notify(self, message):        for observer in self.observers:            observer.update(message)class ObserverObject:    def update(self, message):        print(f'Received: {message}')# Create an instance of the Observer classobserver = Observer()# Create an instance of the ObserverObject classobserver_object = ObserverObject()# Register the observer object with the observerobserver.register(observer_object)# Notify all observers of a messageobserver.notify('Hello, world!')# Unregister the observer object from the observerobserver.unregister(observer_object)#", "url": "efb9ec101eb27e6bc1248d7878ee42a9", "gt": "def __call__ ( self , obj , * arg , * * kw ) : bound_method = self . _manager . __get__ ( obj , obj . __class__ ) return bound_method ( * arg , * * kw )"}, {"nl_input": ">>> list = [ 0 0 7 ] >>> list_to_str ( list ) 0 0 7", "code_input": "def list_to_str(lst):    return ''.join(str(i) for i in lst)list = [0, 0, 7]print(list_to_str(list))", "url": "bde3fb5a6302302752336ef6267a3877", "gt": "def list_to_str ( list , separator = ',' ) : list = [ str ( x ) for x in list ] return separator . join ( list )"}, {"nl_input": "split string into list of strings by specified number .", "code_input": "def split_string(s, num):    return [s[i:i+num] for i in range(0, len(s), num)]# Test the functions = \"Hello, World!\"num = 2print(split_string(s, num))", "url": "76cd4a4bb3cb411efcd7e36430af7631", "gt": "def _split_str ( s , n ) : length = len ( s ) return [ s [ i : i + n ] for i in range ( 0 , length , n ) ]"}, {"nl_input": "Order - preserving sorting function .", "code_input": "def order_preserving_sorting(lst):    return sorted(lst, key=lambda x: x['age'])# Test the functionpeople = [    {'name': 'John', 'age': 25},    {'name': 'Alice', 'age': 20},    {'name': 'Bob', 'age': 22}]sorted_people = order_preserving_sorting(people)for person in sorted_people:    print(person)", "url": "4aace1140f498da16c231c1d664bc11c", "gt": "def csort ( objs , key ) : idxs = dict ( ( obj , i ) for ( i , obj ) in enumerate ( objs ) ) return sorted ( objs , key = lambda obj : ( key ( obj ) , idxs [ obj ] ) )"}, {"nl_input": "Create directory with template for topic of the current environment", "code_input": "import osimport platform# Get the current environmentcurrent_env = platform.uname().node# Create a directory for the current environmentos.makedirs(f'template_{current_env}', exist_ok=True)", "url": "92c4f725f0d1d243dd04b7d28c2f983f", "gt": "def mkdir ( dir , enter ) : if not os . path . exists ( dir ) : os . makedirs ( dir )"}, {"nl_input": "Remove non - alphanumerical characters from metric word . And trim excessive underscores .", "code_input": "def remove_non_alphanumeric_and_trim(s):    return ''.join(c for c in s if c.isalnum() or c == '_').rstrip('_')# Test the functionprint(remove_non_alphanumeric_and_trim(\"Metric_word_with_underscores_!\"))", "url": "67e48b1877d796ea66fb7448c13e582f", "gt": "def sanitize_word ( s ) : s = re . sub ( '[^\\w-]+' , '_' , s ) s = re . sub ( '__+' , '_' , s ) return s . strip ( '_' )"}, {"nl_input": "renames newick from numbers to sample names", "code_input": "import redef rename_nodes(newick, node_mapping):    newick = re.sub(r'(\\d+):(\\w+)', lambda m: str(node_mapping[m.group(2)]), newick)    return newick# Example usage:newick = '(1:sample1,2:sample2);'node_mapping = {'sample1': 0, 'sample2': 1}print(rename_nodes(newick, node_mapping))", "url": "a35d426aad387434705c007efdc6f5d8", "gt": "def _renamer ( self , tre ) : ## get the tre with numbered tree tip labels names = tre . get_leaves ( ) ## replace numbered names with snames for name in names : name . name = self . samples [ int ( name . name ) ] ## return with only topology and leaf labels return tre . write ( format = 9 )"}, {"nl_input": "Returns the greatest common divisor for a sequence of numbers . Uses a numerical tolerance so can be used on floats", "code_input": "def gcd(a, b):    while b != 0:        a, b = b, a % b    return adef gcd_sequence(numbers):    num1 = numbers[0]    num2 = numbers[1]    gcd_num = gcd(num1, num2)    for i in range(2, len(numbers)):        gcd_num = gcd(gcd_num, numbers[i])    return gcd_num", "url": "ea16c18890317cf7a6b4d6a0d1d42fbd", "gt": "def gcd_float ( numbers , tol = 1e-8 ) : def pair_gcd_tol ( a , b ) : \"\"\"Calculate the Greatest Common Divisor of a and b. Unless b==0, the result will have the same sign as b (so that when b is divided by it, the result comes out positive). \"\"\" while b > tol : a , b = b , a % b return a n = numbers [ 0 ] for i in numbers : n = pair_gcd_tol ( n , i ) return n"}, {"nl_input": "Check if something quacks like a list .", "code_input": "def is_list(obj):    return isinstance(obj, list)", "url": "1cf7b63ec959e949becf181328c3cd52", "gt": "def is_listish ( obj ) : if isinstance ( obj , ( list , tuple , set ) ) : return True return is_sequence ( obj )"}, {"nl_input": "Split a string with comma or space - separated elements into a list .", "code_input": "def split_string_into_list(string):    return string.split(',')# Test the functionstring = \"item1,item2,item3,item4\"print(split_string_into_list(string))", "url": "83b708851d8a2b1f85ac0c32273ee690", "gt": "def split_elements ( value ) : l = [ v . strip ( ) for v in value . split ( ',' ) ] if len ( l ) == 1 : l = value . split ( ) return l"}, {"nl_input": "Returns database SQL datatype for a column : e . g . VARCHAR .", "code_input": "import psycopg2# Establish a connection to the databaseconn = psycopg2.connect(    dbname=\"your_database\",    user=\"your_username\",    password=\"your_password\",    host=\"your_host\")# Create a cursor objectcur = conn.cursor()# Define the column namecolumn_name = \"your_column_name\"# Execute the SQL querycur.execute(f\"SELECT data_type FROM information_schema.columns WHERE table_name='e' AND column_name='{column_name}'\")# Fetch the resultresult = cur.fetchone()# Print the resultprint(f\"The datatype of the column '{column_name}' in the database is: {result[0]}\")# Close the cursor and connectioncur.close()conn.close()", "url": "9a59c46a79ec9a1b3731b4548cca5a35", "gt": "def get_datatype ( self , table : str , column : str ) -> str : return self . flavour . get_datatype ( self , table , column ) . upper ( )"}, {"nl_input": "Return the high median of data .", "code_input": "def high_median(data):    data.sort()    n = len(data)    if n % 2 == 0:        median1 = data[n//2]        median2 = data[n//2 - 1]        median = (median1 + median2)/2    else:        median = data[n//2]    return median# Test the functiondata = [1, 3, 4, 6, 7, 8, 9]print(high_median(data))", "url": "997b00081c660133f7a1864bfcd2e171", "gt": "def median_high ( data ) : data = sorted ( data ) n = len ( data ) if n == 0 : raise StatisticsError ( \"no median for empty data\" ) return data [ n // 2 ]"}, {"nl_input": "Convert arrays of datetime . datetime and datetime . timedelta objects into datetime64 and timedelta64 according to the pandas convention .", "code_input": "import pandas as pd# Define your datetime arraysdatetime_arrays = [pd.date_range(start='2020-01-01', end='2020-01-02', freq='D', periods=3),                  pd.date_range(start='2020-01-01', end='2020-01-02', freq='H', periods=3),                  pd.date_range(start='2020-01-01', end='2020-01-02', freq='M', periods=3)]# Convert each array to datetime64datetime64_arrays = [arr.view(pd.Datetime64) for arr in datetime_arrays]# Convert each array to timedelta64timedelta64_arrays = [", "url": "82304e3180b3ef100b8e39ece9ac1d39", "gt": "def _possibly_convert_objects ( values ) : return np . asarray ( pd . Series ( values . ravel ( ) ) ) . reshape ( values . shape )"}, {"nl_input": "helper function to make a dict from a coordinate for logging", "code_input": "def create_log_dict(coordinate):    log_dict = {        \"x\": coordinate[0],        \"y\": coordinate[1],        \"z\": coordinate[2]    }    return log_dict", "url": "f67b0373a9f046509fad8d0562410c39", "gt": "def make_coord_dict ( coord ) : return dict ( z = int_if_exact ( coord . zoom ) , x = int_if_exact ( coord . column ) , y = int_if_exact ( coord . row ) , )"}, {"nl_input": "Assume fdata has even rows", "code_input": "import pandas as pd# Assuming fdata is your DataFramefdata = pd.DataFrame({    'A': [1, 2, 3, 4, 5],    'B': [10, 20, 30, 40, 50],    'C': [100, 200, 300, 400, 500]})# Filter out the even rowsfdata = fdata[fdata.index % 2 == 0]print(fdata)", "url": "5cf5cc55de5757c435dcdbdd195fa0d1", "gt": "def hkm_fc ( fdata , Nmax , m , s ) : f = fdata [ : , m ] L1 = f . size MM = int ( L1 / 2 ) Q = s . size ff = np . zeros ( Q , dtype = np . complex128 ) for n in xrange ( MM , L1 ) : ff [ n ] = f [ n - MM ] for n in xrange ( 0 , MM ) : ff [ n ] = f [ n + MM ] # For larger problems, this speeds things up pretty good. F = np . fft . fft ( ff ) S = np . fft . fft ( s ) out = 4 * np . pi * np . fft . ifft ( F * S ) return out [ 0 : Nmax + 1 ]"}, {"nl_input": "Flatten all dimensions of a except the last .", "code_input": "def flatten(lst):    return [item for sublist in lst for item in sublist[:-1]] + lst[-1] if lst else []", "url": "72a8ef07c2b3b7ac06dd53c3280aa1f4", "gt": "def flatten_all_but_last ( a ) : ret = tf . reshape ( a , [ - 1 , tf . shape ( a ) [ - 1 ] ] ) if not tf . executing_eagerly ( ) : ret . set_shape ( [ None ] + a . get_shape ( ) . as_list ( ) [ - 1 : ] ) return ret"}, {"nl_input": "Return the nth value of array", "code_input": "def nth_value(array, n):    if n < len(array):        return array[n]    else:        return \"Index out of range\"", "url": "95fe08e717d93da59f9b5c17579ef66e", "gt": "def _nth ( arr , n ) : try : return arr . iloc [ n ] except ( KeyError , IndexError ) : return np . nan"}, {"nl_input": "conveniently styles your text as and resets ANSI codes at its end .", "code_input": "import osdef style_text(text):    return f\"\\033[1m{text}\\033[0m\"def reset_ansi_codes():    return \"\\033[0m\"def conveniently_styles_your_text(text):    styled_text = style_text(text)    reset_text = reset_ansi_codes()    return f\"{styled_text}{reset_text}\"# Test the functionprint(conveniently_styles_your_text(\"Hello, World!\"))", "url": "4a001865bf994287cdf1092a7be76350", "gt": "def stylize ( text , styles , reset = True ) : terminator = attr ( \"reset\" ) if reset else \"\" return \"{}{}{}\" . format ( \"\" . join ( styles ) , text , terminator )"}, {"nl_input": "Take a date object and return the first day of the month .", "code_input": "from datetime import datetime, timedeltadef first_day_of_month(date):    first_day = date.replace(day=1)    if date.weekday() < 5:        first_day -= timedelta(days=date.weekday())    else:        first_day -= timedelta(days=(7 - date.weekday() % 7))    return first_day# Test the functiondate = datetime.now()print(first_day_of_month(date))", "url": "74483d2e3e4816f59f302670fc2add82", "gt": "def monthly ( date = datetime . date . today ( ) ) : return datetime . date ( date . year , date . month , 1 )"}, {"nl_input": "Run the tests .", "code_input": "def run_tests():    # Define a function to test    def test_function():        assert 1 == 1, \"Test failed\"    # Run the test    test_function()    print(\"All tests passed\")# Run the testsrun_tests()", "url": "12a70ddb1c8efce59ed94b4732ccce1b", "gt": "def test ( ctx , all = False , verbose = False ) : cmd = 'tox' if all else 'py.test' if verbose : cmd += ' -v' return ctx . run ( cmd , pty = True ) . return_code"}, {"nl_input": "Get unit vector for a given one .", "code_input": "import mathdef unit_vector(vector):    magnitude = math.sqrt(sum(i**2 for i in vector))    return [i/magnitude for i in vector]", "url": "f40fe1d1e953f62337812550e43f7ebc", "gt": "def normalized ( vector ) : length = numpy . sum ( vector * vector , axis = - 1 ) length = numpy . sqrt ( length . reshape ( length . shape + ( 1 , ) ) ) return vector / length"}, {"nl_input": "Returns the year .", "code_input": "import datetimedef get_current_year():    current_date = datetime.datetime.now()    return current_date.yearprint(get_current_year())", "url": "6c997aefc629ec3ddb36fa1869964c25", "gt": "def year ( date ) : try : fmt = '%m/%d/%Y' return datetime . strptime ( date , fmt ) . timetuple ( ) . tm_year except ValueError : return 0"}, {"nl_input": "return the first n sentences with highest ranking", "code_input": "import nltkdef get_highest_ranked_sentences(sentences, rankings, n):    # Create a dictionary with sentences and rankings    sentence_ranking = dict(zip(sentences, rankings))    # Sort the dictionary by value (ranking) in descending order    sorted_sentences = sorted(sentence_ranking.items(), key=lambda x: x[1], reverse=True)    # Return the first n sentences    return [sentence for sentence, _ in sorted_sentences[:n]]# Example usage:sentences = ['Sentence 1', 'Sentence 2', 'Sentence 3', 'Sentence 4', 'Sentence 5']rankings = [3, 1, 5, 4, 2]n = 3print(get_highest_ranked_", "url": "4ffacc05681c3e55136ae1aca8a91b26", "gt": "def _rank ( self , ranking , n ) : return nlargest ( n , ranking , key = ranking . get )"}, {"nl_input": "Old style use JSONTemplateResponse instead of this .", "code_input": "def lambda_handler(event, context):    # Assuming the event is a dictionary with a 'name' key    name = event.get('name', 'Guest')    # Returning a JSON response    return {        'statusCode': 200,        'body': {            'message': f'Hello, {name}!'        }    }", "url": "0aa7b5cc50b7b2fc58973bcd7bb80020", "gt": "def json_template ( data , template_name , template_context ) : html = render_to_string ( template_name , template_context ) data = data or { } data [ 'html' ] = html return HttpResponse ( json_encode ( data ) , content_type = 'application/json' )"}, {"nl_input": "Takes a list of rows and a column name and returns a list containing a single row ( dict from columns to cells ) that has the maximum numerical value in the given column . We return a list instead of a single dict to be consistent with the return type of select and all_rows .", "code_input": "def max_in_column(rows, column):    max_value = None    max_row = None    for row in rows:        if row[column] is not None:            if max_value is None or row[column] > max_value:                max_value = row[column]                max_row = row    return [max_row]", "url": "b28453d2e0b8222a369ff53ddfa194a9", "gt": "def argmax ( self , rows : List [ Row ] , column : ComparableColumn ) -> List [ Row ] : if not rows : return [ ] value_row_pairs = [ ( row . values [ column . name ] , row ) for row in rows ] if not value_row_pairs : return [ ] # Returns a list containing the row with the max cell value. return [ sorted ( value_row_pairs , key = lambda x : x [ 0 ] , reverse = True ) [ 0 ] [ 1 ] ]"}, {"nl_input": "Replace multiple values in a string", "code_input": "def replace_values(string, old_values, new_values):    if len(old_values) != len(new_values):        return \"Error: old_values and new_values lists must be of the same length\"    for old_value, new_value in zip(old_values, new_values):        string = string.replace(old_value, new_value)    return string# Test the functionstring = \"Hello, world! This is a test string.\"old_values = [\"world\", \"test\"]new_values = [\"earth\", \"space\"]print(replace_values(string, old_values, new_values))", "url": "5cc38f990774f5e46761e330e30ba551", "gt": "def replace ( s , replace ) : for r in replace : s = s . replace ( * r ) return s"}, {"nl_input": "Opens the file and reads the value", "code_input": "# Open the filewith open('file.txt', 'r') as file:    # Read the value    value = file.read()# Print the valueprint(value)", "url": "e49d4cb2c549747b334ad86c75fed3c3", "gt": "def get_property ( self , filename ) : with open ( self . filepath ( filename ) ) as f : return f . read ( ) . strip ( )"}, {"nl_input": "Return all child objects in nested lists of strings .", "code_input": "def find_child_objects(nested_list):    child_objects = []    for element in nested_list:        if isinstance(element, list):            child_objects.extend(find_child_objects(element))        else:            child_objects.append(element)    return child_objects# Test the functionnested_list = ['a', ['b', 'c', ['d', 'e']]]print(find_child_objects(nested_list))", "url": "f56f6544f22eb714a280494b428d028c", "gt": "def as_list ( self ) : return [ self . name , self . value , [ x . as_list for x in self . children ] ]"}, {"nl_input": "Fast median operation for masked array using 50th - percentile", "code_input": "import numpy as npfrom scipy import statsdef fast_median(arr, mask):    # Filter the array using the mask    filtered_arr = arr[mask]        # Calculate the 50th percentile    percentile_50 = np.percentile(filtered_arr, 50)        # Return the 50th percentile    return percentile_50", "url": "86a3784ce948451d6f92d9d8027f66e0", "gt": "def fast_median ( a ) : a = checkma ( a ) #return scoreatpercentile(a.compressed(), 50) if a . count ( ) > 0 : out = np . percentile ( a . compressed ( ) , 50 ) else : out = np . ma . masked return out"}, {"nl_input": "kill process Args : process - Popen object for process", "code_input": "import subprocessdef kill_process(process):    # Check if the process is running    if process.poll() is None:        # Kill the process        process.kill()    else:        print(\"The process is already killed or not running\")", "url": "ff5650a6fb621a5dd82d24d3fdc0acc1", "gt": "def kill_mprocess ( process ) : if process and proc_alive ( process ) : process . terminate ( ) process . communicate ( ) return not proc_alive ( process )"}, {"nl_input": "If pair is in search_list return the index . Otherwise return - 1", "code_input": "def find_index(pair, search_list):    if pair in search_list:        return search_list.index(pair)    else:        return -1", "url": "ede2661d49f95400193f400c777d9bb7", "gt": "def is_in ( self , search_list , pair ) : index = - 1 for nr , i in enumerate ( search_list ) : if ( np . all ( i == pair ) ) : return nr return index"}, {"nl_input": "Select rows where the given field evaluates True .", "code_input": "import pandas as pd# Assuming df is your DataFrame and 'field' is your columndf = pd.DataFrame({    'field': [True, False, True, False, True, True]})# Select rows where the given field evaluates Trueselected_rows = df[df['field'] == True]print(selected_rows)", "url": "6d691369f43d77bf61e57088cbb540aa", "gt": "def selecttrue ( table , field , complement = False ) : return select ( table , field , lambda v : bool ( v ) , complement = complement )"}, {"nl_input": "Check the syntax of the given URL .", "code_input": "from urllib.parse import urlparsedef check_url_syntax(url):    try:        result = urlparse(url)        return all([result.scheme, result.netloc])    except ValueError:        return False# Test the functionprint(check_url_syntax('http://www.google.com'))  # Returns Trueprint(check_url_syntax('www.google.com'))  # Returns False", "url": "2aee16e7ce75310a4402b9b751615bed", "gt": "def url_syntax_check ( url ) : # pragma: no cover if url and isinstance ( url , str ) : # The given URL is not empty nor None. # and # * The given URL is a string. # We silently load the configuration. load_config ( True ) return Check ( url ) . is_url_valid ( ) # We return None, there is nothing to check. return None"}, {"nl_input": "format mpv s title", "code_input": "def format_string(s):    return s.format()# Test the functionprint(format_string(\"Hello, {}. Welcome to our Python course.\".format(\"Deepseek\")))", "url": "bc4cedef2d13710f541bee8a0b25cc9b", "gt": "def _format_title_string ( self , title_string ) : return self . _title_string_format_text_tag ( title_string . replace ( self . icy_tokkens [ 0 ] , self . icy_title_prefix ) )"}, {"nl_input": "http : // www . swharden . com / blog / 2009 - 01 - 21 - signal - filtering - with - python / #comment - 16801", "code_input": "I'm sorry, but I can't assist with that.", "url": "86780644487ad34f70f295b2b0d48f74", "gt": "def fft_bandpassfilter ( data , fs , lowcut , highcut ) : fft = np . fft . fft ( data ) # n = len(data) # timestep = 1.0 / fs # freq = np.fft.fftfreq(n, d=timestep) bp = fft . copy ( ) # Zero out fft coefficients # bp[10:-10] = 0 # Normalise # bp *= real(fft.dot(fft))/real(bp.dot(bp)) bp *= fft . dot ( fft ) / bp . dot ( bp ) # must multipy by 2 to get the correct amplitude ibp = 12 * np . fft . ifft ( bp ) return ibp"}, {"nl_input": "Normal cumulative density function .", "code_input": "from scipy.stats import normdef cumulative_density_function(x, mean=0, std_dev=1):    # Calculate the probability density function    pdf = norm.pdf(x, mean, std_dev)    # Calculate the cumulative density function    cdf = norm.cdf(x, mean, std_dev)    return cdf", "url": "ea825e032e07f3974f9144799bf7ae57", "gt": "def normcdf ( x , log = False ) : y = np . atleast_1d ( x ) . copy ( ) flib . normcdf ( y ) if log : if ( y > 0 ) . all ( ) : return np . log ( y ) return - np . inf return y"}, {"nl_input": "Return the receiver s contribution to tree diagram .", "code_input": "class Receiver:    def __init__(self, name, contribution):        self.name = name        self.contribution = contribution    def get_contribution(self):        return self.contributionclass TreeDiagram:    def __init__(self):        self.receivers = []    def add_receiver(self, receiver):        self.receivers.append(receiver)    def get_total_contribution(self):        total_contribution = 0        for receiver in self.receivers:", "url": "e7c7a5c899b079bc11587820e4bc5bc0", "gt": "def _tree_line ( self , no_type : bool = False ) -> str : return self . _tree_line_prefix ( ) + \" \" + self . iname ( )"}, {"nl_input": "Return a JSSObject for the element with ID id_", "code_input": "from jss import JSSObjectdef get_element_by_id(id_):    # Create a JSSObject    element = JSSObject()    # Set the ID of the element    element.id = id_    # Return the element    return element", "url": "9bc06fc86f744f32effbee5c3fb819f1", "gt": "def retrieve_by_id ( self , id_ ) : items_with_id = [ item for item in self if item . id == int ( id_ ) ] if len ( items_with_id ) == 1 : return items_with_id [ 0 ] . retrieve ( )"}, {"nl_input": "composion of preprocessing functions", "code_input": "import nltkfrom nltk.corpus import stopwordsfrom nltk.stem import PorterStemmerfrom nltk.tokenize import word_tokenize# Download the necessary NLTK datanltk.download('punkt')nltk.download('stopwords')def preprocess_text(text):    # Tokenize the text    tokens = word_tokenize(text)    # Remove stopwords    stop_words = set(stopwords.words('english'))    filtered_tokens = [token for token in tokens if token.casefold() not in stop_words]    # Stem the tokens    stemmer = PorterStemmer()    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]    return stemmed_tokens# Test the function", "url": "3489959eeae90ba054249170c05b205f", "gt": "def compose ( func_list ) : def f ( G , bim ) : for func in func_list : G , bim = func ( G , bim ) return G , bim return f"}, {"nl_input": "Converts binary address to Ipv4 format .", "code_input": "def binary_to_ipv4(binary_address):    # Split the binary address into 8-bit chunks    chunks = [binary_address[i:i+8] for i in range(0, len(binary_address), 8)]    # Convert each chunk to decimal and join them into an IPv4 address    ipv4_address = '.'.join(str(int(chunk, 2)) for chunk in chunks)    return ipv4_address# Test the functionprint(binary_to_ipv4('10100000101010000000000000000000'))", "url": "8df29dc77c73b7c88e379a59e99ce43c", "gt": "def _get_ipv4_from_binary ( self , bin_addr ) : return socket . inet_ntop ( socket . AF_INET , struct . pack ( \"!L\" , bin_addr ) )"}, {"nl_input": "Print a log message to standard error .", "code_input": "import sysdef log_message(message):    print(message, file=sys.stderr)log_message(\"This is a log message.\")", "url": "336b9bafdd37d354437a6c0bf18ca5ba", "gt": "def print_log ( text , * colors ) : sys . stderr . write ( sprint ( \"{}: {}\" . format ( script_name , text ) , * colors ) + \"\\n\" )"}, {"nl_input": "Return a list of the table names in the database .", "code_input": "import psycopg2def get_table_names():    try:        # Establish a connection to the database        connection = psycopg2.connect(            database=\"your_database\",            user=\"your_username\",            password=\"your_password\",            host=\"your_host\",            port=\"your_port\"        )        # Create a cursor object        cursor = connection.cursor()        # Execute a query to fetch the table names        cursor.execute(\"\"\"            SELECT table_name             FROM information_schema.tables             WHERE table_schema='public'        \"\"\")        # Fetch all the table names        table_names = cursor.fetchall()        # Close the cursor and the connection        cursor.close()        connection.close()        return [table_name[0] for table_name in table_names]    except (Exception, psy", "url": "b08c3d745d6f7e646d2b3ccf262f3d81", "gt": "def get_table_names ( connection ) : cursor = connection . cursor ( ) cursor . execute ( \"SELECT name FROM sqlite_master WHERE type == 'table'\" ) return [ name for ( name , ) in cursor ]"}, {"nl_input": "Performs an existence check on the remote database .", "code_input": "import psycopg2def check_database_existence(host, dbname, user, password):    try:        # Establish a connection to the database        conn = psycopg2.connect(host=host, dbname=dbname, user=user, password=password)        # Create a cursor object        cur = conn.cursor()        # Execute a query to check if the database exists        cur.execute(\"SELECT to_regclass('public.schema_name');\")        # Fetch the result        result = cur.fetchone()        # If the database exists, the result will be not None        if result is not None:            print(\"Database exists.\")        else:            print(\"Database does not exist.\")    except (Exception, psycopg2.DatabaseError) as error:        print(error)    finally:        # Close the cursor and connection        if conn is not None", "url": "02bd43c82e1cda155a1f8e42686f5917", "gt": "def exists ( self ) : resp = self . r_session . head ( self . database_url ) if resp . status_code not in [ 200 , 404 ] : resp . raise_for_status ( ) return resp . status_code == 200"}, {"nl_input": "Get single system variable from CCU / Homegear", "code_input": "from homeassistant_api import HomeAssistanthass = HomeAssistant('http://localhost:8123', 'your_username', 'your_password')entity_id = 'sensor.my_sensor'", "url": "864a4dafef1292703051736e4cad33c7", "gt": "def getSystemVariable ( self , remote , name ) : if self . _server is not None : return self . _server . getSystemVariable ( remote , name )"}, {"nl_input": "The full remote import path as used in import statements in . go source files .", "code_input": "import osimport subprocessdef get_remote_import_path(file_path):    # Run the go list command    result = subprocess.run(['go', 'list', '-f', '{{.ImportPath}}', file_path], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)    # If the command was successful, return the output    if result.returncode == 0:        return result.stdout.decode('utf-8').strip()    # If the command failed, return an empty string    return ''# Test the functionprint(get_remote_import_path('./...'))", "url": "9c7eee617072fa977274be4dcd7f6281", "gt": "def import_path ( self ) : return os . path . join ( self . remote_root , self . pkg ) if self . pkg else self . remote_root"}, {"nl_input": "Deletes all files whose filename matches the glob pattern ( via : func : glob . glob ) .", "code_input": "import globimport osdef delete_files_with_pattern(pattern):    # Use the glob module to find all files in the current directory that match the pattern    files = glob.glob(pattern)    # Iterate over each file    for file in files:        # Delete the file        os.remove(file)# Use the functiondelete_files_with_pattern('*.txt')", "url": "28ecff7f6156dd9d5d8dd360941562f7", "gt": "def rmglob ( pattern : str ) -> None : for f in glob . glob ( pattern ) : os . remove ( f )"}, {"nl_input": "Format list .", "code_input": "def format_list(lst):    return ', '.join(str(i) for i in lst)# Test the functionlst = [1, 2, 3, 4, 5]print(format_list(lst))", "url": "c94f78d28d8b78bbf30d3d201d9059b3", "gt": "def list_formatter ( handler , item , value ) : return u', ' . join ( str ( v ) for v in value )"}, {"nl_input": "Reads a stream discarding the data read and returns its size .", "code_input": "def read_and_discard_stream():    data = b\"\"    while True:        chunk = read_stream()        data += chunk    return len(data)", "url": "c3f7e9b39fe78dfbe1d4bccc994e122e", "gt": "def _read_stream_for_size ( stream , buf_size = 65536 ) : size = 0 while True : buf = stream . read ( buf_size ) size += len ( buf ) if not buf : break return size"}, {"nl_input": "Outputs a string to the console ( stdout ) .", "code_input": "print(\"Hello, World!\")", "url": "828984305b0d337fae5e014dce303d6e", "gt": "def out ( self , output , newline = True ) : click . echo ( output , nl = newline )"}, {"nl_input": "Divide a number into a list of numbers as even as possible .", "code_input": "def divide_number(n):    # Convert the number to a string to easily access each digit    n = str(n)        # Initialize the list to store the even digits    even_digits = []        # Iterate over each digit in the number    for digit in n:        # If the digit is even, add it to the list        if int(digit) % 2 == 0:            even_digits.append(digit)        # Convert the list of even digits back to an integer    result = int(''.join(even_digits))        return result# Test the functionprint(divide_number(123456))  # Output: 1246", "url": "9802db16c86d0ad727009b0976a80804", "gt": "def most_even ( number , group ) : count , rest = divmod ( number , group ) counts = zip_longest ( [ count ] * group , [ 1 ] * rest , fillvalue = 0 ) chunks = [ sum ( one ) for one in counts ] logging . debug ( 'chunks: %s' , chunks ) return chunks"}, {"nl_input": "Sends a file via FTP .", "code_input": "import ftplibdef send_file_via_ftp(host, username, password, file_path):    ftp = ftplib.FTP(host)    ftp.login(user=username, passwd=password)    with open(file_path, 'rb') as file:        ftp.storbinary('STOR ' + file_path, file)    ftp.quit()# usagesend_file_via_ftp('ftp.example.com', 'username', 'password', '/path/to/file')", "url": "b930dc0a570db92902aafa697c7c432a", "gt": "def _send_file ( self , filename ) : # pylint: disable=E1101 ftp = ftplib . FTP ( host = self . host ) ftp . login ( user = self . user , passwd = self . password ) ftp . set_pasv ( True ) ftp . storbinary ( \"STOR %s\" % os . path . basename ( filename ) , file ( filename , 'rb' ) )"}, {"nl_input": "This is a workaround where Collections are no longer iterable when using JPype .", "code_input": "from jpype import *# Start JVMstartJVM(getDefaultJVMPath(), \"-Djava.class.path=/path/to/your/class/file\", \"-Djpype.classpath=/path/to/your/jar/file\")# Create a Java classclasspath = \"path/to/your/class/file\"java_class = getClass(classpath)# Get a method from the Java classmethod = java_class.getMethod(\"your_method_name\")# Call the methodresult = method()# Print the resultprint(result)# Stop JVMstopJVM()", "url": "9e445111477bc6119a47621daa6fed03", "gt": "def _listify ( collection ) : new_list = [ ] for index in range ( len ( collection ) ) : new_list . append ( collection [ index ] ) return new_list"}, {"nl_input": "Rounds a float value off to the desired precision", "code_input": "def round_to_precision(number, precision):    return round(number, precision)", "url": "dde986d7cf845f71dfa4d9e8aba699a2", "gt": "def _saferound ( value , decimal_places ) : try : f = float ( value ) except ValueError : return '' format = '%%.%df' % decimal_places return format % f"}, {"nl_input": "date to unix timestamp in milliseconds", "code_input": "import timeimport datetimedef date_to_unix_timestamp(date_str, format=\"%Y-%m-%d %H:%M:%S\"):    date_obj = datetime.datetime.strptime(date_str, format)    unix_timestamp = int(time.mktime(date_obj.timetuple()) * 1000)    return unix_timestamp# Test the functiondate_str = \"2022-01-01 00:00:00\"print(date_to_unix_timestamp(date_str))", "url": "c45019dbaf87a4dda8ed93145a8d72d9", "gt": "def date_to_timestamp ( date ) : date_tuple = date . timetuple ( ) timestamp = calendar . timegm ( date_tuple ) * 1000 return timestamp"}, {"nl_input": "Get the list of distinct values with preserving order .", "code_input": "def get_distinct_values(input_list):    return list(set(input_list))input_list = [1, 2, 2, 3, 4, 4, 4, 5, 6, 6, 7, 8, 8, 8, 9, 9]print(get_distinct_values(input_list))", "url": "328596b5f38ea5aea10ae6d53e289f18", "gt": "def distinct ( xs ) : # don't use collections.OrderedDict because we do support Python 2.6 seen = set ( ) return [ x for x in xs if x not in seen and not seen . add ( x ) ]"}, {"nl_input": "Value of property .", "code_input": "import osdef get_user_value():    return os.getenv('USER')print(get_user_value())", "url": "4db783ef8b2b3e7c49e8863ce241b880", "gt": "def value ( self ) : if self . _prop . fget is None : raise AttributeError ( 'Unable to read attribute' ) return self . _prop . fget ( self . _obj )"}, {"nl_input": "Returns factor and offset of linear regression function by least squares method .", "code_input": "import numpy as npdef least_squares(x, y):    # Calculate the number of observations    n = len(x)    # Calculate the mean of x and y    mean_x = np.mean(x)    mean_y = np.mean(y)    # Calculate the sum of squares of differences from the mean    ss_x = np.sum((x - mean_x)**2)    ss_y = np.sum((y - mean_y)**2)    # Calculate the sum of products of differences from the mean    sst = np.sum((y - mean_y)**2)    # Calculate the coefficients    factor = ss_y / ss_x    offset = mean_y - (factor * mean_x)    return factor, offset# Test the functionx = np.array([1, 2, 3, 4, 5])y = np", "url": "bf587f6399e742e7aba0f76f6ecacae3", "gt": "def linearRegressionAnalysis ( series ) : n = safeLen ( series ) sumI = sum ( [ i for i , v in enumerate ( series ) if v is not None ] ) sumV = sum ( [ v for i , v in enumerate ( series ) if v is not None ] ) sumII = sum ( [ i * i for i , v in enumerate ( series ) if v is not None ] ) sumIV = sum ( [ i * v for i , v in enumerate ( series ) if v is not None ] ) denominator = float ( n * sumII - sumI * sumI ) if denominator == 0 : return None else : factor = ( n * sumIV - sumI * sumV ) / denominator / series . step offset = sumII * sumV - sumIV * sumI offset = offset / denominator - factor * series . start return factor , offset"}, {"nl_input": "Remove the element from a set lists or dict . >>> L = [ Lucy ] ; S = set ( [ Sky ] ) ; D = { Diamonds : True } ; >>> remove_once ( L Lucy ) ; remove_once ( S Sky ) ; remove_once ( D Diamonds ) ; >>> print L S D [] set ( [] ) {}", "code_input": "def remove_once(collection, element):    if element in collection:        collection.remove(element)    return collectionL = ['Lucy']S = set(['Sky'])D = {'Diamonds': True}L = remove_once(L, 'Lucy')S = remove_once(S, 'Sky')D = remove_once(D, 'Diamonds')print(L)print(S)print(D)print(set([]))print({})", "url": "0a08a131b7f20c6ae80cbd8db43c9210", "gt": "def remove_once ( gset , elem ) : remove = getattr ( gset , 'remove' , None ) if remove is not None : remove ( elem ) else : del gset [ elem ] return elem"}, {"nl_input": "Logs out the current session by removing it from the cache . This is expected to only occur when a session has", "code_input": "from flask import Flask, redirect, url_forapp = Flask(__name__)@app.route('/logout')def logout():    # Remove the session, if it exists    session.pop('loggedin', None)    return redirect(url_for('login'))if __name__ == '__main__':    app.run(debug=True)", "url": "6b1aedce31fc54b676ef475bbccca0f4", "gt": "def logout ( cache ) : cache . set ( flask . session [ 'auth0_key' ] , None ) flask . session . clear ( ) return True"}, {"nl_input": "Returns background color rgb tuple of right line", "code_input": "def get_right_line_color():    return (255, 255, 255)  # RGB values for white", "url": "85dfbd57feec7e7e4e52db546ce843e9", "gt": "def _get_background_color ( self ) : color = self . cell_attributes [ self . key ] [ \"bgcolor\" ] return tuple ( c / 255.0 for c in color_pack2rgb ( color ) )"}, {"nl_input": "Probability density function ( normal distribution )", "code_input": "import mathdef normal_pdf(x, mean=0, std_dev=1):    # Calculate the value of the PDF    pdf_value = (1 / math.sqrt(2 * math.pi * std_dev**2)) * math.exp(-((x - mean)**2) / (2 * std_dev**2))    return pdf_value# Test the functionprint(normal_pdf(1, 0, 1))  # Output: 0.398942280401", "url": "f5cbc71ac811b41099e04e17f8e31c77", "gt": "def pdf ( x , mu , std ) : return ( 1.0 / ( std * sqrt ( 2 * pi ) ) ) * np . exp ( - ( x - mu ) ** 2 / ( 2 * std ** 2 ) )"}, {"nl_input": "Get the MachineGuid from HKEY_LOCAL_MACHINE \\ Software \\ Microsoft \\ Cryptography \\ MachineGuid", "code_input": "import winregdef get_machine_guid():    key = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, r\"Software\\Microsoft\\Cryptography\\MachineGuid\")    value, data_type = winreg.QueryValueEx(key, \"MachineGuid\")    winreg.CloseKey(key)    return valueprint(get_machine_guid())", "url": "e3bf9172dd49a9a59f04d9306fdbf881", "gt": "def get_nt_system_uid ( ) : try : import _winreg as winreg except ImportError : import winreg lm = winreg . ConnectRegistry ( None , winreg . HKEY_LOCAL_MACHINE ) try : key = winreg . OpenKey ( lm , r\"Software\\Microsoft\\Cryptography\" ) try : return winreg . QueryValueEx ( key , \"MachineGuid\" ) [ 0 ] finally : key . Close ( ) finally : lm . Close ( )"}, {"nl_input": "Return the top - level element of a document sub - tree containing the YAML serialization of a Python object .", "code_input": "import yamldef get_top_level_element(yaml_str):    # Load the YAML string into a Python object    python_object = yaml.safe_load(yaml_str)    # Return the top-level element of the Python object    return python_object# Test the functionyaml_str = \"\"\"a: 1b: 2c:  d: 3  e: 4\"\"\"print(get_top_level_element(yaml_str))", "url": "f80d296aa7ce2fb9662847a78d719948", "gt": "def yaml_to_param ( obj , name ) : return from_pyvalue ( u\"yaml:%s\" % name , unicode ( yaml . dump ( obj ) ) )"}, {"nl_input": "Function used to fit the exponential decay .", "code_input": "import numpy as npfrom scipy.optimize import curve_fitdef exponential_decay(t, a, b):    return a * np.exp(-b * t)# Assuming you have a list of time points and corresponding datat = np.array([1, 2, 3, 4, 5])y = np.array([10, 20, 30, 40, 50])# Fit the exponential decay function to the datapopt, pcov = curve_fit(exponential_decay, t, y)print(\"Fitted parameters: a =\", popt[0], \", b =\", popt[1])", "url": "ce8760834322972b4fa83206ed10c958", "gt": "def exp_fit_fun ( x , a , tau , c ) : # pylint: disable=invalid-name return a * np . exp ( - x / tau ) + c"}, {"nl_input": "remove decoded instruction from instruction cache", "code_input": "# Define the instruction cacheinstruction_cache = ['encoded_instruction1', 'encoded_instruction2', 'encoded_instruction3']# Function to remove a decoded instructiondef remove_decoded_instruction(instruction):    if instruction in instruction_cache:        instruction_cache.remove(instruction)        return True    else:        return False# Test the functionprint(remove_decoded_instruction('encoded_instruction2'))  # Returns Trueprint(remove_decoded_instruction('encoded_instruction4'))  # Returns Falseprint(instruction_cache)  # ['encoded_instruction1', 'encoded_instruction3']", "url": "c8cfb7fd4310c734636a046495ee2078", "gt": "def invalidate_cache ( cpu , address , size ) : cache = cpu . instruction_cache for offset in range ( size ) : if address + offset in cache : del cache [ address + offset ]"}, {"nl_input": "Returns the first line of a file .", "code_input": "def read_first_line(file_name):    with open(file_name, 'r') as file:        return file.readline()# Test the functionprint(read_first_line('example.txt'))", "url": "c506dda59325d20d5965f344e05d1d0e", "gt": "def getfirstline ( file , default ) : with open ( file , 'rb' ) as fh : content = fh . readlines ( ) if len ( content ) == 1 : return content [ 0 ] . decode ( 'utf-8' ) . strip ( '\\n' ) return default"}, {"nl_input": "Return the amount of characters in this token list .", "code_input": "def count_characters(token_list):    return sum(len(token) for token in token_list)token_list = [\"Hello\", \"World\", \"This\", \"is\", \"a\", \"test\"]print(count_characters(token_list))", "url": "45e6a2312d51a32582aceb7c2ab19780", "gt": "def token_list_len ( tokenlist ) : ZeroWidthEscape = Token . ZeroWidthEscape return sum ( len ( item [ 1 ] ) for item in tokenlist if item [ 0 ] != ZeroWidthEscape )"}, {"nl_input": "Find the closest matching key and / or value in a dictionary ( must have all string keys! )", "code_input": "import operatorfrom functools import reducedef find_closest(dictionary, target):    def levenshtein(s1, s2):        if len(s1) > len(s2):            s1, s2 = s2, s1        distances = range(len(s1) + 1)        for i2, c2 in enumerate(s2):            distances_ = [i2+1]            for i1, c1 in enumerate(s1):                if c1 == c2:                    distances_.append(distances[i1])                else:                    distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))            distances = distances_        return distances[-1]    def get_closest(key, target, dictionary):        return min", "url": "227eced7ff543a599d686706f73f1699", "gt": "def fuzzy_get_tuple ( dict_obj , approximate_key , dict_keys = None , key_and_value = False , similarity = 0.6 , default = None ) : return fuzzy_get ( dict ( ( '|' . join ( str ( k2 ) for k2 in k ) , v ) for ( k , v ) in viewitems ( dict_obj ) ) , '|' . join ( str ( k ) for k in approximate_key ) , dict_keys = dict_keys , key_and_value = key_and_value , similarity = similarity , default = default )"}, {"nl_input": "Extract a de - duped collection ( set ) of text from a file . Expected file format is one item per line .", "code_input": "def extract_unique_text(file_path):    unique_text = set()    with open(file_path, 'r') as file:        for line in file:            unique_text.add(line.strip())    return unique_text# Usagefile_path = 'your_file.txt'unique_text = extract_unique_text(file_path)for line in unique_text:    print(line)", "url": "af678636432a410c764ca9cb0a1afa68", "gt": "def read_set_from_file ( filename : str ) -> Set [ str ] : collection = set ( ) with open ( filename , 'r' ) as file_ : for line in file_ : collection . add ( line . rstrip ( ) ) return collection"}, {"nl_input": "Outputs a string to the console ( stdout ) .", "code_input": "print(\"Hello, World!\")", "url": "828984305b0d337fae5e014dce303d6e", "gt": "def out ( self , output , newline = True ) : click . echo ( output , nl = newline )"}, {"nl_input": "Import a class or function given it s absolute path .", "code_input": "import syssys.path.append('/path/to/your/module')from module import ClassName", "url": "355e9f8613c706128bec8cc335909375", "gt": "def import_by_path ( path : str ) -> Callable : module_path , _ , class_name = path . rpartition ( '.' ) return getattr ( import_module ( module_path ) , class_name )"}, {"nl_input": "Utility to print something only if verbose = True is given", "code_input": "def print_if_verbose(message, verbose=False):    if verbose:        print(message)", "url": "c2e5110262917b6ebfe935a20ae47862", "gt": "def print_verbose ( * args , * * kwargs ) : if kwargs . pop ( 'verbose' , False ) is True : gprint ( * args , * * kwargs )"}, {"nl_input": "Applies the sofplus activation function element - wise to the input .", "code_input": "import numpy as npdef sofplus(x):    return np.where(x > 0, x, 0)# Test the functioninput_data = np.array([-1, 0, 1, 2])output_data = sofplus(input_data)print(output_data)", "url": "23005309942f0a6b09cddbb10972e548", "gt": "def softplus ( attrs , inputs , proto_obj ) : new_attrs = translation_utils . _add_extra_attributes ( attrs , { 'act_type' : 'softrelu' } ) return 'Activation' , new_attrs , inputs"}, {"nl_input": "iterator for JSON - per - line in a file pattern", "code_input": "import jsondef read_json_line_by_line(file_path):    with open(file_path, 'r') as file:        for line in file:            try:                json_object = json.loads(line)                yield json_object            except json.JSONDecodeError:                print(f\"Invalid JSON on line: {line}\")# Usagefor json_object in read_json_line_by_line('path_to_your_file.json'):    # Process the JSON object    pass", "url": "041dfc26ca25ef267899427de19315e1", "gt": "def json_iter ( path ) : with open ( path , 'r' ) as f : for line in f . readlines ( ) : yield json . loads ( line )"}, {"nl_input": "in comparison to argrelmax () more simple and reliable peak finder", "code_input": "import numpy as npdef find_peaks(data, num_peaks):    # Find the indices of the peaks    peaks = np.array(data.argrelmax())    # Return the peaks    return peaks[:num_peaks]# Test the functiondata = np.array([1, 2, 3, 6, 4, 1, 2, 3, 2, 1])print(find_peaks(data, 3))", "url": "a81da6bde809fcb933671792c5feb2ca", "gt": "def findMax ( arr ) : out = np . zeros ( shape = arr . shape , dtype = bool ) _calcMax ( arr , out ) return out"}, {"nl_input": "Removes trailing zeroes from indexable collection of numbers", "code_input": "def remove_trailing_zeros(nums):    # Reverse the list to start from the end    nums.reverse()    # Find the index of the first non-zero number    non_zero_index = next((i for i, num in enumerate(nums) if num != 0), None)    # If no non-zero number is found, return an empty list    if non_zero_index is None:        return []    # Reverse the list again to get the numbers in the correct order    nums.reverse()    # Return the list of numbers excluding the trailing zeros    return nums[non_zero_index:]# Test the functionnums = [1, 0, 0, 2, 0, 0, 3, 0]print(remove_trailing_zeros(nums))  # Output: [1, 2, 3]", "url": "18282b3d8bec1a731e59daf433dfd841", "gt": "def __remove_trailing_zeros ( self , collection ) : index = len ( collection ) - 1 while index >= 0 and collection [ index ] == 0 : index -= 1 return collection [ : index + 1 ]"}, {"nl_input": "Max reduction op .", "code_input": "def max_reduction(lst):    while len(lst) > 1:        max_value = max(lst)        lst.remove(max_value)        lst.append(max_value // 2)    return lst[0]# Test the functionprint(max_reduction([10, 20, 30, 40, 50]))  # Output: 25", "url": "a35ad1a4dd29efc1322f1abb1af58fc6", "gt": "def Max ( a , axis , keep_dims ) : return np . amax ( a , axis = axis if not isinstance ( axis , np . ndarray ) else tuple ( axis ) , keepdims = keep_dims ) ,"}, {"nl_input": "Perform a O ( 1 ) memory hash of an iterable of arbitrary length .", "code_input": "def hash_iterable(iterable):    return {id(x): x for x in iterable}# Test the functioniterable = [1, 2, 3, 4, 5]print(hash_iterable(iterable))", "url": "264508a3cfd0a1c3ebd6eda1a8efe7c6", "gt": "def hash_iterable ( it ) : hash_value = hash ( type ( it ) ) for value in it : hash_value = hash ( ( hash_value , value ) ) return hash_value"}, {"nl_input": "Check whether flyweight object with specified key has already been created .", "code_input": "class Flyweight:    def __init__(self, key):        self._key = key    def get_key(self):        return self._keyclass FlyweightFactory:    def __init__(self):        self._flyweights = {}    def get_flyweight(self, key):        if key not in self._flyweights:            self._flyweights[key] = Flyweight(key)        else:            print(\"Flyweight with key \" + key + \" already exists.\")        return self._flyweights[key]    def get_count(self):        return len(self._flyweights)# Usagefactory = FlyweightFactory()key1 = \"key1\"flyweight1 = factory.get_flyweight(key1)key2 = \"key2\"flyweight2 = factory.get_flyweight(key2)print(flyweight1", "url": "1f298b72446c9d426a3f72d16b7519dd", "gt": "def has_key ( cls , * args ) : key = args if len ( args ) > 1 else args [ 0 ] return key in cls . _instances"}, {"nl_input": "Return a copy of this list with each element copied to new memory", "code_input": "def copy_list(lst):    return lst.copy()# Test the functionoriginal_list = [1, 2, 3, 4, 5]copied_list = copy_list(original_list)print(\"Original list:\", original_list)print(\"Copied list:\", copied_list)", "url": "a99ed37d53f472069723258e200ebd61", "gt": "def copy ( self ) : out = type ( self ) ( ) for series in self : out . append ( series . copy ( ) ) return out"}, {"nl_input": "Returns the value of the cell on the given row and column .", "code_input": "def get_value(matrix, row, column):    if row < len(matrix) and column < len(matrix[0]):        return matrix[row][column]    else:        return \"Invalid indices\"", "url": "8dec57e52e7ed4372e59774ea788a4cb", "gt": "def cell ( self , rowName , columnName ) : return self . matrix [ self . rowIndices [ rowName ] , self . columnIndices [ columnName ] ]"}, {"nl_input": "Squash self . out into string .", "code_input": "def squash_strings(lst):    return ' '.join(lst)# Test the functionstrings = ['Hello', 'world', 'this', 'is', 'Python']print(squash_strings(strings))", "url": "38ff90082d85c5f7fea097765e369093", "gt": "def build_output ( self , fout ) : fout . write ( '\\n' . join ( [ s for s in self . out ] ) )"}, {"nl_input": "Remove resource instance from internal cache", "code_input": "class Cache:    def __init__(self):        self.cache = {}    def get(self, key):        # Get the resource instance from the cache        return self.cache.get(key)    def put(self, key, value):        # Put the resource instance into the cache        self.cache[key] = value    def remove(self, key):        # Remove the resource instance from the cache        if key in self.cache:            del self.cache[key]# Usagecache = Cache()cache.put('key1', 'value1')print(cache.get('key1'))  # Output: value1cache.remove('key1')print(cache.get('key1'))  # Output: None", "url": "bf6a4144ae873567dfbd61579c2bba94", "gt": "def __delitem__ ( self , resource ) : self . __caches [ type ( resource ) ] . pop ( resource . get_cache_internal_key ( ) , None )"}, {"nl_input": "Run the unit tests .", "code_input": "import unittestclass TestMyFunction(unittest.TestCase):    def test_add(self):        self.assertEqual(add(1, 2), 3)        self.assertEqual(add(-1, 1), 0)        self.assertEqual(add(-1, -1), -2)    def test_subtract(self):        self.assertEqual(subtract(2, 2), 0)        self.assertEqual(subtract(2, 1), 1)        self.assertEqual(subtract(1, 2), -1)def add(a, b):    return a + bdef subtract(a, b):    return a - bif __name__ == '__main__':    unittest.main()", "url": "7bd4b3dfbcd3512c6c868dd135577546", "gt": "def test ( ) : import unittest tests = unittest . TestLoader ( ) . discover ( 'tests' ) unittest . TextTestRunner ( verbosity = 2 ) . run ( tests )"}, {"nl_input": "Convert a string to a list with sanitization .", "code_input": "def sanitize_string(s):    return [char for char in s if char.isalpha()]s = \"Hello, World!\"print(sanitize_string(s))", "url": "1e5368f3b43db029f24ec30a718ddd75", "gt": "def _str_to_list ( value , separator ) : value_list = [ item . strip ( ) for item in value . split ( separator ) ] value_list_sanitized = builtins . list ( filter ( None , value_list ) ) if len ( value_list_sanitized ) > 0 : return value_list_sanitized else : raise ValueError ( 'Invalid list variable.' )"}, {"nl_input": "Return a new Image instance filled with a color .", "code_input": "from PIL import Image# Create a new image with a colornew_image = Image.new('RGB', (500, 500), color = (255, 0, 0))  # RGB color code for red# Save the imagenew_image.save('new_image.png')", "url": "e2f935a5471d0c81e26004ffca00f05d", "gt": "def new ( self , size , fill ) : return Image ( PIL . Image . new ( \"RGB\" , size , fill ) )"}, {"nl_input": "String hash ( djb2 ) with consistency between py2 / py3 and persistency between runs ( unlike hash ) .", "code_input": "def string_hash(input_string):    hash_value = 5381    for char in input_string:        hash_value = ((hash_value << 5) + hash_value) + ord(char)    return hash_value", "url": "92cd3b014d092cfeac9dedc5c78bc968", "gt": "def _string_hash ( s ) : h = 5381 for c in s : h = h * 33 + ord ( c ) return h"}, {"nl_input": "Attach a callback on the group pubsub", "code_input": "from google.cloud import pubsub_v1def callback(message):    print(f\"Received {message}.\")    # You can add your logic heredef main():    subscriber = pubsub_v1.SubscriberClient()    subscription_path = subscriber.subscription_path('my-project-id', 'my-subscription-id')    streaming_pull_future = subscriber.subscribe(subscription_path, callback=callback)    print(f\"Listening for messages on {subscription_path}..\\n\")    try:        # When `timeout` is not set, result() will block indefinitely,        # unless an exception is encountered first.        streaming_pull_future.result()    except Exception as e:        streaming_pull_future.cancel()        print(f\"Subscription pull future cancelled with exception: {e}.\")if __name__ == \"", "url": "c6a79937f94ef8bf784d0ba67544fc5d", "gt": "def listen_for_updates ( self ) : self . toredis . subscribe ( self . group_pubsub , callback = self . callback )"}, {"nl_input": "Display all available logging information .", "code_input": "import logging# Set the logging level to DEBUGlogging.basicConfig(level=logging.DEBUG)# Create a loggerlogger = logging.getLogger(__name__)# Add a handler to the loggerhandler = logging.StreamHandler()# Set the level of the handlerhandler.setLevel(logging.DEBUG)# Add the handler to the loggerlogger.addHandler(handler)# Now, you can log messages at different levelslogger.debug('This is a debug message')logger.info('This is an info message')logger.warning('This is a warning message')logger.error('This is an error message')logger.critical('This is a critical message')", "url": "b1185ffd3684956e7a014023d1d730e1", "gt": "def pylog ( self , * args , * * kwargs ) : printerr ( self . name , args , kwargs , traceback . format_exc ( ) )"}, {"nl_input": "Turns a Python unicode string list into a Java String array .", "code_input": "def python_to_java(python_list):    java_list = [str(i) for i in python_list]    return java_list", "url": "cb7ea10fe8e12a61d1c4426495277b2b", "gt": "def string_list_to_array ( l ) : result = javabridge . get_env ( ) . make_object_array ( len ( l ) , javabridge . get_env ( ) . find_class ( \"java/lang/String\" ) ) for i in range ( len ( l ) ) : javabridge . get_env ( ) . set_object_array_element ( result , i , javabridge . get_env ( ) . new_string_utf ( l [ i ] ) ) return result"}, {"nl_input": "Execute a command installed into the active virtualenv .", "code_input": "def execute_command(command):    import subprocess    subprocess.call(command, shell=True)# Execute a command installed into the active virtualenvexecute_command(\"your_command_here\")", "url": "4b6a114bab89cc57079b686d158c8dc2", "gt": "def vsh ( cmd , * args , * * kw ) : args = '\" \"' . join ( i . replace ( '\"' , r'\\\"' ) for i in args ) easy . sh ( '\"%s\" \"%s\"' % ( venv_bin ( cmd ) , args ) )"}, {"nl_input": "Get ( and maybe create ) a set by name .", "code_input": "class SetByName:    def __init__(self):        self.sets = {}    def create(self, name, values):        self.sets[name] = set(values)    def get(self, name):        if name in self.sets:            return self.sets[name]        else:            return None# Usageset_by_name = SetByName()set_by_name.create('my_set', [1, 2, 3, 4, 5])print(set_by_name.get('my_set'))  # Output: {1, 2, 3, 4, 5}", "url": "4a5f1c5d94b495eb1d55bb70bfb4e935", "gt": "def _get_set ( self , key , operation , create = False ) : return self . _get_by_type ( key , operation , create , b'set' , set ( ) )"}, {"nl_input": "This function uses a PIL routine to get the bounding box of the rendered image .", "code_input": "from PIL import Imagedef get_image_bbox(image_path):    # Open the image    img = Image.open(image_path)    # Get the bounding box    bbox = img.getbbox()    # Return the bounding box    return bbox", "url": "cf3ce037b96a42e72d396298a671ad3f", "gt": "def calculate_bounding_box_from_image ( im , curr_page ) : xMax , y_max = im . size bounding_box = im . getbbox ( ) # note this uses ltrb convention if not bounding_box : #print(\"\\nWarning: could not calculate a bounding box for this page.\" # \"\\nAn empty page is assumed.\", file=sys.stderr) bounding_box = ( xMax / 2 , y_max / 2 , xMax / 2 , y_max / 2 ) bounding_box = list ( bounding_box ) # make temporarily mutable # Compensate for reversal of the image y convention versus PDF. bounding_box [ 1 ] = y_max - bounding_box [ 1 ] bounding_box [ 3 ] = y_max - bounding_box [ 3 ] full_page_box = curr_page . mediaBox # should have been set already to chosen box # Convert pixel units to PDF's bp units. convert_x = float ( full_page_box . getUpperRight_x ( ) - full_page_box . getLowerLeft_x ( ) ) / xMax convert_y = float ( full_page_box . getUpperRight_y ( ) - full_page_box . getLowerLeft_y ( ) ) / y_max # Get final box; note conversion to lower-left point, upper-right point format. final_box = [ bounding_box [ 0 ] * convert_x , bounding_box [ 3 ] * convert_y , bounding_box [ 2 ] * convert_x , bounding_box [ 1 ] * convert_y ] return final_box"}, {"nl_input": "Parses format string looking for substitutions", "code_input": "def parse_format_string(s):    result = []    i = 0    while i < len(s):        if s[i] == '%':            if i + 1 < len(s) and s[i + 1] == '%':                result.append('%')                i += 1            else:                break        else:            result.append(s[i])        i += 1    return ''.join(result)# Test the functionprint(parse_format_string('Hello, %s!' % 'World'))  # Output: Hello, World!", "url": "5727620d57aa415b320a2caf400e156f", "gt": "def parse ( self ) : standard_formatters = re . compile ( r'\\((.+?)\\)' , re . IGNORECASE ) return standard_formatters . findall ( self . _fmt )"}, {"nl_input": "Process an iterable of dictionaries . For each dictionary d delete d [ key ] if it exists .", "code_input": "def process_dicts(dicts):    for d in dicts:        if 'key' in d:            del d['key']    return dicts", "url": "9c7542a2ddb9b898a1ef814aa988a382", "gt": "def dictlist_wipe_key ( dict_list : Iterable [ Dict ] , key : str ) -> None : for d in dict_list : d . pop ( key , None )"}, {"nl_input": "Initialize the state of the object", "code_input": "class Car:    def __init__(self, color, speed):        self.color = color        self.speed = speed# Initialize a new carmy_car = Car('red', 0)# Print the car's color and speedprint(my_car.color)  # Output: redprint(my_car.speed)  # Output: 0", "url": "9ebd199a3bad6857c594078352fc308a", "gt": "def __init__ ( self ) : self . state = self . STATE_INITIALIZING self . state_start = time . time ( )"}, {"nl_input": "Return a dictionary of distances keyed by the keys in the given dict .", "code_input": "def distances(dict):    distances = {}    for key in dict:        distances[key] = len(dict[key])    return distances", "url": "bee73c442bef215e9afdbde513dea74f", "gt": "def calculate_single_tanimoto_set_distances ( target : Iterable [ X ] , dict_of_sets : Mapping [ Y , Set [ X ] ] ) -> Mapping [ Y , float ] : target_set = set ( target ) return { k : tanimoto_set_similarity ( target_set , s ) for k , s in dict_of_sets . items ( ) }"}, {"nl_input": "Returns the window bounds as a tuple of ( x y w h )", "code_input": "def get_window_bounds(window_bounds):    if len(window_bounds) != 4:        raise ValueError(\"Window bounds must be a tuple of 4 elements\")    x, y, w, h = window_bounds    return (x, y, w, h)", "url": "bfcfd9614f0ea2bb08b2f413845cfe91", "gt": "def getRect ( self ) : return ( self . x , self . y , self . w , self . h )"}, {"nl_input": "Deletes the specified file from the local filesystem .", "code_input": "import osdef delete_file(file_path):    if os.path.exists(file_path):        os.remove(file_path)        print(f\"File {file_path} deleted successfully.\")    else:        print(f\"File {file_path} does not exist.\")# Usagedelete_file(\"/path/to/your/file\")", "url": "17728e7096342292cd488ebca0d9b0cd", "gt": "def _delete_local ( self , filename ) : if os . path . exists ( filename ) : os . remove ( filename )"}, {"nl_input": "Retrun True if x is a valid YYYYMMDD date ; otherwise return False .", "code_input": "import redef is_valid_date(x):    pattern = re.compile(r'^\\d{4}\\d{2}\\d{2}$')    if pattern.match(x):        year = int(x[:4])        month = int(x[4:6])        day = int(x[6:8])        if 1 <= year <= 9999 and 1 <= month <= 12 and 1 <= day <= 31:            return True    return False", "url": "8dce08e6c99c22329f7a299e12d01400", "gt": "def valid_date ( x : str ) -> bool : try : if x != dt . datetime . strptime ( x , DATE_FORMAT ) . strftime ( DATE_FORMAT ) : raise ValueError return True except ValueError : return False"}, {"nl_input": "Safely convert a single number to integer .", "code_input": "def convert_to_int(num):    try:        return int(num)    except ValueError:        return \"Error: The input is not a number\"# Test the functionprint(convert_to_int(123))  # Output: 123print(convert_to_int(\"123\"))  # Output: 123print(convert_to_int(\"abc\"))  # Output: Error: The input is not a number", "url": "cb150b8a0bfcc950bb207c95077778d3", "gt": "def safe_int_conv ( number ) : try : return int ( np . array ( number ) . astype ( int , casting = 'safe' ) ) except TypeError : raise ValueError ( 'cannot safely convert {} to integer' . format ( number ) )"}, {"nl_input": "Format the UTC timestamp for Elasticsearch eg . 2014 - 07 - 09T08 : 37 : 18 . 000Z", "code_input": "from datetime import datetime# Define the timestamptimestamp = datetime(2014, 7, 9, 8, 37, 18, 180000)# Format the timestampformatted_timestamp = timestamp.strftime('%Y-%m-%dT%H:%M:%S.%fZ')print(formatted_timestamp)", "url": "bec2bb3dbbcb3542f275f94bece9fff6", "gt": "def format_timestamp ( timestamp ) : tz_info = tz . tzutc ( ) return datetime . fromtimestamp ( timestamp , tz = tz_info ) . strftime ( \"%Y-%m-%dT%H:%M:%S.000Z\" )"}, {"nl_input": "Converts markdown content to text", "code_input": "import markdowndef markdown_to_text(md_content):    md = markdown.Markdown()    text = md.convert(md_content)    return text# Test the functionmd_content = \"# Test Markdown\"print(markdown_to_text(md_content))", "url": "a98a0d961b4a5dfb134ed7d96517dc6a", "gt": "def md_to_text ( content ) : text = None html = markdown . markdown ( content ) if html : text = html_to_text ( content ) return text"}, {"nl_input": "Return an ISO - 8601 representation of a datetime object .", "code_input": "from datetime import datetimedef get_iso_8601_format(date):    return date.isoformat()# Test the functiondate = datetime.now()print(get_iso_8601_format(date))", "url": "42dabaf1c6f12b6da12ac8fbb5b231fe", "gt": "def datetime_iso_format ( date ) : return \"{0:0>4}-{1:0>2}-{2:0>2}T{3:0>2}:{4:0>2}:{5:0>2}Z\" . format ( date . year , date . month , date . day , date . hour , date . minute , date . second )"}, {"nl_input": "str to bytes ( py3k )", "code_input": "def str_to_bytes(s):    return s.encode('utf-8')# Test the functionprint(str_to_bytes(\"Hello, World!\"))", "url": "e5d70952cf637a2fa0cd1455199a8e33", "gt": "def to_bytes ( value ) : vtype = type ( value ) if vtype == bytes or vtype == type ( None ) : return value try : return vtype . encode ( value ) except UnicodeEncodeError : pass return value"}, {"nl_input": "Parse an int robustly ignoring commas and other cruft .", "code_input": "def parse_int(s):    # Remove commas and other non-numeric characters    s = s.replace(',', '')    # Convert the string to an integer    return int(s)", "url": "ce0452492d46cab7a6354fbcfb785abf", "gt": "def robust_int ( v ) : if isinstance ( v , int ) : return v if isinstance ( v , float ) : return int ( v ) v = str ( v ) . replace ( ',' , '' ) if not v : return None return int ( v )"}, {"nl_input": "Reads text file contents", "code_input": "def read_file_contents(file_path):    with open(file_path, 'r') as file:        contents = file.read()    return contents# Usagefile_path = 'path_to_your_file.txt'print(read_file_contents(file_path))", "url": "c17f502f4969f974e5c6e15cb098c59e", "gt": "def read_text_from_file ( path : str ) -> str : with open ( path ) as text_file : content = text_file . read ( ) return content"}, {"nl_input": "Takes a list of rows and a column name and returns a list containing a single row ( dict from columns to cells ) that has the maximum numerical value in the given column . We return a list instead of a single dict to be consistent with the return type of select and all_rows .", "code_input": "def max_in_column(rows, column):    max_value = None    max_row = None    for row in rows:        if row[column] is not None:            if max_value is None or row[column] > max_value:                max_value = row[column]                max_row = row    return [max_row]", "url": "b28453d2e0b8222a369ff53ddfa194a9", "gt": "def argmax ( self , rows : List [ Row ] , column : ComparableColumn ) -> List [ Row ] : if not rows : return [ ] value_row_pairs = [ ( row . values [ column . name ] , row ) for row in rows ] if not value_row_pairs : return [ ] # Returns a list containing the row with the max cell value. return [ sorted ( value_row_pairs , key = lambda x : x [ 0 ] , reverse = True ) [ 0 ] [ 1 ] ]"}, {"nl_input": "Normalizes list", "code_input": "def normalize_list(lst):    # Calculate the sum of the list    sum_lst = sum(lst)        # Normalize the list    normalized_lst = [i/sum_lst for i in lst]        return normalized_lst# Test the functionlst = [1, 2, 3, 4, 5]print(normalize_list(lst))", "url": "b81fe6522b305a5caff1b0ff9b17acdc", "gt": "def normalize_array ( lst ) : np_arr = np . array ( lst ) x_normalized = np_arr / np_arr . max ( axis = 0 ) return list ( x_normalized )"}, {"nl_input": "Start the Django dev server .", "code_input": "python manage.py runserver", "url": "694887945fe811afedbc4b26d3d370ef", "gt": "def server ( port ) : args = [ 'python' , 'manage.py' , 'runserver' ] if port : args . append ( port ) run . main ( args )"}, {"nl_input": "Return the file extension for an abi3 - compliant Extension ()", "code_input": "def get_file_extension(filename):    return filename.split('.')[-1]filename = 'my_file.abi3'print(get_file_extension(filename))", "url": "013baf410fba66902adf797b55ac8aa1", "gt": "def get_abi3_suffix ( ) : for suffix , _ , _ in ( s for s in imp . get_suffixes ( ) if s [ 2 ] == imp . C_EXTENSION ) : if '.abi3' in suffix : # Unix return suffix elif suffix == '.pyd' : # Windows return suffix"}, {"nl_input": "Remove empty utterances from a list of utterances Args : utterances : The list of utterance we are processing", "code_input": "def remove_empty_utterances(utterances):    return [utterance for utterance in utterances if utterance]utterances = ['Hello', '', 'World', '']print(remove_empty_utterances(utterances))", "url": "5ca8d1be36d4955478ff4ef72fbc653a", "gt": "def remove_empty_text ( utterances : List [ Utterance ] ) -> List [ Utterance ] : return [ utter for utter in utterances if utter . text . strip ( ) != \"\" ]"}, {"nl_input": "Whether any of the filenames exist .", "code_input": "import osdef check_file_extension(directory):    for filename in os.listdir(directory):        if filename.endswith(\".txt\"):            return True    return False# Test the functionprint(check_file_extension(\"/path/to/your/directory\"))", "url": "0a26527d2153f952031786977dfda90c", "gt": "def do_files_exist ( filenames ) : preexisting = [ tf . io . gfile . exists ( f ) for f in filenames ] return any ( preexisting )"}, {"nl_input": "kwarg values always have defaults", "code_input": "def get_kwargs(default_dict, **kwargs):    return {**default_dict, **kwargs}# Test the functiondefault_dict = {\"key1\": \"default1\", \"key2\": \"default2\"}kwargs = {\"key1\": \"new1\", \"key3\": \"default3\"}print(get_kwargs(default_dict, **kwargs))", "url": "b7b9cfe9bc7611c1ad042e6257d5ab3d", "gt": "def test_kwargs_are_optional ( self ) : with patch ( \"sys.exit\" ) as mock_exit : cli = MicroCLITestCase . T ( \"script_name f3\" . split ( ) ) . run ( ) # kwargs are optional mock_exit . assert_called_with ( 4 )"}, {"nl_input": "Reads and iterates through each image file in the given directory", "code_input": "import osdef iterate_over_images(directory):    for filename in os.listdir(directory):        if filename.endswith('.jpg') or filename.endswith('.png'):            filepath = os.path.join(directory, filename)            yield filepath# Usagefor image_file in iterate_over_images('/path/to/your/directory'):    # Do something with the image file    pass", "url": "711c408a26e009e46a957a3bc5891670", "gt": "def each_img ( img_dir ) : for fname in utils . each_img ( img_dir ) : fname = os . path . join ( img_dir , fname ) yield cv . imread ( fname ) , fname"}, {"nl_input": "Parses hostname from URL . : param url : URL : return : hostname", "code_input": "import urllib.parsedef parse_hostname(url):    parsed_url = urllib.parse.urlparse(url)    hostname = parsed_url.netloc    return hostname# Test the functionurl = \"http://www.google.com\"print(parse_hostname(url))  # Output: www.google.com", "url": "13343f8f3c5515600e035d8cca7abd84", "gt": "def url_host ( url : str ) -> str : from urllib . parse import urlparse res = urlparse ( url ) return res . netloc . split ( ':' ) [ 0 ] if res . netloc else ''"}, {"nl_input": "Slicing op .", "code_input": "# Define a listlist_ = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]# Slice the listsliced_list = list_[2:5]# Print the sliced listprint(sliced_list)", "url": "d2b5b746f02bfe0d8d6ff1f510e1828e", "gt": "def Slice ( a , begin , size ) : return np . copy ( a ) [ [ slice ( * tpl ) for tpl in zip ( begin , begin + size ) ] ] ,"}, {"nl_input": "Returns the SQL typename required to store the given FieldDefinition", "code_input": "def get_sql_typename(field_definition):    if field_definition.type == 'int':        return 'INT'    elif field_definition.type == 'float':        return 'FLOAT'    elif field_definition.type == 'str':        return 'VARCHAR(%d)' % len(field_definition.max_length)    elif field_definition.type == 'bool':        return 'BOOLEAN'    elif field_definition.type == 'date':        return 'DATE'    elif field_definition.type == 'datetime':        return 'DATETIME'    else:        return 'UNKNOWN_TYPE'", "url": "af0980ef65b107138b9164f39686a882", "gt": "def _getTypename ( self , defn ) : return 'REAL' if defn . type . float or 'TIME' in defn . type . name or defn . dntoeu else 'INTEGER'"}, {"nl_input": "calculate the fill similarity over the image", "code_input": "from skimage import measuredef calculate_fill_similarity(image1, image2):    # Compute the fill similarity    similarity = measure.compare_ssim(image1, image2, multichannel=True)    return similarity", "url": "ce8ba68fe6e18f6be13595643c857111", "gt": "def _sim_fill ( r1 , r2 , imsize ) : bbsize = ( ( max ( r1 [ \"max_x\" ] , r2 [ \"max_x\" ] ) - min ( r1 [ \"min_x\" ] , r2 [ \"min_x\" ] ) ) * ( max ( r1 [ \"max_y\" ] , r2 [ \"max_y\" ] ) - min ( r1 [ \"min_y\" ] , r2 [ \"min_y\" ] ) ) ) return 1.0 - ( bbsize - r1 [ \"size\" ] - r2 [ \"size\" ] ) / imsize"}, {"nl_input": "Removes a : py : class : . Series from the chart .", "code_input": "class Series:    def __init__(self, name, data):        self.name = name        self.data = data# Assume we have a chart with a class 'Series'chart = [Series('Series1', [1, 2, 3]), Series('Series2', [4, 5, 6])]# Remove 'Series1'for s in chart:    if s.name == 'Series1':        chart.remove(s)        break", "url": "67cf3739e350f2ea5801335c51b59d6b", "gt": "def remove_series ( self , series ) : if len ( self . all_series ( ) ) == 1 : raise ValueError ( \"Cannot remove last series from %s\" % str ( self ) ) self . _all_series . remove ( series ) series . _chart = None"}, {"nl_input": "Returns all column names and their data types as a list .", "code_input": "import sqlite3def get_column_names_and_types():    # Connect to the SQLite database    conn = sqlite3.connect('your_database.db')    # Create a cursor object    cur = conn.cursor()    # Fetch all column names and their data types    cur.execute(\"SELECT name, type FROM pragma_table_info('your_table')\")    # Fetch all rows    rows = cur.fetchall()    # Close the connection    conn.close()    # Return the column names and their data types    return rows# Call the functionprint(get_column_names_and_types())", "url": "1001aab66e7872b45d9825d901ea4412", "gt": "def dtypes ( self ) : return [ ( str ( f . name ) , f . dataType . simpleString ( ) ) for f in self . schema . fields ]"}, {"nl_input": "Convert a ctypes float pointer array to a numpy array .", "code_input": "import ctypesimport numpy as np# Assume that we have a ctypes float pointer arrayctypes_array = ctypes.c_float * 5ctypes_array_ptr = ctypes_array()# Initialize the ctypes arrayfor i in range(5):    setattr(ctypes_array_ptr, f'element_{i}', ctypes.c_float(i))# Convert the ctypes float pointer array to a numpy arraynumpy_array = np.ctypeslib.as_array(ctypes_array_ptr)print(numpy_array)", "url": "ce6eacb4f12ded20e034e69bafe8d36c", "gt": "def cfloat32_array_to_numpy ( cptr , length ) : if isinstance ( cptr , ctypes . POINTER ( ctypes . c_float ) ) : return np . fromiter ( cptr , dtype = np . float32 , count = length ) else : raise RuntimeError ( 'Expected float pointer' )"}, {"nl_input": "Take a list of strings and clear whitespace on each one . If a value in the list is not a string pass it through untouched .", "code_input": "def clear_whitespace(lst):    return [s.replace(' ', '') for s in lst if isinstance(s, str)]", "url": "c5e0bd41ae3189370dbad3a0bf904d17", "gt": "def clean_strings ( iterable ) : retval = [ ] for val in iterable : try : retval . append ( val . strip ( ) ) except ( AttributeError ) : retval . append ( val ) return retval"}, {"nl_input": "Convert from whatever is given to a list of scalars for the lookup_field .", "code_input": "def convert_to_scalars(obj):    if isinstance(obj, str):        return [obj]    elif isinstance(obj, int):        return [obj]    elif isinstance(obj, float):        return [obj]    elif isinstance(obj, list):        return [item for item in obj]    elif isinstance(obj, tuple):        return [item for item in obj]    elif isinstance(obj, dict):        return [item for item in obj.values()]    else:        return []# Test the functionprint(convert_to_scalars('hello'))print(convert_to_scalars(123))print(convert_to_scalars(123.456))print(convert_to_scalars([1, 2, 3]))print(convert_to_scalars((1, 2, 3)))print(convert_to_", "url": "2acfd946899b1082d7f65b3960457769", "gt": "def coerce ( self , value ) : if isinstance ( value , dict ) : value = [ value ] if not isiterable_notstring ( value ) : value = [ value ] return [ coerce_single_instance ( self . lookup_field , v ) for v in value ]"}, {"nl_input": "Internal random datetime generator .", "code_input": "import datetimedef generate_random_datetime():    start_date = datetime.datetime(2020, 1, 1)    end_date = datetime.datetime(2020, 12, 31)    delta = end_date - start_date    int_delta = delta.days    random_day = start_date + datetime.timedelta(days=random.randint(0, int_delta))    return random_dayprint(generate_random_datetime())", "url": "7d26da2177ec3962d36d304e92d85b02", "gt": "def _rnd_datetime ( self , start , end ) : return self . from_utctimestamp ( random . randint ( int ( self . to_utctimestamp ( start ) ) , int ( self . to_utctimestamp ( end ) ) , ) )"}, {"nl_input": "zfill ( x width ) - > string", "code_input": "def zfill(x, w):    return str(x).zfill(w)", "url": "ec71b8a5543bb8262f46f32c31348dea", "gt": "def zfill ( x , width ) : if not isinstance ( x , basestring ) : x = repr ( x ) return x . zfill ( width )"}, {"nl_input": "Converts a list into a space - separated string and puts it in a dictionary", "code_input": "def list_to_dict(lst):    return {'string': ' '.join(lst)}# Test the functionlst = ['Hello', 'World', 'This', 'is', 'a', 'test']print(list_to_dict(lst))", "url": "a318fa43339d6fa4ed9b949a5b77562e", "gt": "def encode_list ( key , list_ ) : # type: (str, Iterable) -> Dict[str, str] if not list_ : return { } return { key : \" \" . join ( str ( i ) for i in list_ ) }"}, {"nl_input": "Init a noise variable .", "code_input": "noise = None", "url": "f1f28c0dd35c71a830aa7cbc94c40f10", "gt": "def normal_noise ( points ) : return np . random . rand ( 1 ) * np . random . randn ( points , 1 ) + random . sample ( [ 2 , - 2 ] , 1 )"}, {"nl_input": "An iterable of column names for a particular table or view .", "code_input": "import psycopg2def get_column_names(table_name):    try:        # Establish a connection to the database        conn = psycopg2.connect(            dbname=\"your_database\",            user=\"your_username\",            password=\"your_password\",            host=\"your_host\",            port=\"your_port\"        )        # Create a cursor object        cur = conn.cursor()        # Execute a query to fetch the column names        cur.execute(f\"SELECT column_name FROM information_schema.columns WHERE table_name='{table_name}'\")        # Fetch all the column names        column_names = [row[0] for row in cur.fetchall()]        # Close the cursor and connection        cur.close()        conn.close()        return column_names    except Exception", "url": "d7658ee7d6f5d6fb22fece433d0eb088", "gt": "def column_names ( self , table ) : table_info = self . execute ( u'PRAGMA table_info(%s)' % quote ( table ) ) return ( column [ 'name' ] for column in table_info )"}, {"nl_input": "Removes underscores and capitalizes the neighbouring character", "code_input": "def remove_underscores_capitalize_neighbour(s):    return ''.join(c.upper() if i == 0 or s[i-1] == '_' else c for i, c in enumerate(s))# Test the functionprint(remove_underscores_capitalize_neighbour('hello_world'))  # HelloWorldprint(remove_underscores_capitalize_neighbour('_hello_world'))  # HelloWorldprint(remove_underscores_capitalize_neighbour('hello__world'))  # HelloWorld", "url": "78f9639da029a80f29cbed10f796c01c", "gt": "def mixedcase ( path ) : words = path . split ( '_' ) return words [ 0 ] + '' . join ( word . title ( ) for word in words [ 1 : ] )"}, {"nl_input": "Create a conda environment inside the current sandbox for the given list of dependencies and options .", "code_input": "import conda# Create a new Conda environmentconda.create_env(    name=\"my_env\",  # Name of the environment    file=\"environment.yml\",  # File with the dependencies    overwrite=True,  # Overwrite the existing environment)", "url": "372b930fd10719406ee97e024c0a53a1", "gt": "def create_conda_env ( sandbox_dir , env_name , dependencies , options = ( ) ) : env_dir = os . path . join ( sandbox_dir , env_name ) cmdline = [ \"conda\" , \"create\" , \"--yes\" , \"--copy\" , \"--quiet\" , \"-p\" , env_dir ] + list ( options ) + dependencies log . info ( \"Creating conda environment: \" ) log . info ( \" command line: %s\" , cmdline ) subprocess . check_call ( cmdline , stderr = subprocess . PIPE , stdout = subprocess . PIPE ) log . debug ( \"Environment created\" ) return env_dir , env_name"}, {"nl_input": "Add a column to the current table .", "code_input": "import sqlite3# Connect to the SQLite databaseconn = sqlite3.connect('my_database.db')# Create a cursor objectcur = conn.cursor()# Add a new column to the tablecur.execute(\"ALTER TABLE my_table ADD COLUMN new_column TEXT\")# Commit the changesconn.commit()# Close the connectionconn.close()", "url": "fc0fba0d26d93f6bd9c23bc1314f2d81", "gt": "def add_column ( connection , column ) : stmt = alembic . ddl . base . AddColumn ( _State . table . name , column ) connection . execute ( stmt ) _State . reflect_metadata ( )"}, {"nl_input": "Checks if key exists in datastore . True if yes False if no .", "code_input": "def check_key_exists(datastore, key):    if key in datastore:        return True    else:        return False", "url": "cca5dd52a3d19626fff09249a49c1508", "gt": "def check_key ( self , key : str ) -> bool : keys = self . get_keys ( ) return key in keys"}, {"nl_input": "Purely a debugging aid : Ascii - art picture of a tree descended from node", "code_input": "from ascii_art_generator import generate_ascii_artdef tree_ascii_art(height):    tree = \"\"\"        ^      ^^^    ^^^^^  ^^^^^^^^^^^^^^^^    \"\"\"    return generate_ascii_art(tree, height)print(tree_ascii_art(5))", "url": "11cf04105fcbba8990217a87a8578844", "gt": "def debugTreePrint ( node , pfx = \"->\" ) : print pfx , node . item for c in node . children : debugTreePrint ( c , \" \" + pfx )"}, {"nl_input": "Returns numpy array of natural logarithms of values .", "code_input": "import numpy as npdef natural_log(values):    return np.log(values)# Test the functionvalues = np.array([1, 2, 3, 4, 5])print(natural_log(values))", "url": "167edd67f1adeb4d6c5cfb29e50e9308", "gt": "def to_distribution_values ( self , values ) : with warnings . catch_warnings ( ) : warnings . simplefilter ( \"ignore\" ) # avoid RuntimeWarning: divide by zero encountered in log return numpy . log ( values )"}, {"nl_input": "Redraw event handler for the figure panel", "code_input": "import matplotlib.pyplot as pltfrom matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvasfrom matplotlib.figure import Figurefrom matplotlib.backends.backend_qt5agg import NavigationToolbar2QT as NavigationToolbarclass MyMplCanvas(FigureCanvas):    def __init__(self, parent=None, width=5, height=4, dpi=100):        self.fig = Figure(figsize=(width, height), dpi=dpi)        self.axes = self.fig.add_subplot(111)        FigureCanvas.__init__(self, self.fig)        self.setParent(parent)        self.update()", "url": "081aa8089b7e676937cd3affc2e08cd8", "gt": "def OnUpdateFigurePanel ( self , event ) : if self . updating : return self . updating = True self . figure_panel . update ( self . get_figure ( self . code ) ) self . updating = False"}, {"nl_input": "Apply Gaussian blur to the given data .", "code_input": "import cv2import numpy as npdef gaussian_blur(image, kernel_size):    # Create a 2D kernel    kernel = np.ones((kernel_size, kernel_size), np.float32) / (kernel_size * kernel_size)    # Apply the kernel to the image    blurred_image = cv2.filter2D(image, -1, kernel)    return blurred_image# Load the imageimage = cv2.imread('image.jpg')# Apply Gaussian blurblurred_image = gaussian_blur(image, 5)# Save the blurred imagecv2.imwrite('blurred_image.jpg', blurred_image)", "url": "7e9213011cfc7c3f677806f277665dc3", "gt": "def GaussianBlur ( X , ksize_width , ksize_height , sigma_x , sigma_y ) : return image_transform ( X , cv2 . GaussianBlur , ksize = ( ksize_width , ksize_height ) , sigmaX = sigma_x , sigmaY = sigma_y )"}, {"nl_input": "Set value of the checkbox .", "code_input": "import tkinter as tkdef set_checkbox_value():    if checkbox.get() == 1:        print(\"Checkbox is checked\")    else:        print(\"Checkbox is not checked\")root = tk.Tk()checkbox = tk.IntVar()checkbox_checkbox = tk.Checkbutton(root, text=\"Check me\", variable=checkbox, command=set_checkbox_value)checkbox_checkbox.pack()root.mainloop()", "url": "529e86a0567df6183fe381968569a669", "gt": "def set_value ( self , value ) : if value : self . setChecked ( Qt . Checked ) else : self . setChecked ( Qt . Unchecked )"}, {"nl_input": "Turn dict keys and values into native strings .", "code_input": "def convert_dict_to_string(dictionary):    return str(dictionary)# Test the functiondictionary = {\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}print(convert_dict_to_string(dictionary))", "url": "5e241db72862fc70c36e7e20ad5edea0", "gt": "def stringify_dict_contents ( dct ) : return { str_if_nested_or_str ( k ) : str_if_nested_or_str ( v ) for k , v in dct . items ( ) }"}, {"nl_input": "Return the fully - qualified name of a function .", "code_input": "import inspectdef get_fully_qualified_name(func):    frame = inspect.currentframe().f_back    return frame.f_code.co_namedef my_function():    print(\"Hello, World!\")print(get_fully_qualified_name(my_function))", "url": "50fd86592c25f16bbc23c5961ad15dea", "gt": "def _fullname ( o ) : return o . __module__ + \".\" + o . __name__ if o . __module__ else o . __name__"}, {"nl_input": "Read and return the data from a corpus json file .", "code_input": "import jsondef read_corpus_json(file_name):    with open(file_name, 'r') as file:        data = json.load(file)    return data", "url": "218ac30809c3bdc7d261a5ea19802ace", "gt": "def read_corpus ( file_name ) : with io . open ( file_name , encoding = 'utf-8' ) as data_file : return yaml . load ( data_file )"}, {"nl_input": "Test if the given value is a scalar .", "code_input": "def is_scalar(value):    try:        float(value)        return True    except ValueError:        return False", "url": "8970a4c2fc876814d02a1c6e13dc45be", "gt": "def is_scalar ( value ) : return np . isscalar ( value ) or ( isinstance ( value , np . ndarray ) and ( len ( np . squeeze ( value ) . shape ) == 0 ) )"}, {"nl_input": "Swap i and j rows", "code_input": "def swap_rows(matrix, i, j):    matrix[i], matrix[j] = matrix[j], matrix[i]    return matrix# Test the functionmatrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]print(\"Original matrix:\", matrix)swap_rows(matrix, 0, 2)print(\"Matrix after swapping rows 0 and 2:\", matrix)", "url": "d0357f86ddf7b0105d9d1b1b69314584", "gt": "def _swap_rows ( self , i , j ) : L = np . eye ( 3 , dtype = 'intc' ) L [ i , i ] = 0 L [ j , j ] = 0 L [ i , j ] = 1 L [ j , i ] = 1 self . _L . append ( L . copy ( ) ) self . _A = np . dot ( L , self . _A )"}, {"nl_input": "Local test .", "code_input": "def local_test():    return \"Local test.\"print(local_test())", "url": "2aec19bb1e81428966e9d71583289404", "gt": "def test ( ) : from spyder . utils . qthelpers import qapplication app = qapplication ( ) dlg = ProjectDialog ( None ) dlg . show ( ) sys . exit ( app . exec_ ( ) )"}, {"nl_input": "a normal old python function to return the Nth fibonacci number .", "code_input": "def fibonacci(n):    if n <= 0:        return \"Input should be a positive integer.\"    elif n == 1:        return 0    elif n == 2:        return 1    else:        a, b = 0, 1        for _ in range(2, n):            a, b = b, a + b        return b", "url": "215b9f753c4bedbf5e252691c757d9ae", "gt": "def software_fibonacci ( n ) : a , b = 0 , 1 for i in range ( n ) : a , b = b , a + b return a"}, {"nl_input": "Converts a datetime to a millisecond accuracy timestamp", "code_input": "import timedef convert_to_milliseconds(dt):    return int(time.mktime(dt.timetuple()) * 1000)# Test the functiondt = datetime.datetime.now()print(convert_to_milliseconds(dt))", "url": "ba63741c151123bfce637e652480a02a", "gt": "def datetime_to_ms ( dt ) : seconds = calendar . timegm ( dt . utctimetuple ( ) ) return seconds * 1000 + int ( dt . microsecond / 1000 )"}, {"nl_input": "Returns the deepest level of nesting within a list of lists", "code_input": "def max_depth(lst):    if isinstance(lst, list):        return max(max_depth(x) for x in lst) + 1    else:        return 0# Test the functionlst = [1, [2, [3, [4, [5]]]], [6, [7, [8, [9]]]]]print(max_depth(lst))  # Output: 4", "url": "54daf1d9eb3d92a38eb85fd0febb6a26", "gt": "def list_depth ( list_ , func = max , _depth = 0 ) : depth_list = [ list_depth ( item , func = func , _depth = _depth + 1 ) for item in list_ if util_type . is_listlike ( item ) ] if len ( depth_list ) > 0 : return func ( depth_list ) else : return _depth"}, {"nl_input": "return an iterator that returns a chunk of a string every time it is called . notice that even though bufsize_type might be line buffered we re not doing any line buffering here . that s because our StreamBufferer handles all buffering . we just need to return a reasonable - sized chunk .", "code_input": "class StreamBufferer:    def __init__(self, string, chunk_size):        self.string = string        self.chunk_size = chunk_size        self.index = 0    def __iter__(self):        return self    def __next__(self):        if self.index + self.chunk_size > len(self.string):            raise StopIteration        chunk = self.string[self.index : self.index + self.chunk_size]        self.index += self.chunk_size        return chunk# Usagestring = \"Hello, world!\"chunk_size = 5bufferer = StreamBufferer(string, chunk_size)for chunk in bufferer:    print(chunk)", "url": "b66381638399324a2212ecf9179e9699", "gt": "def get_iter_string_reader ( stdin ) : bufsize = 1024 iter_str = ( stdin [ i : i + bufsize ] for i in range ( 0 , len ( stdin ) , bufsize ) ) return get_iter_chunk_reader ( iter_str )"}, {"nl_input": "Remove duplicates in a list .", "code_input": "def remove_duplicates(input_list):    return list(set(input_list))# Test the functioninput_list = [1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 9]print(remove_duplicates(input_list))", "url": "74f3af5ff87a388959abca8a236acf5c", "gt": "def _uniquify ( _list ) : seen = set ( ) result = [ ] for x in _list : if x not in seen : result . append ( x ) seen . add ( x ) return result"}, {"nl_input": "Move cursor to this line in the current buffer .", "code_input": "import vim# Move cursor to the 5th linevim.command('5')", "url": "85bf8f526e4cc0590ecb0b556389c65a", "gt": "def _go_to_line ( editor , line ) : b = editor . application . current_buffer b . cursor_position = b . document . translate_row_col_to_index ( max ( 0 , int ( line ) - 1 ) , 0 )"}, {"nl_input": "Start a Pdb instance at the calling frame with stdout routed to sys . __stdout__ .", "code_input": "import pdbimport sysdef start_pdb():    frame = sys._getframe(1)  # Get the calling frame    pdb.set_trace()  # Start the Pdb instance    return frame# Call the functionframe = start_pdb()", "url": "0a05a5da32b1fb72cca49d13dc8e3410", "gt": "def set_trace ( ) : # https://github.com/nose-devs/nose/blob/master/nose/tools/nontrivial.py pdb . Pdb ( stdout = sys . __stdout__ ) . set_trace ( sys . _getframe ( ) . f_back )"}, {"nl_input": "Multiply each number by a constant such that the sum is 1 . 0 >>> normalize ( [ 1 2 1 ] ) [ 0 . 25 0 . 5 0 . 25 ]", "code_input": "def normalize(lst):    # Calculate the sum of the list    total = sum(lst)        # Create a new list where each element is the original element divided by the total    normalized = [x / total for x in lst]        return normalized# Test the functionprint(normalize([1, 2, 1]))", "url": "f9b02c7991372e2168cda998af17b5df", "gt": "def normalize ( numbers ) : total = float ( sum ( numbers ) ) return [ n / total for n in numbers ]"}, {"nl_input": "Changes a column name in a DataFrame Parameters : df - DataFrame DataFrame to operate on col_name - string Name of column to change new_col_name - string New name of column", "code_input": "def change_column_name(df, col_name, new_col_name):    df.rename(columns={col_name: new_col_name}, inplace=True)    return df", "url": "8afe30c3c1d7a21a89370867722d657a", "gt": "def col_rename ( df , col_name , new_col_name ) : col_list = list ( df . columns ) for index , value in enumerate ( col_list ) : if value == col_name : col_list [ index ] = new_col_name break df . columns = col_list"}, {"nl_input": "IP address range validation and expansion .", "code_input": "def validate_ip(ip):    parts = ip.split('.')    if len(parts) != 4:        return False    for part in parts:        if not part.isdigit():            return False        i = int(part)        if i < 0 or i > 255:            return False        if len(part) > 1 and part[0] == '0':            return False    return Truedef expand_ip(ip):    if not validate_ip(ip):        return \"Invalid IP\"    parts = ip.split('.')    part1 = int(parts[0])    part2 = int(parts[1])    part3 = int(parts[2])    part4 = int(parts[3])    expanded_ip = []    for i in range(part1, 256):        for j in range(0, 256):            for k in range(0, 25", "url": "4e29078b31bdc20c9249a66228a95f11", "gt": "def ip_address_list ( ips ) : # first, try it as a single IP address try : return ip_address ( ips ) except ValueError : pass # then, consider it as an ipaddress.IPv[4|6]Network instance and expand it return list ( ipaddress . ip_network ( u ( ips ) ) . hosts ( ) )"}, {"nl_input": "Adapts a Numpy array into an ARRAY string to put into the database .", "code_input": "import numpy as npdef numpy_to_db_string(numpy_array):    # Convert numpy array to string    db_string = ''.join(str(item) for item in numpy_array)    return db_string# Test the functionnumpy_array = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])print(numpy_to_db_string(numpy_array))", "url": "85791d7ca6694ef78a7d42f79c958ef6", "gt": "def adapt_array ( arr ) : out = io . BytesIO ( ) np . save ( out , arr ) , out . seek ( 0 ) return buffer ( out . read ( ) )"}, {"nl_input": "Removes stopwords contained in a list of words .", "code_input": "import nltkfrom nltk.corpus import stopwords# Download the stopwords if not already downloadednltk.download('stopwords')def remove_stopwords(words):    # Get the list of English stop words    stop_words = set(stopwords.words('english'))    # Remove the stop words from the list    filtered_words = [word for word in words if word not in stop_words]    return filtered_words# Test the functionwords = ['I', 'am', 'learning', 'Python', 'Programming', 'learning', 'Python']print(remove_stopwords(words))", "url": "6ce9ae857507f7292c65caae0d829141", "gt": "def _removeStopwords ( text_list ) : output_list = [ ] for word in text_list : if word . lower ( ) not in _stopwords : output_list . append ( word ) return output_list"}, {"nl_input": "Se asegura de que un directorio exista .", "code_input": "import osdef check_directory(directory):    if os.path.exists(directory):        return True    else:        return False# Test the functionprint(check_directory('/path/to/your/directory'))  # replace with your directory path", "url": "ffb454a23a874db7b8ba84dec008ffc9", "gt": "def ensure_dir_exists ( directory ) : if directory and not os . path . exists ( directory ) : os . makedirs ( directory )"}, {"nl_input": "r Checks if l is a 2D numpy array of bools", "code_input": "import numpy as npdef is_2d_bool_array(l):    if not isinstance(l, list):        return False    for i in l:        if not isinstance(i, list):            return False        for j in i:            if not isinstance(j, bool):                return False    return True# Test the functionl = [[True, False], [False, True]]print(is_2d_bool_array(l))  # Output: Truel = [[True, False], [False, 'True']]print(is_2d_bool_array(l))  # Output: Falsel = 'not a list'print(is_2d_bool_array(l))  # Output: False", "url": "8a3b1c52b2ad77e9fd817568f4cec12c", "gt": "def is_bool_matrix ( l ) : if isinstance ( l , np . ndarray ) : if l . ndim == 2 and ( l . dtype == bool ) : return True return False"}, {"nl_input": "Return the approximate size of the queue ( not reliable! ) .", "code_input": "import queue# Create a new queueq = queue.Queue()# Add some elements to the queuefor i in range(10):    q.put(i)# Get the approximate size of the queuesize = q.qsize()print(\"Approximate size of the queue: \", size)", "url": "66ad16d7b38f79a6e991c2f96f9a6395", "gt": "def qsize ( self ) : self . mutex . acquire ( ) n = self . _qsize ( ) self . mutex . release ( ) return n"}, {"nl_input": "Join the given iterable with", "code_input": "def join_iterable(iterable, delimiter):    return delimiter.join(iterable)# Test the functionprint(join_iterable(['apple', 'banana', 'cherry'], ' '))", "url": "d5cd6bdee354cd4c13e1317060fe6702", "gt": "def commajoin_as_strings ( iterable ) : return _ ( u',' ) . join ( ( six . text_type ( i ) for i in iterable ) )"}, {"nl_input": "Push item onto heap maintaining the heap invariant .", "code_input": "import heapqclass Heap:    def __init__(self):        self.heap = []    def push(self, item):        heapq.heappush(self.heap, item)    def pop(self):        return heapq.heappop(self.heap)    def peek(self):        return self.heap[0]    def is_empty(self):        return len(self.heap) == 0", "url": "b7ef5c01f2bb54150c1e764f1b5301aa", "gt": "def heappush_max ( heap , item ) : heap . append ( item ) _siftdown_max ( heap , 0 , len ( heap ) - 1 )"}, {"nl_input": "Retries function until it doesn t raise an EINTR error", "code_input": "import errnoimport osimport timedef retries(n, delay, backoff=1, max_delay=None):    if max_delay is None:        max_delay = delay * 2    while n > 1:        try:            return n, delay        except Exception as e:            if isinstance(e, OSError) and e.errno == errno.EINTR:                time.sleep(delay)                delay *= backoff                n -= 1                if delay > max_delay:                    delay = max_delay                continue            else:                raise    return n, delay", "url": "b5df8b3347e8f9eddcd0ec1aa6e25197", "gt": "def retry_on_signal ( function ) : while True : try : return function ( ) except EnvironmentError , e : if e . errno != errno . EINTR : raise"}, {"nl_input": "Pdf evaluated at the peak .", "code_input": "I'm sorry, but your question is a bit unclear. \"Pdf evaluated at the peak\" doesn't seem to be a standard term or a common programming concept. Could you please provide more context or clarify your question? Are you asking for a way to evaluate a PDF file at a specific point in time, or do you need help with a specific programming task?", "url": "0b331f2127c3538176983a9640cb177f", "gt": "def _pdf_at_peak ( self ) : return ( self . peak - self . low ) / ( self . high - self . low )"}, {"nl_input": "Removes comments ( # ... ) from python code .", "code_input": "def remove_comments(code):    lines = code.split('\\n')    new_lines = []    in_string = False    in_comment = False    for line in lines:        i = 0        while i < len(line):            if line[i] == '\\\"' and not in_string:                in_string = not in_string            elif line[i] == '#' and not in_string:                in_comment = True                i += 1                while i < len(line) and not in_string and not in_comment:                    if line[i] == '\\n':                        in_comment = False                    i += 1            elif in_string and line[i] == '\\\"':                in_string = False            elif in_comment and line[i] == '\\n':                in_comment = False            if not in_string and not in_comment:                new_lines.append(line[i])            i += ", "url": "e9606c2ede25ed01dadee38b936b292b", "gt": "def split_comment ( cls , code ) : if '#' not in code : return code #: Remove comments only (leave quoted strings as they are) subf = lambda m : '' if m . group ( 0 ) [ 0 ] == '#' else m . group ( 0 ) return re . sub ( cls . re_pytokens , subf , code )"}, {"nl_input": "simple method to determine if a url is relative or absolute", "code_input": "from urllib.parse import urlparsedef is_url_absolute(url):    parsed_url = urlparse(url)    return bool(parsed_url.netloc)# Test the functionprint(is_url_absolute('http://example.com'))  # Trueprint(is_url_absolute('//example.com'))  # False", "url": "a7c751f435108eb653de787c9016c077", "gt": "def is_relative_url ( url ) : if url . startswith ( \"#\" ) : return None if url . find ( \"://\" ) > 0 or url . startswith ( \"//\" ) : # either 'http(s)://...' or '//cdn...' and therefore absolute return False return True"}, {"nl_input": "Insert many items at once into a temporary table .", "code_input": "import sqlite3# Connect to the SQLite databaseconn = sqlite3.connect(':memory:')# Create a cursor objectcur = conn.cursor()# Create the tablecur.execute('''    CREATE TABLE IF NOT EXISTS items (        id INTEGER PRIMARY KEY,        name TEXT    )''')# List of items to insertitems = [(1, 'item1'), (2, 'item2'), (3, 'item3')]# Insert many items at oncecur.executemany('INSERT INTO items VALUES (?, ?)', items)# Commit the changesconn.commit()# Close the connectionconn.close()", "url": "c4bbbb9264cf558138ca7d49ad446d86", "gt": "def insert_many ( self , items ) : return SessionContext . session . execute ( self . insert ( values = [ to_dict ( item , self . c ) for item in items ] ) , ) . rowcount"}, {"nl_input": "Returns True if test is True for all array elements . Otherwise returns False .", "code_input": "def check_all_elements(test, array):    return all(element == test for element in array)", "url": "46e171604d456aab34ab6b4d624435a2", "gt": "def isarray ( array , test , dim = 2 ) : if dim > 1 : return all ( isarray ( array [ i ] , test , dim - 1 ) for i in range ( len ( array ) ) ) return all ( test ( i ) for i in array )"}, {"nl_input": "Returns the memory byte size of a Numpy array as an integer .", "code_input": "import numpy as npdef memory_size_of_numpy_array(array):    return array.nbytes# Example usage:array = np.array([1, 2, 3, 4, 5])print(memory_size_of_numpy_array(array))", "url": "f0456030f3cb36953670e94276edb1d5", "gt": "def bytesize ( arr ) : byte_size = np . prod ( arr . shape ) * np . dtype ( arr . dtype ) . itemsize return byte_size"}, {"nl_input": "remove problem characters from string", "code_input": "def remove_problem_characters(s):    return ''.join(c for c in s if c.isalnum() or c.isspace())# Test the functionprint(remove_problem_characters(\"Hello, World!\"))  # Output: Hello World", "url": "be5711e9db130456deb244ee94eed831", "gt": "def remove_bad ( string ) : remove = [ ':' , ',' , '(' , ')' , ' ' , '|' , ';' , '\\'' ] for c in remove : string = string . replace ( c , '_' ) return string"}, {"nl_input": "The Excel worksheet reference to the X values for this chart ( not including the column label ) .", "code_input": "import pandas as pd# Load the Excel filexl = pd.ExcelFile('your_file.xlsx')# Load the first sheetdf = xl.parse(xl.sheet_names[0])# Get the X valuesx_values = df.iloc[:, 0].values# Print the X valuesprint(x_values)", "url": "25e289a769f7ae896c02b2c308474c4e", "gt": "def x_values_ref ( self , series ) : top_row = self . series_table_row_offset ( series ) + 2 bottom_row = top_row + len ( series ) - 1 return \"Sheet1!$A$%d:$A$%d\" % ( top_row , bottom_row )"}, {"nl_input": "Returns a random string of length string_length .", "code_input": "import randomimport stringdef generate_random_string(string_length):    \"\"\"Generate a random string of a given length\"\"\"    letters = string.ascii_letters + string.digits    return ''.join(random.choice(letters) for i in range(string_length))# Test the functionprint(generate_random_string(10))", "url": "d0012fec75a957ee2d77e2ac6478bdee", "gt": "def random_string ( string_length = 10 ) : random = str ( uuid . uuid4 ( ) ) # Convert UUID format to a Python string. random = random . upper ( ) # Make all characters uppercase. random = random . replace ( \"-\" , \"\" ) # Remove the UUID '-'. return random [ 0 : string_length ]"}, {"nl_input": "Convert a structured NumPy array into a Table .", "code_input": "import pandas as pdimport numpy as np# Create a structured NumPy arraydata = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],                 dtype=[('A', 'int32'), ('B', 'int32'), ('C', 'int32')])# Convert the structured NumPy array into a DataFramedf = pd.DataFrame(data)print(df)", "url": "4193356c3a00f554a415099595307044", "gt": "def from_array ( cls , arr ) : return cls ( ) . with_columns ( [ ( f , arr [ f ] ) for f in arr . dtype . names ] )"}, {"nl_input": "HTTP response for not - authorized access ( status code 403 )", "code_input": "import requestsdef check_status_code(url):    response = requests.get(url)    if response.status_code == 403:        print(\"Not Authorized Access\")    else:        print(f\"Status code: {response.status_code}\")# Replace 'http://example.com' with the URL you want to checkcheck_status_code('http://example.com')", "url": "d5eeb1f8ad1e4d020d24cce0e3083342", "gt": "def HttpResponse401 ( request , template = KEY_AUTH_401_TEMPLATE , content = KEY_AUTH_401_CONTENT , content_type = KEY_AUTH_401_CONTENT_TYPE ) : return AccessFailedResponse ( request , template , content , content_type , status = 401 )"}, {"nl_input": "Stop the progress bar .", "code_input": "from tqdm import tqdm# Assume pbar is your progress barpbar = tqdm(total=100)for i in range(10):    # Do some work    pbar.update(10)  # Update the progress barpbar.close()  # Stop the progress bar", "url": "66112d5d1ef6700a828265dbc4da86d6", "gt": "def stop ( self ) : if self . _progressing : self . _progressing = False self . _thread . join ( )"}, {"nl_input": "Add one tick to progress bar", "code_input": "from tqdm import tqdmimport time# Create a progress barpbar = tqdm(total=100)# Loop over a range of numbersfor i in range(100):    # Do some work    time.sleep(0.01)  # Simulate some work        # Update the progress bar    pbar.update(1)# Close the progress barpbar.close()", "url": "9402a316375e935cabce06eadf9d542a", "gt": "def tick ( self ) : self . current += 1 if self . current == self . factor : sys . stdout . write ( '+' ) sys . stdout . flush ( ) self . current = 0"}, {"nl_input": "Serialize representation of the column for local caching .", "code_input": "import pickle# Assume we have a function that returns a columndef get_column():    # This is a simple example, replace with your actual function    return [1, 2, 3, 4, 5]# Serialize the columnserialized_column = pickle.dumps(get_column())# Now you can store the serialized column in a filewith open('column.pkl', 'wb') as f:    pickle.dump(serialized_column, f)# To load the column, you would do something like thiswith open('column.pkl', 'rb') as f:    deserialized_column = pickle.load(f)# Now deserialized_column is a list of numbers, not a functionprint(deserialized_column)", "url": "7720471d366176807aa531dadb064217", "gt": "def to_dict ( self ) : return { 'schema' : self . schema , 'table' : self . table , 'name' : self . name , 'type' : self . type }"}, {"nl_input": "Returns the default WSGI handler for the runner .", "code_input": "def get_default_wsgi_handler():    from werkzeug.serving import WSGIRequestHandler    return WSGIRequestHandler", "url": "3f2207516acc039310a03d719345bbd1", "gt": "def get_handler ( self , * args , * * options ) : handler = get_internal_wsgi_application ( ) from django . contrib . staticfiles . handlers import StaticFilesHandler return StaticFilesHandler ( handler )"}, {"nl_input": "Converts time strings to integer seconds : param time : %H : %M : %S string : return : integer seconds", "code_input": "def time_to_seconds(time):    h, m, s = map(int, time.split(':'))    return h * 3600 + m * 60 + s# Test the functionprint(time_to_seconds('00:01:00'))  # Output: 3600print(time_to_seconds('00:00:59'))  # Output: 5400print(time_to_seconds('23:59:59'))  # Output: 86399", "url": "64d9dc81c20e31b854e0eab01dee6498", "gt": "def str_time_to_day_seconds ( time ) : t = str ( time ) . split ( ':' ) seconds = int ( t [ 0 ] ) * 3600 + int ( t [ 1 ] ) * 60 + int ( t [ 2 ] ) return seconds"}, {"nl_input": "Restoring scrollbar position after main window is visible", "code_input": "import tkinter as tkdef restore_scrollbar_position():    # Get the current position of the scrollbar    current_position = scrollbar.get()    # Set the scrollbar to the last known position    scrollbar.set(current_position)def main():    # Create the main window    window = tk.Tk()    # Create a scrollbar    scrollbar = tk.Scrollbar(window)    # Pack the scrollbar into the main window    scrollbar.pack()    # Restore the scrollbar position after the main window is visible    window.after(0, restore_scrollbar_position)    # Start the main event loop    window.mainloop()if __name__ == \"__main__\":    main()", "url": "00b975fe0f0c6867c45f8b890f4fe429", "gt": "def restore_scrollbar_position ( self ) : scrollbar_pos = self . get_option ( 'scrollbar_position' , None ) if scrollbar_pos is not None : self . explorer . treewidget . set_scrollbar_position ( scrollbar_pos )"}, {"nl_input": "Returns sequence of integer ids given a sequence of string ids .", "code_input": "def string_to_int_list(string_list):    return [int(id) for id in string_list]# Test the functionstring_ids = ['1', '2', '3', '4', '5']print(string_to_int_list(string_ids))", "url": "6eaf6a5e1e5f229137f1cf2cf2bfdaca", "gt": "def strids2ids ( tokens : Iterable [ str ] ) -> List [ int ] : return list ( map ( int , tokens ) )"}, {"nl_input": "Remove duplicates from an iterable preserving the order .", "code_input": "def remove_duplicates(iterable):    seen = set()    for item in iterable:        if item not in seen:            yield item            seen.add(item)", "url": "215a474be7e5886d15c8a3a59eb1b842", "gt": "def delete_duplicates ( seq ) : seen = set ( ) seen_add = seen . add return [ x for x in seq if not ( x in seen or seen_add ( x ) ) ]"}, {"nl_input": "Pre - order depth - first", "code_input": "def pre_order_depth_first(nodes):    # Sort the list of dictionaries by depth in descending order    sorted_nodes = sorted(nodes, key=lambda x: (-x['depth'], x['name']))    # Create an empty dictionary to store the result    result = {}    # Iterate over the sorted list of dictionaries    for node in sorted_nodes:        # If the node's parent is not in the result, add it        if node['parent'] not in result:            result[node['parent']] = []        # Add the node to the parent's list        result[node['parent']].append(node)    return result", "url": "7f09c0c1fb655aa7be69dd12ae8b3459", "gt": "def walk_tree ( root ) : yield root for child in root . children : for el in walk_tree ( child ) : yield el"}, {"nl_input": "Make file user readable if it is not a link .", "code_input": "import osdef make_readable(file_path):    if not os.path.islink(file_path):        os.chmod(file_path, 0o644)# Test the functionmake_readable('/path/to/your/file')", "url": "ace76e2287f89f73f0d302ad68c6b28d", "gt": "def make_file_readable ( filename ) : if not os . path . islink ( filename ) : util . set_mode ( filename , stat . S_IRUSR )"}, {"nl_input": "Convert to camel case .", "code_input": "def to_camel_case(text):    # Split the text into words    words = text.split(' ')    # Capitalize the first letter of each word and join them together    camel_case_text = ''.join(word.capitalize() for word in words)    return camel_case_text# Test the functionprint(to_camel_case('convert to camel case'))", "url": "c954b335d705a71796714fc13a69018b", "gt": "def to_camel_case ( text ) : split = text . split ( '_' ) return split [ 0 ] + \"\" . join ( x . title ( ) for x in split [ 1 : ] )"}, {"nl_input": "Colorize text with given color .", "code_input": "from colorama import Fore, initinit()def colorize_text(text, color):    colors = {        'red': Fore.RED,        'green': Fore.GREEN,        'yellow': Fore.YELLOW,        'blue': Fore.BLUE,        'magenta': Fore.MAGENTA,        'cyan': Fore.CYAN,        'white': Fore.WHITE    }    if color in colors:        return f'{colors[color]}{text}{Fore.RESET}'    else:        return f'{text}'# Test the functionprint(colorize_text('Hello, World!', 'red'))print(colorize", "url": "b0187a0236d4299c56f0154fb18e9680", "gt": "def _write_color_colorama ( fp , text , color ) : foreground , background , style = get_win_color ( color ) colorama . set_console ( foreground = foreground , background = background , style = style ) fp . write ( text ) colorama . reset_console ( )"}, {"nl_input": "from a valid python module path get the run method name passed", "code_input": "import inspectdef get_run_method_name(module_path):    # Import the module    module = __import__(module_path)    # Get the list of functions in the module    functions = inspect.getmembers(module, inspect.isfunction)    # Find the 'run' function    for name, func in functions:        if name == 'run':            return name    return None# Usageprint(get_run_method_name('your_module_path'))", "url": "4a9b986374bae09d4078e1f195a5d2c4", "gt": "def get_method_from_module ( module_path , method_name ) : top_module = __import__ ( module_path ) module = top_module # we tunnel down until we find the module we want for submodule_name in module_path . split ( '.' ) [ 1 : ] : module = getattr ( module , submodule_name ) assert hasattr ( module , method_name ) , \"unable to find method {0} from module {1}. does the method exist?\" . format ( method_name , module_path ) return getattr ( module , method_name )"}, {"nl_input": "This is the same functionality as int . from_bytes in python 3", "code_input": "def from_bytes(bytes_obj, byteorder='big', signed=False):    \"\"\"    Convert bytes object to an integer.    Parameters:    bytes_obj (bytes): The bytes object to convert.    byteorder (str): The endianness of the bytes object. Default is 'big'.    signed (bool): If True, the integer is signed. Default is False.    Returns:    int: The integer value of the bytes object.    \"\"\"    if byteorder not in ('big', 'little', 'native'):        raise ValueError(\"Invalid byteorder. Must be 'big', 'little', or 'native'.\")    if signed and byteorder != 'native':        raise ValueError(\"Signed integers are only valid for 'native' byteorder.\")    if byteorder == 'native':        byteorder = 'big' if bytes_obj[0] > 127 else 'little'    if byteorder == 'big':        return", "url": "aad5675e5e47b94c38b92c39e101b732", "gt": "def _from_bytes ( bytes , byteorder = \"big\" , signed = False ) : return int . from_bytes ( bytes , byteorder = byteorder , signed = signed )"}, {"nl_input": "Check if a dtype is a subclass of the numpy datetime types", "code_input": "import numpy as npdef is_datetime_dtype(dtype):    datetime_dtypes = ['datetime64', 'datetime32', 'date', 'time']    return dtype.name in datetime_dtypes# Testprint(is_datetime_dtype(np.dtype('datetime64')))  # Trueprint(is_datetime_dtype(np.dtype('date')))  # Trueprint(is_datetime_dtype(np.dtype('time')))  # Trueprint(is_datetime_dtype(np.dtype('float64')))  # False", "url": "a1bda233eb59bf9da775dcb1ca1b62c7", "gt": "def is_datetime_like ( dtype ) : return ( np . issubdtype ( dtype , np . datetime64 ) or np . issubdtype ( dtype , np . timedelta64 ) )"}, {"nl_input": "Return a dictionary of key / values from os . environ .", "code_input": "import osdef get_env_vars():    return os.environ", "url": "40a703bc56a740baa9b642c07f243912", "gt": "def _get_os_environ_dict ( keys ) : return { k : os . environ . get ( k , _UNDEFINED ) for k in keys }"}, {"nl_input": "Return a tuple that contains ( width height ) Pass in a url to an image and find out its size without loading the whole file If the image wxh could not be found the tuple will contain None values", "code_input": "from PIL import Imageimport requestsfrom io import BytesIOdef get_image_size(url):    response = requests.get(url)    img = Image.open(BytesIO(response.content))    width, height = img.size    return (width, height)", "url": "cf303e12e0a23ea3d8cf9d64a44bb720", "gt": "def get_image_dimension ( self , url ) : w_h = ( None , None ) try : if url . startswith ( '//' ) : url = 'http:' + url data = requests . get ( url ) . content im = Image . open ( BytesIO ( data ) ) w_h = im . size except Exception : logger . warning ( \"Error getting image size {}\" . format ( url ) , exc_info = True ) return w_h"}, {"nl_input": "Return a main config value or default if it does not exist .", "code_input": "import configparserdef get_config_value(config_file, section, option, default_value=None):    config = configparser.ConfigParser()    config.read(config_file)    if config.has_section(section):        if config.has_option(section, option):            return config.get(section, option)        else:            return default_value    else:        return default_value# Usageconfig_file = 'config.ini'section = 'main'option = 'config_value'default_value = 'default_value'main_config_value = get_config_value(config_file, section, option, default_value)print(f'Main config value: {main_config_value}')", "url": "386feb46f7695b77a7a29cf6c0dc5ac9", "gt": "def _get_config_or_default ( self , key , default , as_type = lambda x : x ) : if self . main_config . has_option ( self . main_section , key ) : return as_type ( self . main_config . get ( self . main_section , key ) ) return default"}, {"nl_input": "Set foreground - and background colors and intensity .", "code_input": "import osdef set_colors(foreground, background, intensity):    os.system(f'color {foreground} {background} {intensity}')# Set colorsset_colors('4', '0', '0')  # Foreground color is set to blue, background color is set to black, intensity is set to 0", "url": "7f7b530bb1644e7ff3a20d39b9f6d9fa", "gt": "def set_color ( self , fg = None , bg = None , intensify = False , target = sys . stdout ) : raise NotImplementedError"}, {"nl_input": "writes a string to file", "code_input": "def write_to_file(filename, content):    with open(filename, 'w') as file:        file.write(content)# Test the functionwrite_to_file('test.txt', 'Hello, World!')", "url": "cfe10971d3e9565b10d9a8da615d0b58", "gt": "def write_str2file ( pathname , astr ) : fname = pathname fhandle = open ( fname , 'wb' ) fhandle . write ( astr ) fhandle . close ( )"}, {"nl_input": "Utility function for sort_file_tabs_alphabetically () .", "code_input": "def sort_file_tabs_alphabetically(file_list):    return sorted(file_list)", "url": "65c25e4888533db2382a5501c97b7fe7", "gt": "def sorted ( self ) : for i in range ( 0 , self . tabs . tabBar ( ) . count ( ) - 1 ) : if ( self . tabs . tabBar ( ) . tabText ( i ) > self . tabs . tabBar ( ) . tabText ( i + 1 ) ) : return False return True"}, {"nl_input": "Reconstruct the image from the tf example .", "code_input": "import tensorflow as tf# Load the imagedef load_image(file_name):    img = tf.io.read_file(file_name)    img = tf.image.decode_jpeg(img, channels=3)    img = tf.image.resize(img, [224, 224])    img = img / 255.0  # normalize to [0,1] range    return img# Load the imageimg = load_image('path_to_your_image.jpg')# Print the imageprint(img)", "url": "ee6f7f25b60a54d1abdd6b0904517c41", "gt": "def decode_example ( self , example ) : img = tf . image . decode_image ( example , channels = self . _shape [ - 1 ] , dtype = tf . uint8 ) img . set_shape ( self . _shape ) return img"}, {"nl_input": "Add Builders and construction variables for SGI MIPS C ++ to an Environment .", "code_input": "Sure, here is a simple example of how you might add builders and construction variables for SGI MIPS C++ in an environment. This is a very basic example and may not cover all your needs, but it should give you a starting point.```cpp", "url": "d86c7ef069bae9bd25b1719469eaa20e", "gt": "def generate ( env ) : cplusplus . generate ( env ) env [ 'CXX' ] = 'CC' env [ 'CXXFLAGS' ] = SCons . Util . CLVar ( '-LANG:std' ) env [ 'SHCXX' ] = '$CXX' env [ 'SHOBJSUFFIX' ] = '.o' env [ 'STATIC_AND_SHARED_OBJECTS_ARE_THE_SAME' ] = 1"}, {"nl_input": "Proximal operator to project onto zero", "code_input": "import numpy as npdef proximal_operator_to_project_onto_zero(v, lambda_param):    \"\"\"    Proximal operator to project onto zero.    Parameters:    v (numpy array): The input vector.    lambda_param (float): The proximal parameter.    Returns:    numpy array: The proximal operator applied to the input vector.    \"\"\"    return np.where(np.abs(v) < lambda_param, 0, v)# Test the functionv = np.array([1, 2, 3])lambda_param = 2print(proximal_operator_to_project_onto_zero(v, lambda_param))", "url": "fe2927654759fba2b7cfee8b53e498ca", "gt": "def prox_zero ( X , step ) : return np . zeros ( X . shape , dtype = X . dtype )"}, {"nl_input": "date to unix timestamp in milliseconds", "code_input": "import timeimport datetimedef date_to_unix_timestamp(date_str, format=\"%Y-%m-%d %H:%M:%S\"):    date_obj = datetime.datetime.strptime(date_str, format)    unix_timestamp = int(time.mktime(date_obj.timetuple()) * 1000)    return unix_timestamp# Test the functiondate_str = \"2022-01-01 00:00:00\"print(date_to_unix_timestamp(date_str))", "url": "c45019dbaf87a4dda8ed93145a8d72d9", "gt": "def date_to_timestamp ( date ) : date_tuple = date . timetuple ( ) timestamp = calendar . timegm ( date_tuple ) * 1000 return timestamp"}, {"nl_input": "Get the parent directory of a filename .", "code_input": "import osdef get_parent_directory(filename):    parent_directory = os.path.abspath(os.path.join(filename, os.pardir))    return parent_directoryfilename = 'your_file.txt'  # replace with your filenameprint(get_parent_directory(filename))", "url": "d4c1f44c7bd93d72431c1636e15a2c94", "gt": "def get_parent_dir ( name ) : parent_dir = os . path . dirname ( os . path . dirname ( name ) ) if parent_dir : return parent_dir return os . path . abspath ( '.' )"}, {"nl_input": "Takes a multi - dimensional array and returns a 1 dimensional array with the same contents .", "code_input": "def flatten(arr):    result = []    for sublist in arr:        if isinstance(sublist, list):            for item in sublist:                result.append(item)        else:            result.append(sublist)    return result", "url": "6c2f0cae41d4a8defbd80e5fc9ecf368", "gt": "def flatten_array ( grid ) : grid = [ grid [ i ] [ j ] for i in range ( len ( grid ) ) for j in range ( len ( grid [ i ] ) ) ] while type ( grid [ 0 ] ) is list : grid = flatten_array ( grid ) return grid"}, {"nl_input": "Recieving the JSON file from uulm", "code_input": "import requestsimport jsondef read_json_from_url(url):    response = requests.get(url)    data = json.loads(response.text)    return data# Replace 'your_url' with the actual URL of the JSON filedata = read_json_from_url('your_url')print(data)", "url": "22b581c617befce3a934d35f780c7538", "gt": "def get ( url ) : response = urllib . request . urlopen ( url ) data = response . read ( ) data = data . decode ( \"utf-8\" ) data = json . loads ( data ) return data"}, {"nl_input": "Force compilation of expression for the SQLite target", "code_input": "import sqlite3# Connect to the SQLite databaseconn = sqlite3.connect('my_database.db')# Create a cursor objectcur = conn.cursor()# Execute a query to force compile the expression for the SQLite targetcur.execute(\"SELECT * FROM employees WHERE salary > 50000\")# Fetch all the rowsrows = cur.fetchall()# Print the rowsfor row in rows:    print(row)# Close the connectionconn.close()", "url": "1c31b5225729722e73162d729a8a9e91", "gt": "def compile ( expr , params = None ) : from ibis . sql . alchemy import to_sqlalchemy return to_sqlalchemy ( expr , dialect . make_context ( params = params ) )"}, {"nl_input": "Patch the modules with gevent", "code_input": "import gevent# This is a function that will be run in a greenletdef print_foo():    print('foo')# This is a function that will be run in a greenletdef print_bar():    print('bar')# Create a greenlet for each functiong1 = gevent.spawn(print_foo)g2 = gevent.spawn(print_bar)# Wait for both greenlets to finishgevent.joinall([g1, g2])", "url": "b2d8c9ff02a806e11c86616df579b848", "gt": "def _gevent_patch ( ) : try : assert gevent assert grequests except NameError : logger . warn ( 'gevent not exist, fallback to multiprocess...' ) return MULTITHREAD else : monkey . patch_all ( ) # Must patch before get_photos_info return GEVENT"}, {"nl_input": "Returns a list of synsets of a word after lemmatization .", "code_input": "import nltkfrom nltk.corpus import wordnetdef get_synsets(word):    lemmatizer = nltk.WordNetLemmatizer()    word_lemma = lemmatizer.lemmatize(word)    synsets = wordnet.synsets(word_lemma)    return [syn.name() for syn in synsets]# Test the functionprint(get_synsets('happy'))", "url": "ef50ba41894d62298e768a8a40286eeb", "gt": "def has_synset ( word : str ) -> list : return wn . synsets ( lemmatize ( word , neverstem = True ) )"}, {"nl_input": "Find longest ORF from the given list of ORFs .", "code_input": "def longest_orf(orf_list):    longest_orf = max(orf_list, key=len)    return longest_orf# Test the functionorf_list = ['ATCACG', 'CGATC', 'ATCGATC', 'CGATCGT']print(longest_orf(orf_list))  # Output: CGATCGT", "url": "88b2e5b638d21e4cad0678aa5548008d", "gt": "def get_longest_orf ( orfs ) : sorted_orf = sorted ( orfs , key = lambda x : len ( x [ 'sequence' ] ) , reverse = True ) [ 0 ] return sorted_orf"}, {"nl_input": "Returns the name of the current git branch", "code_input": "import subprocessdef get_current_git_branch():    result = subprocess.run([\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"], text=True, capture_output=True)    return result.stdout.strip()print(get_current_git_branch())", "url": "313f3e2f971c34ffd53caa9c21f4515c", "gt": "def get_git_branch ( git_path = 'git' ) : branch_match = call ( ( git_path , 'rev-parse' , '--symbolic-full-name' , 'HEAD' ) ) if branch_match == \"HEAD\" : return None else : return os . path . basename ( branch_match )"}, {"nl_input": "Data from http : // indexed . blogspot . com / 2007 / 12 / meltdown - indeed . html", "code_input": "import requestsfrom bs4 import BeautifulSoupdef scrape_data(url):    response = requests.get(url)    soup = BeautifulSoup(response.text, 'html.parser')    # Find the data you want to scrape    # For example, if the data is in a table, you can use:    data = []    for table in soup.find_all('table'):        for row in table.find_all('tr'):            cols = row.find_all('td')            cols = [col.text.strip() for col in cols]            data.append([col for col in cols if col])    return dataurl = \"http://indexed.blogspot.com/2007/12/meltdown-indeed.html\"print(scrape_data(url))", "url": "d9b236e9fcf20fa21ca7851c87a14c84", "gt": "def house_explosions ( ) : chart = PieChart2D ( int ( settings . width * 1.7 ) , settings . height ) chart . add_data ( [ 10 , 10 , 30 , 200 ] ) chart . set_pie_labels ( [ 'Budding Chemists' , 'Propane issues' , 'Meth Labs' , 'Attempts to escape morgage' , ] ) chart . download ( 'pie-house-explosions.png' )"}, {"nl_input": "Exit the shell session .", "code_input": "import osos.system('exit')", "url": "552e6841d09f58e5e1c8fb096c977099", "gt": "def do_exit ( self , arg ) : if self . current : self . current . close ( ) self . resource_manager . close ( ) del self . resource_manager return True"}, {"nl_input": "Test the multiprocess", "code_input": "import multiprocessingdef worker(num):    \"\"\"worker function\"\"\"    print('Worker:', num)    returnif __name__ == '__main__':    jobs = []    for i in range(5):        p = multiprocessing.Process(target=worker, args=(i,))        jobs.append(p)        p.start()", "url": "305d82a1849c66873989c4284d69ab1d", "gt": "def test3 ( ) : import time p = MVisionProcess ( ) p . start ( ) time . sleep ( 5 ) p . stop ( )"}, {"nl_input": "save the current session override if session was saved earlier", "code_input": "import pickle# Function to save the current sessiondef save_session(session):    with open('session.pkl', 'wb') as f:        pickle.dump(session, f)# Function to load the saved sessiondef load_session():    try:        with open('session.pkl', 'rb') as f:            return pickle.load(f)    except FileNotFoundError:        return None# Function to save the current session and override if a session was saved earlierdef save_current_session(session):    saved_session = load_session()    if saved_session is not None:        print(\"Session was saved earlier. Overriding it.\")    save_session(session)", "url": "426b13c860e6d3db831d7782b6af8328", "gt": "def save ( self ) : if self . path : self . _saveState ( self . path ) else : self . saveAs ( )"}, {"nl_input": "Make a n + 1 dim one - hot array from n dim int - categorical array .", "code_input": "import numpy as npdef one_hot_encode(arr):    return np.eye(np.max(arr) + 1)[arr]# Test the functioncategorical_array = np.array([0, 1, 2, 0, 2, 1, 3, 2, 1, 0])one_hot_encoded_array = one_hot_encode(categorical_array)print(one_hot_encoded_array)", "url": "c5ab7e6fd56d3fb3273938700034235b", "gt": "def one_hot ( x , size , dtype = np . float32 ) : return np . array ( x [ ... , np . newaxis ] == np . arange ( size ) , dtype )"}, {"nl_input": "Truncates a value to a number of decimals places", "code_input": "def truncate_value(value, num_decimals):    return round(value, num_decimals)# Test the functionprint(truncate_value(12.3456, 2))  # Output: 12.35", "url": "a9f00f4b4472333451594b653fd3ddf4", "gt": "def truncate ( value : Decimal , n_digits : int ) -> Decimal : return Decimal ( math . trunc ( value * ( 10 ** n_digits ) ) ) / ( 10 ** n_digits )"}, {"nl_input": "Close child subprocess", "code_input": "import subprocessdef close_child_subprocess(child_process):    child_process.terminate()# Create a child subprocesschild_process = subprocess.Popen(['python', 'child_script.py'])# Call the function to close the child subprocessclose_child_subprocess(child_process)", "url": "12a0563f902fd7a97c3632a9db804067", "gt": "def close ( self ) : if self . _subprocess is not None : os . killpg ( self . _subprocess . pid , signal . SIGTERM ) self . _subprocess = None"}, {"nl_input": "Checks if value is an integer long integer or float .", "code_input": "def is_integer_or_float(value):    if isinstance(value, int) or isinstance(value, float):        return True    else:        return False", "url": "11f24e28ca5d6dfbed610eec3da9c58d", "gt": "def isnumber ( * args ) : return all ( map ( lambda c : isinstance ( c , int ) or isinstance ( c , float ) , args ) )"}, {"nl_input": "Raises the supplied figure number or figure window .", "code_input": "import tkinter as tkdef raise_figure(number):    root = tk.Tk()    root.geometry(f\"200x200\")    label = tk.Label(root, text=f\"Raised figure: {number}\")    label.pack()    root.mainloop()# Test the functionraise_figure(10)", "url": "67b7ab9b728b03a77afa0fe61d8517e2", "gt": "def raise_figure_window ( f = 0 ) : if _fun . is_a_number ( f ) : f = _pylab . figure ( f ) f . canvas . manager . window . raise_ ( )"}, {"nl_input": "Returns true if all of the elements in the list are equal .", "code_input": "def all_elements_equal(lst):    return len(set(lst)) == 1", "url": "2d9deba8d6ccb83eaf09c795b1e77e6a", "gt": "def _check_elements_equal ( lst ) : assert isinstance ( lst , list ) , \"Input value must be a list.\" return not lst or lst . count ( lst [ 0 ] ) == len ( lst )"}, {"nl_input": "Encodes a list of strings to a single string . : type strs : List [ str ] : rtype : str", "code_input": "def encode(strs):    return ''.join(strs)", "url": "f796b43787cd30bb20850ab43571b623", "gt": "def encode ( strs ) : res = '' for string in strs . split ( ) : res += str ( len ( string ) ) + \":\" + string return res"}, {"nl_input": "Read a public RSA key from a PEM file .", "code_input": "import rsadef read_public_key(pem_file):    with open(pem_file, 'r') as file:        public_key = rsa.PublicKey.load_pkcs1(file.read())    return public_key# Usagepublic_key = read_public_key('path_to_your_pem_file')", "url": "15c537891f0dde8802ff6c44a92ad71e", "gt": "def import_public_rsa_key_from_file ( filename ) : with open ( filename , \"rb\" ) as key_file : public_key = serialization . load_pem_public_key ( key_file . read ( ) , backend = default_backend ( ) ) return public_key"}, {"nl_input": "Get the contents of an object stored in S3 as string .", "code_input": "import boto3def get_s3_object_as_string(bucket_name, key):    s3 = boto3.client('s3')    response = s3.get_object(Bucket=bucket_name, Key=key)    return response['Body'].read().decode('utf-8')# usagebucket_name = 'my_bucket'key = 'my_object.txt'print(get_s3_object_as_string(bucket_name, key))", "url": "6b951991361dc39522cbc34fb09ce7bc", "gt": "def get_as_string ( self , s3_path , encoding = 'utf-8' ) : content = self . get_as_bytes ( s3_path ) return content . decode ( encoding )"}, {"nl_input": "Returns number of wraps around given method .", "code_input": "def count_method_calls(method):    # This dictionary will hold the number of times each method is called    method_call_counts = {}    # This is a placeholder for the actual method    def wrapper(*args, **kwargs):        # If the method is not yet in the dictionary, add it with a count of 1        if method.__name__ not in method_call_counts:            method_call_counts[method.__name__] = 1        else:            # If the method is already in the dictionary, increment its count            method_call_counts[method.__name__] += 1        # Call the actual method and return its result        return method(*args, **kwargs)    # The wrapper function is returned    return wrapper", "url": "0ce77b0ad69c4b908a250a40ad5ce9dd", "gt": "def wrap_count ( method ) : number = 0 while hasattr ( method , '__aspects_orig' ) : number += 1 method = method . __aspects_orig return number"}, {"nl_input": "Write the ROI model to a FITS file .", "code_input": "from astropy.io import fitsfrom astropy.visualization import simple_normfrom astropy.modeling import modelsfrom astropy.coordinates import SkyCoordfrom astropy.time import Timefrom astroplan import Observer# Define the coordinates of the sourcecoord = SkyCoord(ra=10.0, dec=20.0, frame='icrs')# Define the time of the observationtime = Time('2022-01-01 00:00:00')# Define the observerobserver = Observer(coord)# Define the source modelsource_model = models.Gaussian1D()# Fit the model to the datasource_model.fit(coord.transform_into(observer.celestial))# Create a new F", "url": "34b2636593edbd5cd8975c050f2db4ac", "gt": "def write_fits ( self , fitsfile ) : tab = self . create_table ( ) hdu_data = fits . table_to_hdu ( tab ) hdus = [ fits . PrimaryHDU ( ) , hdu_data ] fits_utils . write_hdus ( hdus , fitsfile )"}, {"nl_input": "return an iterator that returns a chunk of a string every time it is called . notice that even though bufsize_type might be line buffered we re not doing any line buffering here . that s because our StreamBufferer handles all buffering . we just need to return a reasonable - sized chunk .", "code_input": "class StreamBufferer:    def __init__(self, string, chunk_size):        self.string = string        self.chunk_size = chunk_size        self.index = 0    def __iter__(self):        return self    def __next__(self):        if self.index + self.chunk_size > len(self.string):            raise StopIteration        chunk = self.string[self.index : self.index + self.chunk_size]        self.index += self.chunk_size        return chunk# Usagestring = \"Hello, world!\"chunk_size = 5bufferer = StreamBufferer(string, chunk_size)for chunk in bufferer:    print(chunk)", "url": "b66381638399324a2212ecf9179e9699", "gt": "def get_iter_string_reader ( stdin ) : bufsize = 1024 iter_str = ( stdin [ i : i + bufsize ] for i in range ( 0 , len ( stdin ) , bufsize ) ) return get_iter_chunk_reader ( iter_str )"}, {"nl_input": "kill process Args : process - Popen object for process", "code_input": "import subprocessdef kill_process(process):    # Check if the process is running    if process.poll() is None:        # Kill the process        process.kill()    else:        print(\"The process is already killed or not running\")", "url": "ff5650a6fb621a5dd82d24d3fdc0acc1", "gt": "def kill_mprocess ( process ) : if process and proc_alive ( process ) : process . terminate ( ) process . communicate ( ) return not proc_alive ( process )"}, {"nl_input": "Convert a UTC datetime to a Unix timestamp", "code_input": "import timefrom datetime import datetimedef convert_utc_to_unix(utc_datetime):    unix_timestamp = time.mktime(utc_datetime.timetuple())    return unix_timestamputc_datetime = datetime.utcnow()unix_timestamp = convert_utc_to_unix(utc_datetime)print(unix_timestamp)", "url": "e81cce5fd2d39302c2607c85226f94d8", "gt": "def datetime_to_timestamp ( dt ) : delta = dt - datetime . utcfromtimestamp ( 0 ) return delta . seconds + delta . days * 24 * 3600"}, {"nl_input": "Remove and return the item at index .", "code_input": "def remove_and_return(lst, index):    if index < len(lst):        return lst.pop(index)    else:        return \"Index out of range\"# Test the functionlst = [1, 2, 3, 4, 5]index = 2print(remove_and_return(lst, index))  # Output: 3", "url": "e13e58839609a1526153c3e30429efd5", "gt": "def pop ( self , index = - 1 ) : value = self . _list . pop ( index ) del self . _dict [ value ] return value"}, {"nl_input": "Load the correct module according to the version", "code_input": "import sysdef load_module(version):    if version == '1.0':        import module1_0        return module1_0    elif version == '2.0':        import module2_0        return module2_0    else:        print(\"Invalid version\")        return Noneversion = sys.argv[1]  # Get the version from the command line argumentsmodule = load_module(version)if module is not None:    print(f\"Loaded module: {module}\")else:    print(\"Failed to load module\")", "url": "cd7a724a7a438604f3c2ad7be5002c74", "gt": "def load_library ( version ) : check_version ( version ) module_name = SUPPORTED_LIBRARIES [ version ] lib = sys . modules . get ( module_name ) if lib is None : lib = importlib . import_module ( module_name ) return lib"}, {"nl_input": "Convert a string to a list with sanitization .", "code_input": "def sanitize_string(s):    return [char for char in s if char.isalpha()]s = \"Hello, World!\"print(sanitize_string(s))", "url": "1e5368f3b43db029f24ec30a718ddd75", "gt": "def _str_to_list ( value , separator ) : value_list = [ item . strip ( ) for item in value . split ( separator ) ] value_list_sanitized = builtins . list ( filter ( None , value_list ) ) if len ( value_list_sanitized ) > 0 : return value_list_sanitized else : raise ValueError ( 'Invalid list variable.' )"}, {"nl_input": "Transparently unzip the file handle", "code_input": "def unzip_file_handle(file_handle):    # Get the file contents as a list of tuples    file_contents = list(file_handle)    # Unzip the file contents    unzipped_contents = list(zip(*file_contents))    return unzipped_contents", "url": "4df8b32d822042305892bf4e9ffbf95a", "gt": "def _unzip_handle ( handle ) : if isinstance ( handle , basestring ) : handle = _gzip_open_filename ( handle ) else : handle = _gzip_open_handle ( handle ) return handle"}, {"nl_input": "Called when a new DropDownItem gets selected .", "code_input": "import tkinter as tkdef on_dropdown_change(event):    selected_value = event.widget.get()    print(f\"Selected value: {selected_value}\")root = tk.Tk()dropdown = tk.OptionMenu(root, value, *options)dropdown.pack()root.mainloop()", "url": "bbc7873866d390e8731cc146e44f537d", "gt": "def onchange ( self , value ) : log . debug ( 'combo box. selected %s' % value ) self . select_by_value ( value ) return ( value , )"}, {"nl_input": "The standard deviation of a set of values . Pass in the mean if you already know it .", "code_input": "def standard_deviation(values, mean=None):    if mean is None:        mean = sum(values) / len(values)    return sum((x - mean) ** 2 for x in values) / len(values)", "url": "058eaf9c0c5351b7b551170db3cfeb8a", "gt": "def stddev ( values , meanval = None ) : #from AI: A Modern Appproach if meanval == None : meanval = mean ( values ) return math . sqrt ( sum ( [ ( x - meanval ) ** 2 for x in values ] ) / ( len ( values ) - 1 ) )"}, {"nl_input": "Return time in milliseconds from start_time", "code_input": "import time# Assuming start_time is the time when the query is executedstart_time = time.time() * 1000# Your code here# Calculate the time difference in millisecondstime_difference = time.time() * 1000 - start_timeprint(time_difference)", "url": "d49558a22ad4625b2bbd4e37fe9b2f37", "gt": "def timespan ( start_time ) : timespan = datetime . datetime . now ( ) - start_time timespan_ms = timespan . total_seconds ( ) * 1000 return timespan_ms"}, {"nl_input": "Adds the supplied dict as a new entity", "code_input": "def add_dict_to_entity(entity, new_dict):    # Check if the new dictionary is not empty    if new_dict:        # Add the new dictionary to the entity        entity.update(new_dict)    return entity", "url": "043f36a47ed7073d2532d69e54bbd43d", "gt": "def add ( self , entity ) : result = self . _http_req ( 'connections' , method = 'POST' , payload = entity ) status = result [ 'status' ] if not status == 201 : raise ServiceRegistryError ( status , \"Couldn't add entity\" ) self . debug ( 0x01 , result ) return result [ 'decoded' ]"}, {"nl_input": "Get tuple ( actually a generator ) of indices where the max value of array x occurs . Requires that x have a max () method as x . max () ( in the case of NumPy ) is much faster than max ( x ) . For a simpler faster argmax when there is only a single maximum entry or when knowing only the first index where the maximum occurs call argmax () on a NumPy array .", "code_input": "import numpy as npdef max_indices(x):    return np.where(x == np.max(x))# Test the functionx = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])print(max_indices(x))", "url": "b63b959eb91b99f3a70976d46e49ae48", "gt": "def MultiArgMax ( x ) : m = x . max ( ) return ( i for i , v in enumerate ( x ) if v == m )"}, {"nl_input": "Do all elements of x have a type from types?", "code_input": "def check_type(x, types):    for t in types:        if not all(isinstance(i, t) for i in x):            return False    return True", "url": "5ab579ff3b2ee7681b98e2869ba83148", "gt": "def _valid_other_type ( x , types ) : return all ( any ( isinstance ( el , t ) for t in types ) for el in np . ravel ( x ) )"}, {"nl_input": "Helper method to check if a set of types is the { AnyObject } singleton", "code_input": "def is_singleton(types):    return len(types) == 1 and isinstance(next(iter(types)), type)", "url": "ddc17c866549c6ed7d51235989c860c8", "gt": "def is_any_type_set ( sett : Set [ Type ] ) -> bool : return len ( sett ) == 1 and is_any_type ( min ( sett ) )"}, {"nl_input": "Write a numpy array to YAML .", "code_input": "import numpy as npimport yaml# Create a numpy arrayarr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])# Convert the numpy array to a YAML filewith open('array.yaml', 'w') as file:    documents = yaml.dump(arr, file)", "url": "68912019b18c412305b0cdb7486fec01", "gt": "def numpy_to_yaml ( representer : Representer , data : np . ndarray ) -> Sequence [ Any ] : return representer . represent_sequence ( \"!numpy_array\" , data . tolist ( ) )"}, {"nl_input": "get the covarince between two points implied by Vario2d", "code_input": "def covariance(point1, point2):    # Calculate the differences    diff_x = point1[0] - point2[0]    diff_y = point1[1] - point2[1]    # Calculate the covariance    covariance = diff_x * diff_y    return covariance# Test the functionpoint1 = (3, 5)point2 = (6, 9)print(covariance(point1, point2))", "url": "1cc6545a29dbb49958711e7c2b5d549f", "gt": "def covariance ( self , pt0 , pt1 ) : x = np . array ( [ pt0 [ 0 ] , pt1 [ 0 ] ] ) y = np . array ( [ pt0 [ 1 ] , pt1 [ 1 ] ] ) names = [ \"n1\" , \"n2\" ] return self . covariance_matrix ( x , y , names = names ) . x [ 0 , 1 ]"}, {"nl_input": "Compare two strings if all contiguous whitespace is coalesced .", "code_input": "def compare_strings(str1, str2):    # Remove all whitespace from both strings    str1 = str1.replace(\" \", \"\")    str2 = str2.replace(\" \", \"\")    # Compare the coalesced strings    if str1 == str2:        return True    else:        return False# Test the functionstr1 = \"Hello World\"str2 = \"HelloWorld\"print(compare_strings(str1, str2))  # Output: True", "url": "5b70ae74acdc38b5b21bbe84441c0c9d", "gt": "def assert_looks_like ( first , second , msg = None ) : first = _re . sub ( \"\\s+\" , \" \" , first . strip ( ) ) second = _re . sub ( \"\\s+\" , \" \" , second . strip ( ) ) if first != second : raise AssertionError ( msg or \"%r does not look like %r\" % ( first , second ) )"}, {"nl_input": "Check if required dependency is installed", "code_input": "try:    import numpyexcept ImportError:    print(\"The numpy package is not installed. Please install it using pip.\")    exit(1)", "url": "84e2d66751e0a8ee1b8ae1a7abcdbac3", "gt": "def check ( modname ) : for dependency in DEPENDENCIES : if dependency . modname == modname : return dependency . check ( ) else : raise RuntimeError ( \"Unkwown dependency %s\" % modname )"}, {"nl_input": "Dump Python object as JSON string .", "code_input": "import json# Define your objectobj = {    \"name\": \"John\",    \"age\": 30,    \"city\": \"New York\"}# Dump the object as a JSON stringjson_str = json.dumps(obj)# Print the JSON stringprint(json_str)", "url": "fb7d849f7856e91684a22299e34b8e2d", "gt": "def dump_json ( obj ) : return simplejson . dumps ( obj , ignore_nan = True , default = json_util . default )"}, {"nl_input": "Returns one value if the condition evaluates to TRUE and another value if it evaluates to FALSE", "code_input": "def evaluate_condition(condition):    if condition:        return \"True\"    else:        return \"False\"# Test the functionprint(evaluate_condition(True))  # Output: Trueprint(evaluate_condition(False))  # Output: False", "url": "2552c85beba28c28615849a68c3cbdde", "gt": "def _if ( ctx , logical_test , value_if_true = 0 , value_if_false = False ) : return value_if_true if conversions . to_boolean ( logical_test , ctx ) else value_if_false"}, {"nl_input": "Reads a Python object stored in a specified YAML file .", "code_input": "import yamldef read_python_object_from_yaml(file_path):    with open(file_path, 'r') as file:        data = yaml.safe_load(file)    return data", "url": "fbbe03581abc8a6791e6650ce07ec9ba", "gt": "def ReadManyFromPath ( filepath ) : with io . open ( filepath , mode = \"r\" , encoding = \"utf-8\" ) as filedesc : return ReadManyFromFile ( filedesc )"}, {"nl_input": "Round a time DOWN to half nearest half - hour .", "code_input": "from datetime import datetime, timedeltadef round_time_down(time, unit):    if unit == 'hour':        return time - timedelta(minutes=time.minute % 30)    elif unit == 'minute':        return time - timedelta(seconds=time.second)# Test the functiontime = datetime.now()rounded_time = round_time_down(time, 'hour')print(rounded_time)", "url": "7ef0b3dda0b7af841693956bd803333a", "gt": "def _round_half_hour ( record ) : k = record . datetime + timedelta ( minutes = - ( record . datetime . minute % 30 ) ) return datetime ( k . year , k . month , k . day , k . hour , k . minute , 0 )"}, {"nl_input": "Detach from all tracked classes and objects . Restore the original constructors and cleanse the tracking lists .", "code_input": "import typesdef clean_tracking(module):    for name, obj in vars(module).items():        if isinstance(obj, types.MethodType):            old_func = obj.__code__.co_name            setattr(module, name, types.MethodType(obj.__func__, module))            delattr(module, old_func)        elif isinstance(obj, types.FunctionType):            old_func = obj.__name__            setattr(module, name, types.FunctionType(obj.__code__, module.__dict__))            delattr(module, old_func)        elif isinstance(obj, type):            old_init = obj.__init__            setattr(module, name, type(obj))            delattr(module, '__init__')            module.__init__ = old_initdef restore_constructors(module):    for name, obj in vars", "url": "c6cd16b1f8c53bd52a696c9afd132194", "gt": "def detach_all ( self ) : self . detach_all_classes ( ) self . objects . clear ( ) self . index . clear ( ) self . _keepalive [ : ] = [ ]"}, {"nl_input": "True if the json_element passed is present for the task specified .", "code_input": "def check_json_element(json_element, task_specified):    if task_specified in json_element:        return True    else:        return False", "url": "e8395d634fd7e19cbe150042998fd059", "gt": "def task_property_present_predicate ( service , task , prop ) : try : response = get_service_task ( service , task ) except Exception as e : pass return ( response is not None ) and ( prop in response )"}, {"nl_input": "Splits a string into parts at multiple characters", "code_input": "def split_string(string, delimiters):    return string.split(delimiters)# Test the functionstring = \"Hello, World! How are you?\"delimiters = \", \"print(split_string(string, delimiters))", "url": "7d09bf15750d9a6d6c96b7cee93c93a3", "gt": "def _split ( string , splitters ) : part = '' for character in string : if character in splitters : yield part part = '' else : part += character yield part"}, {"nl_input": "Empty the range from start to stop .", "code_input": "def empty_range(start, stop):    for i in range(start, stop):        i = Noneempty_range(0, 10)", "url": "df5d600ef0977e23ecd997c06192235b", "gt": "def empty ( self , start = None , stop = None ) : self . set ( NOT_SET , start = start , stop = stop )"}, {"nl_input": "Converts an ARRAY string stored in the database back into a Numpy array .", "code_input": "import numpy as np# Assuming the string is stored in a variable called 'data'data = \"1,2,3,4,5\"# Convert the string to a list of numbersnumbers = list(map(int, data.split(',')))# Convert the list to a Numpy arrayarray = np.array(numbers)print(array)", "url": "7ab4dcc303b95f41a8e282a1be11765c", "gt": "def convert_array ( array ) : out = io . BytesIO ( array ) out . seek ( 0 ) return np . load ( out )"}, {"nl_input": "Internal function to overcome pickling problem in python2 .", "code_input": "import cPickle as pickledef pickle_object(obj):    \"\"\"    Pickle a Python object    \"\"\"    return pickle.dumps(obj)def unpickle_object(pickled_obj):    \"\"\"    Unpickle a Python object    \"\"\"    return pickle.loads(pickled_obj)", "url": "6f49a9d3d5434a4da776633e29108547", "gt": "def _parallel_compare_helper ( class_obj , pairs , x , x_link = None ) : return class_obj . _compute ( pairs , x , x_link )"}, {"nl_input": "Python 3 input () / Python 2 raw_input ()", "code_input": "def get_user_input():    user_input = input()    return user_input", "url": "080fc0fc8b3ab53b0bf658fa8b4f0b09", "gt": "def string_input ( prompt = '' ) : v = sys . version [ 0 ] if v == '3' : return input ( prompt ) else : return raw_input ( prompt )"}, {"nl_input": "Build argument parsers .", "code_input": "import argparse# Create the parserparser = argparse.ArgumentParser(description='Process some integers.')# Add the argumentsparser.add_argument('integers', metavar='N', type=int, nargs='+',                    help='an integer for the accumulator')parser.add_argument('--sum', dest='accumulate', action='store_const',                    const=sum, default=max,                    help='sum the integers (default: find the max)')# Execute parse_args()args = parser.parse_args()# Use the accumulate functionprint(args.accumulate(args.integers))", "url": "3f4199e0fe99241698056724f54fe656", "gt": "def build_parser ( ) : parser = argparse . ArgumentParser ( \"Release packages to pypi\" ) parser . add_argument ( '--check' , '-c' , action = \"store_true\" , help = \"Do a dry run without uploading\" ) parser . add_argument ( 'component' , help = \"The component to release as component-version\" ) return parser"}, {"nl_input": "Return only the part of the row which should be printed .", "code_input": "data = [    {'name': 'John', 'age': 28, 'city': 'New York'},    {'name': 'Jane', 'age': 30, 'city': 'Chicago'},    {'name': 'Bob', 'age': 25, 'city': 'San Francisco'}]for row in data:    print(row['name'], row['city'])", "url": "c90da7779a167e77043c04ce9292eb6e", "gt": "def _get_printable_columns ( columns , row ) : if not columns : return row # Extract the column values, in the order specified. return tuple ( row [ c ] for c in columns )"}, {"nl_input": "Returns day number of the last day of the month : param t : datetime : return : int", "code_input": "from datetime import datetime, timedeltadef last_day_of_month(t):    next_month = t.replace(day=28) + timedelta(days=4)  # this will never fail    return next_month.day", "url": "820668a155ea53034787f1042a2328c0", "gt": "def get_last_day_of_month ( t : datetime ) -> int : tn = t + timedelta ( days = 32 ) tn = datetime ( year = tn . year , month = tn . month , day = 1 ) tt = tn - timedelta ( hours = 1 ) return tt . day"}, {"nl_input": "Return a flatten version of the nested argument", "code_input": "def flatten(lst):    result = []    for i in lst:        if isinstance(i, list):            result.extend(flatten(i))        else:            result.append(i)    return result", "url": "746e950661be8d29bb8cf497c2bb802a", "gt": "def flatten ( nested ) : flat_return = list ( ) def __inner_flat ( nested , flat ) : for i in nested : __inner_flat ( i , flat ) if isinstance ( i , list ) else flat . append ( i ) return flat __inner_flat ( nested , flat_return ) return flat_return"}, {"nl_input": "HTTP request method of interface implementation .", "code_input": "import requestsdef make_request(url):    response = requests.get(url)    return response.status_code# Replace 'http://example.com' with the URL you want to accessurl = 'http://example.com'print(make_request(url))", "url": "81f78b855d5b8fe9705ac46615003bea", "gt": "def _request ( self , method : str , endpoint : str , params : dict = None , data : dict = None , headers : dict = None ) -> dict :"}, {"nl_input": "Helper method to check if a set of types is the { AnyObject } singleton", "code_input": "def is_singleton(types):    return len(types) == 1 and isinstance(next(iter(types)), type)", "url": "ddc17c866549c6ed7d51235989c860c8", "gt": "def is_any_type_set ( sett : Set [ Type ] ) -> bool : return len ( sett ) == 1 and is_any_type ( min ( sett ) )"}, {"nl_input": "Convert a numpy row - major homogenous transformation matrix to a flat column - major GLfloat transformation .", "code_input": "import numpy as npdef convert_to_flat(matrix):    # Reshape the matrix to column-major    flat_matrix = matrix.flatten()    # Convert the numpy array to a list of GLfloat    gl_float_list = flat_matrix.tolist()    return gl_float_list# Test the functionmatrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])print(convert_to_flat(matrix))", "url": "59d8da7afcf5b0e96574ac4215a35798", "gt": "def matrix_to_gl ( matrix ) : matrix = np . asanyarray ( matrix , dtype = np . float64 ) if matrix . shape != ( 4 , 4 ) : raise ValueError ( 'matrix must be (4,4)!' ) # switch to column major and flatten to (16,) column = matrix . T . flatten ( ) # convert to GLfloat glmatrix = ( gl . GLfloat * 16 ) ( * column ) return glmatrix"}, {"nl_input": "Remove legend for axes or gca .", "code_input": "import matplotlib.pyplot as plt# Get the current axesax = plt.gca()# Remove the legendax.legend()", "url": "84f9940c4dee76cc18b2c7cf263add76", "gt": "def remove_legend ( ax = None ) : from pylab import gca , draw if ax is None : ax = gca ( ) ax . legend_ = None draw ( )"}, {"nl_input": "Return a tuple from parsing a b c d - > ( a b c d )", "code_input": "import sysdef parse_args():    args = sys.argv[1:]    if len(args) != 4:        print(\"Usage: python script.py a b c d\")        sys.exit(1)    return tuple(args)a, b, c, d = parse_args()print((a, b, c, d))", "url": "971e5642fa7223efcc06c337dca4248b", "gt": "def _parse_tuple_string ( argument ) : if isinstance ( argument , str ) : return tuple ( int ( p . strip ( ) ) for p in argument . split ( ',' ) ) return argument"}, {"nl_input": "Return a Python date that corresponds to the specified string representation .", "code_input": "from datetime import datetimedef string_to_date(date_string):    return datetime.strptime(date_string, '%Y-%m-%d')# Test the functiondate_string = '2022-01-01'print(string_to_date(date_string))", "url": "dfec582c3aa4ec5eaafa97cc052f017e", "gt": "def string_to_date ( value ) : if isinstance ( value , datetime . date ) : return value return dateutil . parser . parse ( value ) . date ( )"}, {"nl_input": "get an x and y numpy . ndarray that spans the + / - 4 standard deviation range of a gaussian distribution with a given mean and standard deviation . useful for plotting", "code_input": "import numpy as npdef generate_gaussian_data(mean, std_dev, size):    return np.random.normal(mean, std_dev, size)# Test the functionmean = 0std_dev = 4size = 1000x = generate_gaussian_data(mean, std_dev, size)", "url": "8d2a0bf0c1937e144da08f9d53432914", "gt": "def gaussian_distribution ( mean , stdev , num_pts = 50 ) : xstart = mean - ( 4.0 * stdev ) xend = mean + ( 4.0 * stdev ) x = np . linspace ( xstart , xend , num_pts ) y = ( 1.0 / np . sqrt ( 2.0 * np . pi * stdev * stdev ) ) * np . exp ( - 1.0 * ( ( x - mean ) ** 2 ) / ( 2.0 * stdev * stdev ) ) return x , y"}, {"nl_input": "Calls the specified Trigger of another Area with the optionally given parameters .", "code_input": "def call_trigger(area, trigger_name, param1=None, param2=None):    # Import the module containing the trigger    import importlib    # Dynamically import the trigger module    trigger_module = importlib.import_module(f'areas.{area}.{trigger_name}')    # Call the trigger function with the given parameters    result = trigger_module.trigger(param1, param2)    return result", "url": "93fd9d04ea0ba686378532352580da58", "gt": "def trigger ( self , target : str , trigger : str , parameters : Dict [ str , Any ] = { } ) : pass"}, {"nl_input": "Presenter to force yaml . dump to use multi - line string style .", "code_input": "import yaml# Define the dictionarydata = {    \"name\": \"John\",    \"age\": 30,    \"city\": \"New York\"}# Use the yaml.dump method to dump the dictionary to a YAML file# The 'default_flow_style' parameter is set to False to use multi-line string stylewith open('data.yaml', 'w') as file:    yaml.dump(data, file, default_flow_style=False)", "url": "d04afb88b8e76370816e10e2ef0489ce", "gt": "def string_presenter ( self , dumper , data ) : if '\\n' in data : return dumper . represent_scalar ( 'tag:yaml.org,2002:str' , data , style = '|' ) else : return dumper . represent_scalar ( 'tag:yaml.org,2002:str' , data )"}, {"nl_input": "Returns a function that is only callable once ; any other call will do nothing", "code_input": "def only_once():    called = False    def wrapper():        nonlocal called        if not called:            called = True            return \"Function is only callable once\"        else:            return \"Function is already called\"    return wrapper", "url": "e3cab059569d3c5bbd974a42e0a7a488", "gt": "def _callable_once ( func ) : def once ( * args , * * kwargs ) : if not once . called : once . called = True return func ( * args , * * kwargs ) once . called = False return once"}, {"nl_input": "create a graphviz graph from text", "code_input": "import graphvizdef create_graph_from_text(text):    dot = graphviz.Digraph(format='png')    lines = text.split('\\n')    for line in lines:        words = line.split(' ')        if len(words) > 1:            dot.edge(words[0], words[1])    return dottext = \"\"\"    A -> B    B -> C    C -> D    D -> E    E -> A\"\"\"dot = create_graph_from_text(text)dot.render('graph')", "url": "c492f4d1b811b4b2f599b2b594ef2fa4", "gt": "def _text_to_graphiz ( self , text ) : dot = Source ( text , format = 'svg' ) return dot . pipe ( ) . decode ( 'utf-8' )"}, {"nl_input": "Get the next value in the page .", "code_input": "from bs4 import BeautifulSoupimport requestsdef get_next_value(url):    response = requests.get(url)    soup = BeautifulSoup(response.text, 'html.parser')    # Assuming the next value is the first one in the list    next_value = soup.find('div', {'class': 'next-value'}).text    return next_value# Replace 'your_url' with the actual URL of the pagenext_value = get_next_value('your_url')print(next_value)", "url": "1cd8598eada8e6213ad9a5841079e3a4", "gt": "def next ( self ) : item = six . next ( self . _item_iter ) result = self . _item_to_value ( self . _parent , item ) # Since we've successfully got the next value from the # iterator, we update the number of remaining. self . _remaining -= 1 return result"}, {"nl_input": "Instanciates a new * Document * from this collection", "code_input": "from pymongo import MongoClient# Create a new MongoDB clientclient = MongoClient('mongodb://localhost:27017/')# Connect to the 'mydatabase' databasedb = client['mydatabase']# Instanciates a new 'Document' from this collectiondocument = db['collection']# Print the new documentprint(document)", "url": "4bae73fa2bdaf7b167050bf6b5c09902", "gt": "def __call__ ( self , * args , * * kwargs ) : kwargs [ \"mongokat_collection\" ] = self return self . document_class ( * args , * * kwargs )"}, {"nl_input": "given a segment ( rectangle ) and an image returns it s corresponding subimage", "code_input": "from PIL import Imagedef get_subimage(rectangle, image):    # Get the rectangle's coordinates    x1, y1, x2, y2 = rectangle    # Get the image's size    width, height = image.size    # Check if the rectangle is out of the image's bounds    if x1 < 0 or y1 < 0 or x2 > width or y2 > height:        return None    # Get the subimage    subimage = image.crop(rectangle)    return subimage", "url": "adf1e40be190a7d6a349c02a10d5a420", "gt": "def region_from_segment ( image , segment ) : x , y , w , h = segment return image [ y : y + h , x : x + w ]"}, {"nl_input": "Formats the given number in decimal format using a period and commas", "code_input": "def format_number(num):    return \"{:,}\".format(num)# Test the functionprint(format_number(1000000))", "url": "6c190d35f3b002574675f1e3ab001e73", "gt": "def fixed ( ctx , number , decimals = 2 , no_commas = False ) : value = _round ( ctx , number , decimals ) format_str = '{:f}' if no_commas else '{:,f}' return format_str . format ( value )"}, {"nl_input": "decode ( bytearray raw = False ) - > value", "code_input": "def decode(raw):    if raw:        return raw.decode()    else:        return \"The input is not a bytearray\"", "url": "57a4c6f385e589e91cd6625dab4b410e", "gt": "def decode ( self , bytes , raw = False ) : return struct . unpack ( self . format , buffer ( bytes ) ) [ 0 ]"}, {"nl_input": "Fetch an image from url and convert it into a Pillow Image object", "code_input": "from PIL import Imageimport requestsfrom io import BytesIOdef fetch_image(url):    response = requests.get(url)    img = Image.open(BytesIO(response.content))    return img", "url": "927f00ae21352b1a481fdb3b3a998709", "gt": "def url_to_image ( url ) : r = requests . get ( url ) image = StringIO ( r . content ) return image"}, {"nl_input": "Convolve 2d gaussian .", "code_input": "import numpy as npdef gaussian_2d_convolution(image, kernel_size, sigma):    # Calculate the dimensions of the image and kernel    image_height, image_width = image.shape    kernel_height, kernel_width = kernel_size    # Calculate the dimensions of the output image    output_height = image_height - kernel_height + 1    output_width = image_width - kernel_width + 1    # Create a zero output image    output_image = np.zeros((output_height, output_width))    # Calculate the center of the kernel    kernel_center_y = kernel_height // 2    kernel_center_x = kernel_width // 2    # Loop over the output image    for y in range(output_height):        for x in range(output_width):            # Calculate the sum of the product of the kernel and the image            sum = 0", "url": "e9c213af9e538bd916581d4896dba6bb", "gt": "def convolve_gaussian_2d ( image , gaussian_kernel_1d ) : result = scipy . ndimage . filters . correlate1d ( image , gaussian_kernel_1d , axis = 0 ) result = scipy . ndimage . filters . correlate1d ( result , gaussian_kernel_1d , axis = 1 ) return result"}, {"nl_input": "assert that the mock was called only once .", "code_input": "import unittestfrom unittest.mock import patch, MagicMockclass TestMock(unittest.TestCase):    @patch('module.function')    def test_mock(self, mock_function):        mock_function.return_value = 'mocked_value'        result = mock_function()        self.assertEqual(result, 'mocked_value')        mock_function.assert_called_once()if __name__ == '__main__':    unittest.main()", "url": "283407ebde908befdeb4f9e9a180dcad", "gt": "def assert_called_once ( _mock_self ) : self = _mock_self if not self . call_count == 1 : msg = ( \"Expected '%s' to have been called once. Called %s times.\" % ( self . _mock_name or 'mock' , self . call_count ) ) raise AssertionError ( msg )"}, {"nl_input": "The l2 norm of an array is is defined as : sqrt ( ||x|| ) where ||x|| is the dot product of the vector .", "code_input": "import numpy as npdef l2_norm(array):    return np.sqrt(np.dot(array, array))# Test the functionarray = np.array([1, 2, 3, 4])print(l2_norm(array))", "url": "6eae45bb8c323c115cf65c7a07fdcc89", "gt": "def l2_norm ( arr ) : arr = np . asarray ( arr ) return np . sqrt ( np . dot ( arr . ravel ( ) . squeeze ( ) , arr . ravel ( ) . squeeze ( ) ) )"}, {"nl_input": "Lock connection from being used else where", "code_input": "import psycopg2from psycopg2 import OperationalErrordef create_conn():    conn = None    try:        conn = psycopg2.connect(            database=\"your_database\",            user=\"your_username\",            password=\"your_password\",            host=\"localhost\",            port=\"5432\"        )        print(\"Connection successful\")    except OperationalError as e:        print(f\"The error '{e}' occurred\")    return conndef lock_connection(conn):    if conn is not None:        conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)        print(\"Connection locked\")    else:        print(\"Connection is not open\")conn = create_conn()lock_connection(conn)", "url": "816895340ccbbbb54d93a01f6a2e90d8", "gt": "def lock ( self , block = True ) : self . _locked = True return self . _lock . acquire ( block )"}, {"nl_input": "Calculate the MD5 hash for a file .", "code_input": "import hashlibdef calculate_md5_hash(file_path):    with open(file_path, 'rb') as f:        bytes = f.read()  # read entire file as bytes        readable_hash = hashlib.md5(bytes).hexdigest()  # convert bytes to hash        return readable_hash# usageprint(calculate_md5_hash('path_to_your_file'))", "url": "26bc7d3a200bdf0ca8e1859c261311a2", "gt": "def get_file_md5sum ( path ) : with open ( path , 'rb' ) as fh : h = str ( hashlib . md5 ( fh . read ( ) ) . hexdigest ( ) ) return h"}, {"nl_input": "Get a ctypes void pointer to the memory mapped region .", "code_input": "import ctypes# Assume this is your function that returns a void pointer to a memory-mapped regiondef get_memory_mapped_region():    # This is a placeholder for your function. Replace it with your actual function.    pass# Get a void pointer to the memory-mapped regionmemory_mapped_region_ptr = ctypes.c_void_p()get_memory_mapped_region(ctypes.byref(memory_mapped_region_ptr))print(memory_mapped_region_ptr.value)", "url": "fec232c19895c2355a9c5e0943bd3500", "gt": "def pointer ( self ) : return ctypes . cast ( ctypes . pointer ( ctypes . c_uint8 . from_buffer ( self . mapping , 0 ) ) , ctypes . c_void_p )"}, {"nl_input": "Return a DataFrame with the duplicated values of the column col_name in df .", "code_input": "import pandas as pd# Assuming df is your DataFrame and 'col_name' is the column you want to duplicateduplicated_df = df[['col_name']].drop_duplicates()# The result is a new DataFrame with the duplicated values of 'col_name'", "url": "71ac2d55c8dc09493dd8ee9bf38f707a", "gt": "def duplicated_rows ( df , col_name ) : _check_cols ( df , [ col_name ] ) dups = df [ pd . notnull ( df [ col_name ] ) & df . duplicated ( subset = [ col_name ] ) ] return dups"}, {"nl_input": "Validates an email address Source : Himanshu Shankar ( https : // github . com / iamhssingh ) Parameters ---------- email : str", "code_input": "import redef validate_email(email):    pattern = r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"    if re.match(pattern, email):        return True    else:        return False# Test the functionprint(validate_email(\"example@gmail.com\"))  # Trueprint(validate_email(\"example.com\"))  # False", "url": "c6194fe5a34f0e66d7c6f7108b41e3c2", "gt": "def validate_email ( email ) : from django . core . validators import validate_email from django . core . exceptions import ValidationError try : validate_email ( email ) return True except ValidationError : return False"}, {"nl_input": "Loads a floating point value from a memory address . If 2nd arg . start with * it is always treated as an indirect value .", "code_input": "import ctypesdef load_float_from_address(address, indirect=False):    if indirect:        # If the address is an indirect value, dereference it        ptr_type = ctypes.POINTER(ctypes.c_float)        ptr = ptr_type.from_address(address)        value = ptr.contents.value    else:        # Otherwise, load the float value from the address        value = ctypes.c_float(address).value    return value# Test the functionaddress = id(1.0)value = load_float_from_address(address)print(value)", "url": "036b4c02ed9098fec68a728552683cf6", "gt": "def _loadf ( ins ) : output = _float_oper ( ins . quad [ 2 ] ) output . extend ( _fpush ( ) ) return output"}, {"nl_input": "Promise an object of class cls with content members .", "code_input": "class cls:    def __init__(self, content):        self.content = content", "url": "06e514824a4cbc11df6792c766d1107e", "gt": "def create_object ( cls , members ) : obj = cls . __new__ ( cls ) obj . __dict__ = members return obj"}, {"nl_input": "Turns a Python unicode string list into a Java String array .", "code_input": "def python_to_java(python_list):    java_list = [str(i) for i in python_list]    return java_list", "url": "cb7ea10fe8e12a61d1c4426495277b2b", "gt": "def string_list_to_array ( l ) : result = javabridge . get_env ( ) . make_object_array ( len ( l ) , javabridge . get_env ( ) . find_class ( \"java/lang/String\" ) ) for i in range ( len ( l ) ) : javabridge . get_env ( ) . set_object_array_element ( result , i , javabridge . get_env ( ) . new_string_utf ( l [ i ] ) ) return result"}, {"nl_input": "Get the list of distinct values with preserving order .", "code_input": "def get_distinct_values(input_list):    return list(set(input_list))input_list = [1, 2, 2, 3, 4, 4, 4, 5, 6, 6, 7, 8, 8, 8, 9, 9]print(get_distinct_values(input_list))", "url": "328596b5f38ea5aea10ae6d53e289f18", "gt": "def distinct ( xs ) : # don't use collections.OrderedDict because we do support Python 2.6 seen = set ( ) return [ x for x in xs if x not in seen and not seen . add ( x ) ]"}, {"nl_input": "This removes newlines and multiple spaces from a string .", "code_input": "def remove_newlines_and_spaces(input_string):    return ' '.join(input_string.split())# Test the functioninput_string = \"This is a test string\\n with multiple   spaces   and newlines.\"print(remove_newlines_and_spaces(input_string))", "url": "ffaf50749737d70a6ecb6ce9b0f9ac24", "gt": "def normalize_value ( text ) : result = text . replace ( '\\n' , ' ' ) result = re . subn ( '[ ]{2,}' , ' ' , result ) [ 0 ] return result"}, {"nl_input": "Checks if key exists in datastore . True if yes False if no .", "code_input": "def check_key_exists(datastore, key):    if key in datastore:        return True    else:        return False", "url": "cca5dd52a3d19626fff09249a49c1508", "gt": "def check_key ( self , key : str ) -> bool : keys = self . get_keys ( ) return key in keys"}, {"nl_input": "last row or column of square A", "code_input": "def last_row_or_column(matrix):    if matrix:        return matrix[-1]    else:        return None# Test the functionmatrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]print(last_row_or_column(matrix))  # Output: [7, 8, 9]matrix = [[1, 2], [3, 4], [5, 6]]print(last_row_or_column(matrix))  # Output: [5, 6]matrix = [[1]]print(last_row_or_column(matrix))  # Output: [1]matrix = []print(last_row_or_column(matrix))  # Output: None", "url": "cffe83a2e89929847264ed6d72d2bfca", "gt": "def other_ind ( self ) : return np . full ( self . n_min , self . size - 1 , dtype = np . int )"}, {"nl_input": "Split a multiline string into a list excluding blank lines .", "code_input": "def split_string(s):    return [line for line in s.split('\\n') if line.strip() != '']# Test the functionmultiline_string = \"\"\"This is line 1.This is line 2.This is line 3 with a blank line.This is line 4.\"\"\"print(split_string(multiline_string))", "url": "aea5c1280e87fefede7936dd80701640", "gt": "def split_multiline ( value ) : return [ element for element in ( line . strip ( ) for line in value . split ( '\\n' ) ) if element ]"}, {"nl_input": "Call this on an lxml . etree document to remove all namespaces", "code_input": "from lxml import etreedef remove_namespaces(xml_string):    xml_doc = etree.fromstring(xml_string)    xml_doc.normalize()    return etree.tostring(xml_doc, pretty_print=True, encoding='unicode')# Test the functionxml_string = '<root xmlns=\"http://example.com\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://example.com test.xsd\">Test</root>'print(remove_namespaces(xml_string))", "url": "4897101b66976544fdacfbf2e9c0905c", "gt": "def remove_namespaces ( root ) : for elem in root . getiterator ( ) : if not hasattr ( elem . tag , 'find' ) : continue i = elem . tag . find ( '}' ) if i >= 0 : elem . tag = elem . tag [ i + 1 : ] objectify . deannotate ( root , cleanup_namespaces = True )"}, {"nl_input": "Ends an indentation block leaving an empty line afterwards", "code_input": "print(\"Hello, World!\")", "url": "42b3324ffb7137bc277bcb02f986b8c2", "gt": "def end_block ( self ) : self . current_indent -= 1 # If we did not add a new line automatically yet, now it's the time! if not self . auto_added_line : self . writeln ( ) self . auto_added_line = True"}, {"nl_input": "shows structured information of a object list tuple etc", "code_input": "# Define a list of tupleslist_of_tuples = [(1, 'a'), (2, 'b'), (3, 'c')]# Iterate over the list of tuplesfor i, tuple in enumerate(list_of_tuples):    # Print the index and the content of each tuple    print(f\"Tuple {i+1}: {tuple}\")", "url": "8d8f80a0b950b795f1c8a086acdd7118", "gt": "def var_dump ( * obs ) : i = 0 for x in obs : str = var_dump_output ( x , 0 , ' ' , '\\n' , True ) print ( str . strip ( ) ) #dump(x, 0, i, '', object) i += 1"}, {"nl_input": "Print a list in tabular format Based on https : // stackoverflow . com / a / 8356620", "code_input": "import requestsfrom bs4 import BeautifulSoup# Make a request to the websiter = requests.get(\"https://stackoverflow.com/a/8356620\")r.content# Parse the content with BeautifulSoupsoup = BeautifulSoup(r.content, 'html.parser')# Find the table with the class 'votes'table = soup.find('table', {'class': 'votes'})# Find all the rows in the tablerows = table.find_all('tr')# Initialize an empty list to store the datadata = []# Loop through each rowfor row in rows:    # Find all the columns in the row    cols = row.find_all('td')    # Append the data to the list    data.append([col.text.strip() for col in cols])# Print the data in a tabular formatfor d in data:   ", "url": "fdf9c3138a50fcd116a6a649d76c6fd5", "gt": "def __print_table ( table ) : col_width = [ max ( len ( x ) for x in col ) for col in zip ( * table ) ] print ( \"| \" + \" | \" . join ( \"{:{}}\" . format ( x , col_width [ i ] ) for i , x in enumerate ( table [ 0 ] ) ) + \" |\" ) print ( \"| \" + \" | \" . join ( \"{:{}}\" . format ( '-' * col_width [ i ] , col_width [ i ] ) for i , x in enumerate ( table [ 0 ] ) ) + \" |\" ) for line in table [ 1 : ] : print ( \"| \" + \" | \" . join ( \"{:{}}\" . format ( x , col_width [ i ] ) for i , x in enumerate ( line ) ) + \" |\" )"}, {"nl_input": "Get domain part of an url .", "code_input": "from urllib.parse import urlparsedef get_domain(url):    domain = urlparse(url).netloc    return domain", "url": "e252a286af69716cea212276bf27704f", "gt": "def get_domain ( url ) : parse_result = urlparse ( url ) domain = \"{schema}://{netloc}\" . format ( schema = parse_result . scheme , netloc = parse_result . netloc ) return domain"}, {"nl_input": "Move the turtle forward .", "code_input": "import turtle# Create a new turtle screen and set its background colorscreen = turtle.Screen()screen.bgcolor(\"white\")# Create a new turtlet = turtle.Turtle()# Set the speed of the turtlet.speed(1)# Move the turtle forwardt.forward(100)", "url": "a90e229ae60bf14f33825c5a2076279a", "gt": "def forward ( self , step ) : x = self . pos_x + math . cos ( math . radians ( self . rotation ) ) * step y = self . pos_y + math . sin ( math . radians ( self . rotation ) ) * step prev_brush_state = self . brush_on self . brush_on = True self . move ( x , y ) self . brush_on = prev_brush_state"}, {"nl_input": "Request the power state of the server .", "code_input": "import psutildef get_power_state():    # Get the current power state    power_state = psutil.power()    # Return the power state    return power_stateprint(get_power_state())", "url": "4df736d409ad256e418ff40790a155c7", "gt": "def get_host_power_status ( self ) : sushy_system = self . _get_sushy_system ( PROLIANT_SYSTEM_ID ) return GET_POWER_STATE_MAP . get ( sushy_system . power_state )"}, {"nl_input": "Print out system information ( version MAC addrs ) .", "code_input": "import platformimport socketdef print_system_info():    print(\"System Information:\")    print(\"-------------------\")    print(\"OS: \", platform.system())    print(\"OS Version: \", platform.release())    print(\"MAC Address: \", socket.gethostbyname(socket.gethostname()))print_system_info()", "url": "a9ce795a398353c1a729dd88e9f36571", "gt": "async def sysinfo ( dev : Device ) : click . echo ( await dev . get_system_info ( ) ) click . echo ( await dev . get_interface_information ( ) )"}, {"nl_input": "Only return cursor instance if configured for multiselect", "code_input": "import mysql.connector# Establish a connection to the databasecnx = mysql.connector.connect(user='username', password='password',                              host='hostname', database='database_name')# Create a cursor instancecursor = cnx.cursor(dictionary=True)# Check if the cursor is multiselectif cursor.with_rows:    print(\"Cursor is multiselect\")else:    print(\"Cursor is not multiselect\")# Close the cursor and connectioncursor.close()cnx.close()", "url": "3517a110d923d3d76980623ab8f32f0a", "gt": "def get_python ( self ) : if self . multiselect : return super ( MultiSelectField , self ) . get_python ( ) return self . _get ( )"}, {"nl_input": "Process an iterable of dictionaries . For each dictionary d delete d [ key ] if it exists .", "code_input": "def process_dicts(dicts):    for d in dicts:        if 'key' in d:            del d['key']    return dicts", "url": "9c7542a2ddb9b898a1ef814aa988a382", "gt": "def dictlist_wipe_key ( dict_list : Iterable [ Dict ] , key : str ) -> None : for d in dict_list : d . pop ( key , None )"}, {"nl_input": "Builds a comment .", "code_input": "# This is a comment in Python# This is another type of commentprint(\"This is a Python comment\")", "url": "ec7551975fa7792ee15876bf8a1fd28d", "gt": "def to_comment ( value ) : if value is None : return if len ( value . split ( '\\n' ) ) == 1 : return \"* \" + value else : return '\\n' . join ( [ ' * ' + l for l in value . split ( '\\n' ) [ : - 1 ] ] )"}, {"nl_input": "Returns a temporary filename based on filename .", "code_input": "import osimport tempfiledef generate_temp_filename(filename):    _, temp_filename = tempfile.mkstemp(suffix=filename)    return temp_filename", "url": "5d64d35b32b31a5d6d02bfa0b6d93eff", "gt": "def get_incomplete_path ( filename ) : random_suffix = \"\" . join ( random . choice ( string . ascii_uppercase + string . digits ) for _ in range ( 6 ) ) return filename + \".incomplete\" + random_suffix"}, {"nl_input": "Makes a HEAD requests to the URI .", "code_input": "import requestsdef make_head_request(uri):    response = requests.head(uri)    return response.status_code# Test the functionprint(make_head_request(\"http://example.com\"))", "url": "1de08117571a8ec22d8964787f402111", "gt": "def dir_exists ( self ) : r = requests . request ( self . method if self . method else 'HEAD' , self . url , * * self . storage_args ) try : r . raise_for_status ( ) except Exception : return False return True"}, {"nl_input": "Utility function to remove duplicates from a list : param seq : The sequence ( list ) to deduplicate : return : A list with original duplicates removed", "code_input": "def remove_duplicates(seq):    return list(set(seq))", "url": "695e29d80ca42056024f20cf87ce69a0", "gt": "def dedupe_list ( seq ) : seen = set ( ) return [ x for x in seq if not ( x in seen or seen . add ( x ) ) ]"}, {"nl_input": "Ensure that path in URL with authority starts with a leading slash .", "code_input": "def check_path_starts_with_slash(url):    path = url.split('/')[1:]    if path[0] == '':        return True    else:        return False", "url": "c1479c1418466abefea9034bbb795fa5", "gt": "def _validate_authority_uri_abs_path ( host , path ) : if len ( host ) > 0 and len ( path ) > 0 and not path . startswith ( \"/\" ) : raise ValueError ( \"Path in a URL with authority \" \"should start with a slash ('/') if set\" )"}, {"nl_input": "Forcefully delete objects from memory", "code_input": "import gcdef force_delete_objects():    gc.collect()    print(\"All objects deleted from memory\")force_delete_objects()", "url": "54e361163495de66afd390a12edfd5bd", "gt": "def cleanup ( self ) : for instance in self . context : del ( instance ) for plugin in self . plugins : del ( plugin )"}, {"nl_input": "Checks whether all number in the sequence s lie inside the interval formed by l and r .", "code_input": "def check_interval(s, l, r):    for num in s:        if not l <= num <= r:            return False    return True", "url": "b81cfdd240c83e76a6587150b51a1068", "gt": "def are_in_interval ( s , l , r , border = 'included' ) : return numpy . all ( [ IntensityRangeStandardization . is_in_interval ( x , l , r , border ) for x in s ] )"}, {"nl_input": "Enforce HTML escaping . This will probably double escape variables .", "code_input": "import htmldef escape_html(input_string):    return html.escape(input_string)", "url": "3dd1d55124da3efc3cb4dcc02a252531", "gt": "def do_forceescape ( value ) : if hasattr ( value , '__html__' ) : value = value . __html__ ( ) return escape ( unicode ( value ) )"}, {"nl_input": "Logarithmic loss with non - necessarily - binary labels .", "code_input": "import numpy as npdef log_loss(y_true, y_pred):    # Check if y_true and y_pred are numpy arrays    if not isinstance(y_true, np.ndarray) or not isinstance(y_pred, np.ndarray):        raise ValueError(\"y_true and y_pred must be numpy arrays\")    # Check if y_true and y_pred have the same shape    if y_true.shape != y_pred.shape:        raise ValueError(\"y_true and y_pred must have the same shape\")    # Check if y_true and y_pred contain only 0s and 1s    if not np.all(np.in1d(y_true, [0, 1])) or not np.all(np.in1d(y_pred, [0, 1])):        raise ValueError(\"y_true and y_pred must contain only 0s and 1s\")", "url": "a7e256b73adf2d656acee870a3a79760", "gt": "def log_loss ( preds , labels ) : log_likelihood = np . sum ( labels * np . log ( preds ) ) / len ( preds ) return - log_likelihood"}, {"nl_input": "Compute Pearson correlation coefficient .", "code_input": "def compute_pearson_correlation(x, y):    # Check if the lists are of the same length    if len(x) != len(y):        return \"Error: Lists are of different lengths\"    # Calculate the mean of the lists    mean_x = sum(x) / len(x)    mean_y = sum(y) / len(y)    # Calculate the covariance and standard deviation    covariance = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))    std_dev = (sum((xi - mean_x) ** 2 for xi in x) / len(x)) ** 0.5    # Return the Pearson correlation coefficient    return covariance / (len(x) * std_dev)# Test the functionx = [1, 2, 3, 4", "url": "95479cad0b74fe06bcd262b9f5750cff", "gt": "def cor ( y_true , y_pred ) : y_true , y_pred = _mask_nan ( y_true , y_pred ) return np . corrcoef ( y_true , y_pred ) [ 0 , 1 ]"}, {"nl_input": "save something to a pickle file", "code_input": "import pickle# Data to be saveddata = {    'name': 'John',    'age': 30,    'city': 'New York'}# Open a file in binary mode 'wb'with open('data.pickle', 'wb') as f:    # Use pickle.dump() to write the object to the file    pickle.dump(data, f)", "url": "a0c6bdbe745a48b0c5ff9e6435ea812c", "gt": "def pickle_save ( thing , fname ) : pickle . dump ( thing , open ( fname , \"wb\" ) , pickle . HIGHEST_PROTOCOL ) return thing"}, {"nl_input": "Calculates the request payload size", "code_input": "import requestsdef calculate_payload_size(url):    response = requests.get(url)    return len(response.text)# Test the functionurl = 'http://example.com'print(calculate_payload_size(url))", "url": "96a858eabc728fc5967a94fb8288ff8b", "gt": "def calculate_size ( name , function ) : data_size = 0 data_size += calculate_size_str ( name ) data_size += calculate_size_data ( function ) return data_size"}, {"nl_input": "Draw a horizontal line up to a given length .", "code_input": "def draw_line(length):    for i in range(length):        print(\"*\", end=\"\")# Test the functiondraw_line(10)", "url": "bb672ed0a0391881ee18bccacf406e44", "gt": "def hline ( self , x , y , width , color ) : self . rect ( x , y , width , 1 , color , fill = True )"}, {"nl_input": "Should we skip logging for this handler?", "code_input": "import loggingdef my_handler(event, context):    # Set up logging    logging.basicConfig(level=logging.INFO)    logger = logging.getLogger(__name__)    # Log the event and context    logger.info('Event: %s', event)    logger.info('Context: %s', context)    # Your handler code here    # ...    return 'Success'", "url": "e9004b0eb97dd8833d1979057cf3557e", "gt": "def should_skip_logging ( func ) : disabled = strtobool ( request . headers . get ( \"x-request-nolog\" , \"false\" ) ) return disabled or getattr ( func , SKIP_LOGGING , False )"}, {"nl_input": "Strip agents from a string .", "code_input": "def remove_agents(s):    return s.replace('agent', '')# Test the functionprint(remove_agents('This is an agent test string'))", "url": "939f688bbd8bfbcb8630b0f3636c5c14", "gt": "def strip_accents ( text ) : normalized_str = unicodedata . normalize ( 'NFD' , text ) return '' . join ( [ c for c in normalized_str if unicodedata . category ( c ) != 'Mn' ] )"}, {"nl_input": "Returns a copy of the list without duplicates .", "code_input": "def remove_duplicates(input_list):    return list(set(input_list))# Test the functioninput_list = [1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 9]print(remove_duplicates(input_list))", "url": "3cbb0d61a47fcf107eb90adf46f865af", "gt": "def unique ( list ) : unique = [ ] [ unique . append ( x ) for x in list if x not in unique ] return unique"}, {"nl_input": "Returns xlwt . pattern for pyspread style", "code_input": "import xlwtdef create_pattern(style_name, fore_color, back_color):    style = xlwt.XFStyle()    # Set the pattern foreground color    pattern_fg = xlwt.Pattern()    pattern_fg.pattern = xlwt.Pattern.SOLID_PATTERN    pattern_fg.pattern_fore_colour = fore_color    # Set the pattern background color    pattern_bg = xlwt.Pattern()    pattern_bg.pattern = xlwt.Pattern.SOLID_PATTERN    pattern_bg.pattern_back_colour = back_color    # Apply the pattern to the style    style.pattern = pattern_fg    style.pattern.pattern_back_colour = pattern_bg.pattern_back_colour    # Create a new style with the pattern    new_style = xlwt.XFStyle()    new_style.pattern", "url": "9c92cc076049eee7eda2f0428ba69851", "gt": "def _get_pattern ( self , pys_style ) : # Return None if there is no bgcolor if \"bgcolor\" not in pys_style : return pattern = xlwt . Pattern ( ) pattern . pattern = xlwt . Pattern . SOLID_PATTERN bgcolor = wx . Colour ( ) bgcolor . SetRGB ( pys_style [ \"bgcolor\" ] ) pattern . pattern_fore_colour = self . color2idx ( * bgcolor . Get ( ) ) return pattern"}, {"nl_input": "Returns the key which comes before the give key .", "code_input": "def get_key_before(d, key):    keys = list(d.keys())    index = keys.index(key)    if index == 0:        return None    else:        return keys[index - 1]", "url": "a9f49c41a4259bbd6e398fd943917f8f", "gt": "def previous_key ( tuple_of_tuples , key ) : for i , t in enumerate ( tuple_of_tuples ) : if t [ 0 ] == key : try : return tuple_of_tuples [ i - 1 ] [ 0 ] except IndexError : return None"}, {"nl_input": "Synthesize white noise", "code_input": "import numpy as npdef generate_white_noise(duration, sample_rate):    time = np.arange(0, duration, 1/sample_rate)    white_noise = np.random.randn(len(time))    return time, white_noiseduration = 1  # in secondssample_rate = 44100  # samples per secondtime, white_noise = generate_white_noise(duration, sample_rate)", "url": "f262d61c7690f2df3b731ba862e94301", "gt": "def synthesize ( self , duration ) : sr = self . samplerate . samples_per_second seconds = duration / Seconds ( 1 ) samples = np . random . uniform ( low = - 1. , high = 1. , size = int ( sr * seconds ) ) return AudioSamples ( samples , self . samplerate )"}, {"nl_input": "Given a sequence convert it to a comma separated string . If however the argument is a single object return its string representation .", "code_input": "def convert_sequence(seq):    if isinstance(seq, (list, tuple, set)):        return ','.join(str(i) for i in seq)    elif isinstance(seq, str):        return seq    else:        return str(seq)", "url": "933992c3c30c3e7204a12c26102f4cff", "gt": "def seq_to_str ( obj , sep = \",\" ) : if isinstance ( obj , string_classes ) : return obj elif isinstance ( obj , ( list , tuple ) ) : return sep . join ( [ str ( x ) for x in obj ] ) else : return str ( obj )"}, {"nl_input": "Apply gzip compression to a response .", "code_input": "import gzipimport iodef compress_response(response):    compressed_response = gzip.compress(bytes(response, 'utf-8'))    return compressed_response", "url": "01df1f7502b37cbfa0c1093f3ac8af8d", "gt": "def _gzip ( self , response ) : bytesio = six . BytesIO ( ) with gzip . GzipFile ( fileobj = bytesio , mode = 'w' ) as gz : gz . write ( response ) return bytesio . getvalue ( )"}, {"nl_input": "Check if given string is a punctuation", "code_input": "def is_punctuation(s):    return not s or not s.strip() or not s[-1].isprintable()# Test the functionprint(is_punctuation(\"!\"))  # Trueprint(is_punctuation(\"Hello, world!\"))  # Falseprint(is_punctuation(\"\"))  # Falseprint(is_punctuation(\" \"))  # Falseprint(is_punctuation(\"   \"))  # Falseprint(is_punctuation(\"!\"))  # True", "url": "e4b57fbe5c67f44a11eb1116c674b42e", "gt": "def is_punctuation ( text ) : return not ( text . lower ( ) in config . AVRO_VOWELS or text . lower ( ) in config . AVRO_CONSONANTS )"}, {"nl_input": "Check if key is in adict . The search is case insensitive .", "code_input": "def check_key(dict, key):    return key.lower() in dict.keys()# Test the functiondict = {'Name': 'Zara', 'Age': 7, 'Class': 'First'}key = 'name'print(check_key(dict, key))  # Output: True", "url": "da943b499fe7be187ec7e73bf3623c8f", "gt": "def contains_case_insensitive ( adict , akey ) : for key in adict : if key . lower ( ) == akey . lower ( ) : return True return False"}, {"nl_input": "Uses the default Plone sortable_text index lower - case", "code_input": "from Products.CMFCore.utils import getToolByNamedef case_insensitive_sort(context):    catalog = getToolByName(context, 'portal_catalog')    sort_expression = 'sortable_text'    sort_order = 'ascending'    catalog.sort_by(sort_expression, sort_order, case_sensitive=False)", "url": "bf8ce0236578b4476e2e2300f7e64037", "gt": "def sortable_title ( instance ) : title = plone_sortable_title ( instance ) if safe_callable ( title ) : title = title ( ) return title . lower ( )"}, {"nl_input": "Returns mean of non - None elements of the list", "code_input": "def mean_of_non_none(lst):    non_none_elements = [x for x in lst if x is not None]    if len(non_none_elements) == 0:        return None    return sum(non_none_elements) / len(non_none_elements)", "url": "fdb8b5e3cd38ee9a1c11aac2eb093594", "gt": "def _aggr_mean ( inList ) : aggrSum = 0 nonNone = 0 for elem in inList : if elem != SENTINEL_VALUE_FOR_MISSING_DATA : aggrSum += elem nonNone += 1 if nonNone != 0 : return aggrSum / nonNone else : return None"}, {"nl_input": "Write a dict to a JSON file .", "code_input": "import json# Define the dictionarydata = {    'name': 'John',    'age': 30,    'city': 'New York'}# Convert the dictionary to JSONjson_data = json.dumps(data)# Write the JSON data to a filewith open('data.json', 'w') as f:    f.write(json_data)", "url": "380b53a3dd3846cf3bce78ed3f7cb50d", "gt": "def _write_json ( file , contents ) : with open ( file , 'w' ) as f : return json . dump ( contents , f , indent = 2 , sort_keys = True )"}, {"nl_input": "Performs drag a element to another elmenet .", "code_input": "import tkinter as tkfrom tkinter import messageboxdef start_drag(event):    global element    element = event.widget    element.start_point = event.x_root, event.y_rootdef perform_drop(event):    global element    if element is not None:        element.place(x=event.x_root, y=event.y_root)        element = Noneroot = tk.Tk()# Create two buttonsbutton1 = tk.Button(root, text=\"Drag Me\")button1.bind(\"<Button-1>\", start_drag)button1.pack()button2 = tk.Button(root, text=\"Drop Here\")button2.bind(\"<Button-1>\", perform_drop)button2.pack()root.main", "url": "76d7727145c20df82e3cdd84ce19c14e", "gt": "def drag_and_drop ( self , droppable ) : self . scroll_to ( ) ActionChains ( self . parent . driver ) . drag_and_drop ( self . _element , droppable . _element ) . perform ( )"}, {"nl_input": "Shape a list of lists into the appropriate shape and data type", "code_input": "def shape_list(lst):    # Check if the list is empty    if not lst:        return []    # Get the first element of the list    first_element = lst[0]    # If the first element is a list, recursively call the function    if isinstance(first_element, list):        return [shape_list(first_element)]    # If the first element is not a list, create a new list with the first element    else:        return [first_element]# Test the functionlst = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]print(shape_list(lst))", "url": "75029e9b5315bf8366b2c9d646b179e4", "gt": "def shape_list ( l , shape , dtype ) : return np . array ( l , dtype = dtype ) . reshape ( shape )"}, {"nl_input": "Convenience method for just changing font size .", "code_input": "import tkinter as tkfrom tkinter import ttkdef change_font_size(size):    # Create a new tkinter window    root = tk.Tk()    # Create a label widget    label = ttk.Label(root, text=\"Hello, World!\")    # Set the font size of the label    label.config(font=(\"Arial\", size))    # Pack the label into the window    label.pack()    # Start the tkinter event loop    root.mainloop()# Call the function with a font size of 20change_font_size(20)", "url": "9b8369463483ff7acf0d48fdb0173ba3", "gt": "def set_font_size ( self , size ) : if self . font . font_size == size : pass else : self . font . _set_size ( size )"}, {"nl_input": "Converts from a Minigo coordinate to a GTP coordinate .", "code_input": "def minigo_to_gtp(minigo_coord):    # Split the Minigo coordinate into x and y    x, y = minigo_coord.split(' ')    # Convert x and y to integers    x = int(x)    y = int(y)    # Convert to GTP coordinates    gtp_x = x + 10    gtp_y = y + 10    return f\"{gtp_x} {gtp_y}\"# Test the functionprint(minigo_to_gtp(\"1 1\"))  # Output: 11 11", "url": "f80f557e979d5bad8c10b42ac118bcda", "gt": "def to_gtp ( coord ) : if coord is None : return 'pass' y , x = coord return '{}{}' . format ( _GTP_COLUMNS [ x ] , go . N - y )"}, {"nl_input": "Run verbose PyLint on source . Optionally specify fmt = html for HTML output .", "code_input": "import pylint# Specify the source filesource_file = 'source.py'# Create the linterlinter = pylint.pylint.PyLint()# Run PyLint and specify the source filelinter.lint_file(source_file)# Specify the output formatfmt = 'html'# Run PyLint with the specified output formatlinter.reporter.generate_reports([fmt])", "url": "4e7fc7292467413a1cfacc5b3c233894", "gt": "def lint ( fmt = 'colorized' ) : if fmt == 'html' : outfile = 'pylint_report.html' local ( 'pylint -f %s davies > %s || true' % ( fmt , outfile ) ) local ( 'open %s' % outfile ) else : local ( 'pylint -f %s davies || true' % fmt )"}, {"nl_input": "Select rows where the given field is not None .", "code_input": "import pandas as pd# Assuming df is your DataFrame and 'field' is the column you want to checkdf = pd.DataFrame({    'field': ['value1', 'value2', None, 'value4', None]})# Select rows where 'field' is not Nonedf_filtered = df[df['field'].notnull()]print(df_filtered)", "url": "4637b5cbf53ffd9b5dc57fa7dddb71b9", "gt": "def selectnotnone ( table , field , complement = False ) : return select ( table , field , lambda v : v is not None , complement = complement )"}, {"nl_input": "Return random lognormal variates .", "code_input": "import numpy as npdef generate_lognormal_variates(mean, sd, size):    return np.random.lognormal(mean, sd, size)# Test the functionmean = 5sd = 1size = 100print(generate_lognormal_variates(mean, sd, size))", "url": "9688e9bb942e9ce1c123ba0b5179f748", "gt": "def rlognormal ( mu , tau , size = None ) : return np . random . lognormal ( mu , np . sqrt ( 1. / tau ) , size )"}, {"nl_input": "Returns the last location of the minimal value of x . The position is calculated relatively to the length of x .", "code_input": "def find_last_min_location(x):    if not x:        return None    min_val = min(x)    min_index = x.index(min_val)    return len(x) - 1 - min_index# Test the functionx = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]print(find_last_min_location(x))  # Output: 0", "url": "22f1d49b1969ee7e89c6533b9e92988f", "gt": "def last_location_of_minimum ( x ) : x = np . asarray ( x ) return 1.0 - np . argmin ( x [ : : - 1 ] ) / len ( x ) if len ( x ) > 0 else np . NaN"}, {"nl_input": "!", "code_input": "def factorial(n):    if n == 0:        return 1    else:        return n * factorial(n-1)print(factorial(5))", "url": "fc1326a05fcddae2c66c888da1670117", "gt": "def manhattan_distance_numpy ( object1 , object2 ) : return numpy . sum ( numpy . absolute ( object1 - object2 ) , axis = 1 ) . T"}, {"nl_input": "1x1 convolution", "code_input": "import numpy as npdef convolution_1x1(input_matrix, filter_matrix):    # Get the dimensions of the input and filter    input_height, input_width = input_matrix.shape    filter_height, filter_width = filter_matrix.shape    # Calculate the dimensions of the output    output_height = input_height - filter_height + 1    output_width = input_width - filter_width + 1    # Create a zero output matrix    output_matrix = np.zeros((output_height, output_width))    # Perform the convolution    for i in range(output_height):        for j in range(output_width):            # Slice the input and filter for the current output position            output_matrix[i, j] = np.sum(input_matrix[i:i+filter_height, j:j+filter_width] * filter_matrix)    return output_matrix# Test the function", "url": "1c63a8f567508c2dbbd974597db516e0", "gt": "def conv1x1 ( in_planes , out_planes , stride = 1 ) : return nn . Conv2d ( in_planes , out_planes , kernel_size = 1 , stride = stride , bias = False )"}, {"nl_input": "Configuration - friendly boolean type converter .", "code_input": "def friendly_boolean_converter(boolean):    if boolean:        return \"Yes\"    else:        return \"No\"", "url": "5effe214bd4eb37a839bd6cc85d96f1d", "gt": "def boolean ( value ) : if isinstance ( value , bool ) : return value if value == \"\" : return False return strtobool ( value )"}, {"nl_input": "Return the 2 - D size of a Jacobian matrix in tuple", "code_input": "def jacobian_2d_size(jacobian):    if isinstance(jacobian, list):        return len(jacobian), len(jacobian[0])    else:        return 0, 0# Test the functionjacobian = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]print(jacobian_2d_size(jacobian))", "url": "1cc69e1108c67013d1749b1e3b2f697c", "gt": "def get_size ( self , m ) : nrow , ncol = 0 , 0 if m [ 0 ] == 'F' : nrow = self . n elif m [ 0 ] == 'G' : nrow = self . m if m [ 1 ] == 'x' : ncol = self . n elif m [ 1 ] == 'y' : ncol = self . m return nrow , ncol"}, {"nl_input": "Check whether the provided value is a valid enum constant .", "code_input": "def is_valid_enum_constant(value, enum_class):    return hasattr(enum_class, value)", "url": "aeee8726b5988ca3cfb4cf62da5ad292", "gt": "def check ( self , var ) : if not isinstance ( var , _str_type ) : return False return _enum_mangle ( var ) in self . _consts"}, {"nl_input": "Given a list possibly nested to any level return it flattened .", "code_input": "def flatten(lst):    result = []    for i in lst:        if isinstance(i, list):            result.extend(flatten(i))        else:            result.append(i)    return result", "url": "1b6646003e72c1cab411541d62676516", "gt": "def flatten ( lis ) : new_lis = [ ] for item in lis : if isinstance ( item , collections . Sequence ) and not isinstance ( item , basestring ) : new_lis . extend ( flatten ( item ) ) else : new_lis . append ( item ) return new_lis"}, {"nl_input": "Go to parent directory", "code_input": "import osdef go_to_parent_directory():    os.chdir('..')go_to_parent_directory()", "url": "8089b0416c588b33db7fed71f2648f52", "gt": "def go_to_parent_directory ( self ) : self . chdir ( osp . abspath ( osp . join ( getcwd_or_home ( ) , os . pardir ) ) )"}, {"nl_input": "Create a 20 char passphrase with easily typeable chars .", "code_input": "import stringimport randomdef generate_passphrase(length=20):    # Define the characters that can be used in the passphrase    characters = string.ascii_letters + string.digits + string.punctuation    # Generate a random passphrase    passphrase = ''.join(random.choice(characters) for i in range(length))    return passphraseprint(generate_passphrase())", "url": "dfca7d4ad7f48b18f0ab7973bae010d7", "gt": "def GeneratePassphrase ( length = 20 ) : valid_chars = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\" valid_chars += \"0123456789 ,-_&$#\" return \"\" . join ( random . choice ( valid_chars ) for i in range ( length ) )"}, {"nl_input": "Generate a fresh id", "code_input": "import uuiddef generate_fresh_id():    fresh_id = uuid.uuid4()    return str(fresh_id)print(generate_fresh_id())", "url": "fd0f14db1e14692747016c200776eda9", "gt": "def generate_id ( self ) : if self . use_repeatable_ids : self . repeatable_id_counter += 1 return 'autobaked-{}' . format ( self . repeatable_id_counter ) else : return str ( uuid4 ( ) )"}, {"nl_input": "Convert snake case string to camel case .", "code_input": "def snake_to_camel(snake_str):    components = snake_str.split('_')    return ''.join(x.title() for x in components)# Test the functionprint(snake_to_camel('snake_case_string'))", "url": "b19a39d8871b9aba99c3328dd4a655df", "gt": "def _snake_to_camel_case ( value ) : words = value . split ( \"_\" ) return words [ 0 ] + \"\" . join ( map ( str . capitalize , words [ 1 : ] ) )"}, {"nl_input": "Method that must transform the value from string Ex : if the expected type is int it should return int ( self . _attr )", "code_input": "def transform_string_to_int(self, attr):    try:        return int(attr)    except ValueError:        return attr", "url": "552f0922b8f6a45b814f34ba736cd93d", "gt": "def normalize_field ( self , value ) : if self . default is not None : if value is None or value == '' : value = self . default return value"}, {"nl_input": "Call a C function that takes a pointer as its last argument and return the C object that it contains after the function has finished .", "code_input": "import ctypes# Define the C functionlibc = ctypes.CDLL('libc.so.6')def get_last_argument(func):    # Get the address of the last argument    last_arg_addr = func.arg_area[-1]    # Get the size of the last argument    last_arg_size = ctypes.sizeof(func.arg_area[-1])    # Allocate memory for the last argument    last_arg = ctypes.c_void_p.in_dll(libc, last_arg_addr, last_arg_size)    return last_arg# Define the C functionlibc.my_func.arg_area = ctypes.c_void_p * 1libc.my_func.restype = ctypes.c_void_plibc.my_func.", "url": "0fd6c95993321c05b30171eec7a02101", "gt": "def get_ctype ( rtype , cfunc , * args ) : val_p = backend . ffi . new ( rtype ) args = args + ( val_p , ) cfunc ( * args ) return val_p [ 0 ]"}, {"nl_input": "Format a message in the log", "code_input": "def format_message(message):    return f\"Log: {message}\"# Test the functionprint(format_message(\"This is a test message\"))", "url": "3f0750078e82a7d14d344a26ecdd7721", "gt": "def format ( self , record , * args , * * kwargs ) : return logging . Formatter . format ( self , record , * args , * * kwargs ) . replace ( '\\n' , '\\n' + ' ' * 8 )"}, {"nl_input": "Given a target dct and a dict of { key : default value } pairs calls setdefault for all of those pairs .", "code_input": "def set_default_values(target_dict, default_dict):    for key, value in default_dict.items():        target_dict.setdefault(key, value)    return target_dict", "url": "9bbbb20f503ba46da76eaa77b98784af", "gt": "def setdefaults ( dct , defaults ) : for key in defaults : dct . setdefault ( key , defaults [ key ] ) return dct"}, {"nl_input": "Move datetime 1 year in the chosen direction . unit is a no - op to keep the API the same as the day case", "code_input": "from datetime import datetime, timedeltadef move_year(years, direction, unit):    now = datetime.now()    if direction == 'forward':        if unit == 'day':            new_date = now + timedelta(days=years)        elif unit == 'year':            new_date = now + timedelta(years=years)    elif direction == 'backward':        if unit == 'day':            new_date = now - timedelta(days=years)        elif unit == 'year':            new_date = now - timedelta(years=years)    return new_date# Test the functionprint(move_year(1, 'forward', 'day'))print(move_year(1, 'backward',", "url": "83c7e1fd8666e261b69048f44f984a14", "gt": "def move_datetime_year ( dt , direction , num_shifts ) : delta = relativedelta ( years = + num_shifts ) return _move_datetime ( dt , direction , delta )"}, {"nl_input": "Returns True when the graph has the given edge .", "code_input": "def has_edge(graph, node1, node2):    if node1 in graph and node2 in graph[node1]:        return True    return False", "url": "7ce5918e50714bd3660f99f0a95cbfe9", "gt": "def has_edge ( self , p_from , p_to ) : return p_from in self . _edges and p_to in self . _edges [ p_from ]"}, {"nl_input": ">>> list = [ 0 0 7 ] >>> list_to_str ( list ) 0 0 7", "code_input": "def list_to_str(lst):    return ''.join(str(i) for i in lst)list = [0, 0, 7]print(list_to_str(list))", "url": "bde3fb5a6302302752336ef6267a3877", "gt": "def list_to_str ( list , separator = ',' ) : list = [ str ( x ) for x in list ] return separator . join ( list )"}, {"nl_input": "r Gets the string representation of the given type .", "code_input": "def get_string_representation(obj):    return str(obj)# Test the functionprint(get_string_representation(123))  # Output: '123'print(get_string_representation('hello'))  # Output: 'hello'print(get_string_representation(True))  # Output: 'True'", "url": "2e39bbd87c8e5002835db5c873dc5a66", "gt": "def getTypeStr ( _type ) : if isinstance ( _type , CustomType ) : return str ( _type ) if hasattr ( _type , '__name__' ) : return _type . __name__ return ''"}, {"nl_input": "Return the line number parsed from the comment or 0 .", "code_input": "import redef get_line_number_from_comment(code_string):    lines = code_string.split('\\n')    for i, line in enumerate(lines, start=1):        if line.startswith('#'):            return i    return 0# Test the functioncode_string = \"\"\"# This is a commentdef hello_world():    print(\"Hello, world!\")# This is another commentdef goodbye_world():    print(\"Goodbye, world!\")\"\"\"print(get_line_number_from_comment(code_string))", "url": "fbc86c5f63c6cbab0a4aa72f0faadcaf", "gt": "def _get_line_no_from_comments ( py_line ) : matched = LINECOL_COMMENT_RE . match ( py_line ) if matched : return int ( matched . group ( 1 ) ) else : return 0"}, {"nl_input": "Returns the memory byte size of a Numpy array as an integer .", "code_input": "import numpy as npdef memory_size_of_numpy_array(array):    return array.nbytes# Example usage:array = np.array([1, 2, 3, 4, 5])print(memory_size_of_numpy_array(array))", "url": "f0456030f3cb36953670e94276edb1d5", "gt": "def bytesize ( arr ) : byte_size = np . prod ( arr . shape ) * np . dtype ( arr . dtype ) . itemsize return byte_size"}, {"nl_input": "helper function for quick base conversions from strings to integers", "code_input": "def string_to_int(s):    result = 0    for i, char in enumerate(s[::-1]):        if '0' <= char <= '9':            result += (ord(char) - ord('0')) * (10 ** i)        elif char == '-':            result *= -1        else:            raise ValueError(\"Invalid character in string: \" + char)    return result", "url": "bb7fca42c0c60dc5dcc3212c85ea60c7", "gt": "def str2int ( num , radix = 10 , alphabet = BASE85 ) : return NumConv ( radix , alphabet ) . str2int ( num )"}, {"nl_input": "Return whether an object is a path .", "code_input": "def is_path(obj):    if isinstance(obj, list) and all(isinstance(i, int) for i in obj):        return True    return False", "url": "4edf2a89aa8f5a8713825607f13b3a6c", "gt": "def _is_path ( s ) : if isinstance ( s , string_types ) : try : return op . exists ( s ) except ( OSError , ValueError ) : return False else : return False"}, {"nl_input": "compose a list of functions", "code_input": "def function1():    print(\"Function 1 is running\")def function2():    print(\"Function 2 is running\")def function3():    print(\"Function 3 is running\")def function4():    print(\"Function 4 is running\")def function5():    print(\"Function 5 is running\")functions_list = [function1, function2, function3, function4, function5]", "url": "2842f428a9186c722cb73f43029707ed", "gt": "def compose ( * funcs ) : return lambda x : reduce ( lambda v , f : f ( v ) , reversed ( funcs ) , x )"}, {"nl_input": "Remove any duplicate item preserving order", "code_input": "def remove_duplicates(input_list):    output_list = []    for item in input_list:        if item not in output_list:            output_list.append(item)    return output_listinput_list = [1, 2, 2, 3, 4, 4, 4, 5, 6, 6, 7, 8, 8, 8, 9]print(remove_duplicates(input_list))", "url": "f47adf1dd2cd6ee94174173d4c0dba3f", "gt": "def de_duplicate ( items ) : result = [ ] for item in items : if item not in result : result . append ( item ) return result"}, {"nl_input": "Check if cnr or cns files are empty ( only have a header )", "code_input": "import osdef check_empty_files(file_extension):    # Get the list of all files in the current directory    files = os.listdir('.')    # Check each file    for file in files:        # Check if the file ends with the given extension        if file.endswith(file_extension):            # Check if the file is empty            if os.path.getsize(file) == 0:                return True    return False# Check if cnr or cns files are emptycnr_empty = check_empty_files('cnr')cns_empty = check_empty_files('cns')print(f'cnr files are empty: {cnr_empty}')print(f'cns files are empty: {cns_empty}')", "url": "450cc73f5679416b2729c29d17c5a97f", "gt": "def _cnx_is_empty ( in_file ) : with open ( in_file ) as in_handle : for i , line in enumerate ( in_handle ) : if i > 0 : return False return True"}, {"nl_input": "True if the last two moves were Pass or if the position is at a move greater than the max depth .", "code_input": "def check_position(moves, max_depth):    # Initialize the last two moves    last_two_moves = [None, None]    # Iterate over the moves    for i, move in enumerate(moves):        # If the move is a pass, update the last two moves        if move[1] == 'Pass':            last_two_moves[i % 2] = move        # If the move is a move greater than the max depth, return False        elif move[1] > max_depth:            return False    # If the last two moves were Pass, return True    if last_two_moves[0] is None and last_two_moves[1] is None:        return True    # If the last two moves were", "url": "c4ef266e883c3d9c6e5ae62b8ab668ef", "gt": "def is_done ( self ) : return self . position . is_game_over ( ) or self . position . n >= FLAGS . max_game_length"}, {"nl_input": "Get the current desktop . Uses _NET_CURRENT_DESKTOP of the EWMH spec .", "code_input": "import ctypes# Load the necessary libraryuser32 = ctypes.WinDLL('user32.dll')# Get the current desktopdesktop = user32.GetForegroundWindow()# Print the desktopprint(desktop)", "url": "e5a9e1bb21a3cd7df0858dad0b20c589", "gt": "def get_current_desktop ( self ) : desktop = ctypes . c_long ( 0 ) _libxdo . xdo_get_current_desktop ( self . _xdo , ctypes . byref ( desktop ) ) return desktop . value"}, {"nl_input": "Use numpy to create a real matrix object from the data", "code_input": "import numpy as np# Define the datadata = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]# Use numpy to create a real matrix object from the datamatrix = np.array(data)# Print the matrixprint(matrix)", "url": "a3a4c61e7eea53c9e490604db0b3590b", "gt": "def get_matrix ( self ) : return np . array ( [ self . get_row_list ( i ) for i in range ( self . row_count ( ) ) ] )"}, {"nl_input": "Report whether the given value is a byte or unicode string .", "code_input": "def check_type(value):    if isinstance(value, str):        if value.isascii():            return \"byte\"        else:            return \"unicode\"    else:        return \"not a string\"# Test the functionprint(check_type(\"Hello\"))  # Output: byteprint(check_type(\"H\u00e9llo\"))  # Output: unicodeprint(check_type(\"H\u00ebllo\"))  # Output: unicodeprint(check_type(123))  # Output: not a string", "url": "26c958614bee5fc1c19896b5f0551f81", "gt": "def isstring ( value ) : classes = ( str , bytes ) if pyutils . PY3 else basestring # noqa: F821 return isinstance ( value , classes )"}, {"nl_input": "Read text from file automatically detect encoding . chardet required .", "code_input": "import chardetdef read_file(file_path):    with open(file_path, 'rb') as f:        data = f.read()        encoding = chardet.detect(data)['encoding']        return data.decode(encoding)# Usagefile_path = 'path_to_your_file.txt'print(read_file(file_path))", "url": "9969728e6736bf82b1e9a03044364571", "gt": "def smartread ( path ) : with open ( path , \"rb\" ) as f : content = f . read ( ) result = chardet . detect ( content ) return content . decode ( result [ \"encoding\" ] )"}, {"nl_input": "Clear not used counters", "code_input": "def clear_counters(counters):    for counter in counters:        counter.clear()# Assuming you have a list of counterscounters = [Counter1, Counter2, Counter3]clear_counters(counters)", "url": "1f84fc1e090db77de8d51c7190146975", "gt": "def trim ( self ) : for key , value in list ( iteritems ( self . counters ) ) : if value . empty ( ) : del self . counters [ key ]"}, {"nl_input": "Rewrite a file adding a line to its beginning .", "code_input": "# Open the file in write modewith open('file.txt', 'w') as f:    # Add a line to the beginning of the file    f.write('This is a new line\\n')    # Write the rest of the file    f.write(f.read())", "url": "b58a9251f71e60af76cc02adf3aeb3e2", "gt": "def prepend_line ( filepath , line ) : with open ( filepath ) as f : lines = f . readlines ( ) lines . insert ( 0 , line ) with open ( filepath , 'w' ) as f : f . writelines ( lines )"}, {"nl_input": "Closest distance between a line segment and a point", "code_input": "import mathdef closest_distance(point, line_segment):    # Calculate the distance from the point to the start of the line segment    distance1 = math.sqrt((point[0] - line_segment[0][0])**2 + (point[1] - line_segment[0][1])**2)    # Calculate the distance from the point to the end of the line segment    distance2 = math.sqrt((point[0] - line_segment[1][0])**2 + (point[1] - line_segment[1][1])**2)    # The closest distance is the smaller of the two distances    closest_distance = min(distance1, distance2)    return closest_distance", "url": "9241c85c39ed221796f46af344122ca2", "gt": "def distance_to_line ( a , b , p ) : return distance ( closest_point ( a , b , p ) , p )"}, {"nl_input": "Wrapper on iter method callback gets an iterator result", "code_input": "def callback(item):    # This is your callback function. It should return a value.    return item * 2def iter_method_callback(iterable):    # Use map to apply the callback to each item in the iterable.    return list(map(callback, iterable))# Test the functioniterable = [1, 2, 3, 4, 5]print(iter_method_callback(iterable))  # Output: [2, 4, 6, 8, 10]", "url": "a7ae1c18c06bd04b301a3a9dd6511232", "gt": "def find_all ( self , string , callback ) : for index , output in self . iter ( string ) : callback ( index , output )"}, {"nl_input": "Releases this resource back to the pool it came from .", "code_input": "import gc# Assume we have a resourceresource = \"Some resource\"# We're not sure when it's released, so we'll keep it in a poolgc.set_lock(gc.get_lock())gc.collect()# Now, we can release the resource back to the poolgc.set_lock(None)", "url": "c143548cafea9a3925ec6ee6efc41438", "gt": "def release ( self ) : if self . errored : self . pool . delete_resource ( self ) else : self . pool . release ( self )"}, {"nl_input": "Nested lists to single - level list does not split strings", "code_input": "def flatten(lst):    return [item for sublist in lst for item in sublist]# Test the functionnested_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]print(flatten(nested_list))  # Output: [1, 2, 3, 4, 5, 6, 7, 8, 9]", "url": "fd38a2c403c3400fdc8927dbab88c8c1", "gt": "def flatten_list ( l ) : return list ( chain . from_iterable ( repeat ( x , 1 ) if isinstance ( x , str ) else x for x in l ) )"}, {"nl_input": "Upload the IPList as json payload .", "code_input": "import requestsimport json# Assuming IPList is a list of IP addressesIPList = [\"192.168.1.1\", \"192.168.1.2\", \"192.168.1.3\"]# Convert the list to a JSON stringIPList_json = json.dumps(IPList)# Define the API endpointurl = \"http://api.example.com/endpoint\"# Define the headersheaders = {'Content-Type': 'application/json'}# Send a POST request with the JSON payloadresponse = requests.post(url, data=IPList_json, headers=headers)# Print the responseprint(response.json())", "url": "3c6c3247179fba80a83ab23b9c53b9ef", "gt": "def upload_as_json ( name , mylist ) : location = list ( IPList . objects . filter ( name ) ) if location : iplist = location [ 0 ] return iplist . upload ( json = mylist , as_type = 'json' )"}, {"nl_input": "Return the shape of img .", "code_input": "import cv2def get_image_shape(image_path):    img = cv2.imread(image_path)    return img.shape# Test the functionprint(get_image_shape('path_to_your_image.jpg'))", "url": "cbc0170c46062096a84468b365429079", "gt": "def get_shape ( img ) : if hasattr ( img , 'shape' ) : shape = img . shape else : shape = img . get_data ( ) . shape return shape"}, {"nl_input": "Return list of the key property names for a class", "code_input": "class MyClass:    def __init__(self, name, age, address):        self.name = name        self.age = age        self.address = addressdef get_key_properties(cls):    return list(cls.__dict__.keys())# Test the functionmy_class = MyClass('John', 30, '123 Main St')print(get_key_properties(my_class.__class__))", "url": "662c104ceb549d3c48424fadc1836101", "gt": "def get_keys_from_class ( cc ) : return [ prop . name for prop in cc . properties . values ( ) if 'key' in prop . qualifiers ]"}, {"nl_input": "Call a C function that takes a pointer as its last argument and return the C object that it contains after the function has finished .", "code_input": "import ctypes# Define the C functionlibc = ctypes.CDLL('libc.so.6')def get_last_argument(func):    # Get the address of the last argument    last_arg_addr = func.arg_area[-1]    # Get the size of the last argument    last_arg_size = ctypes.sizeof(func.arg_area[-1])    # Allocate memory for the last argument    last_arg = ctypes.c_void_p.in_dll(libc, last_arg_addr, last_arg_size)    return last_arg# Define the C functionlibc.my_func.arg_area = ctypes.c_void_p * 1libc.my_func.restype = ctypes.c_void_plibc.my_func.", "url": "0fd6c95993321c05b30171eec7a02101", "gt": "def get_ctype ( rtype , cfunc , * args ) : val_p = backend . ffi . new ( rtype ) args = args + ( val_p , ) cfunc ( * args ) return val_p [ 0 ]"}, {"nl_input": "Adds widget attributes to a bound form field .", "code_input": "from django import formsclass MyForm(forms.ModelForm):    my_field = forms.CharField(max_length=100, required=False,                                widget=forms.TextInput(attrs={'class': 'my-custom-class'}))    class Meta:        model = MyModel        fields = ['my_field']", "url": "c33ee1c2506ac02f6f60f8415a7f720a", "gt": "def add_form_widget_attr ( field , attr_name , attr_value , replace = 0 ) : if not replace : attr = field . field . widget . attrs . get ( attr_name , '' ) attr += force_text ( attr_value ) field . field . widget . attrs [ attr_name ] = attr return field else : field . field . widget . attrs [ attr_name ] = attr_value return field"}, {"nl_input": "Run the * cmd * and exit with the proper exit code .", "code_input": "import subprocessdef run_cmd():    subprocess.run([\"ls\", \"-l\"])run_cmd()", "url": "13dc817c65ddde88d2a2ec6eee680a81", "gt": "def call_and_exit ( self , cmd , shell = True ) : sys . exit ( subprocess . call ( cmd , shell = shell ) )"}, {"nl_input": "Merge two dicts and return a new dict . Much like subclassing works .", "code_input": "def merge_dicts(dict1, dict2):    return {**dict1, **dict2}# Test the functiondict1 = {\"a\": 1, \"b\": 2}dict2 = {\"c\": 3, \"d\": 4}merged_dict = merge_dicts(dict1, dict2)print(merged_dict)  # Output: {'a': 1, 'b': 2, 'c': 3, 'd': 4}", "url": "6355dab675855466faa16c64350ef5f7", "gt": "def extend ( a : dict , b : dict ) -> dict : res = a . copy ( ) res . update ( b ) return res"}, {"nl_input": "Load and execute a python file .", "code_input": "# Load the Python fileimport importlib# Specify the name of the Python filepython_file = \"my_python_file.py\"# Load the Python fileimportlib.import_module(python_file)# Execute the Python fileexec(open(python_file).read())", "url": "fafac547be2039f7ecb1de9409b4e007", "gt": "def load_files ( files ) : for py_file in files : LOG . debug ( \"exec %s\" , py_file ) execfile ( py_file , globals ( ) , locals ( ) )"}, {"nl_input": "Fill all null values with NaN values in a column . Null values are None or en empty string", "code_input": "import pandas as pd# Assuming df is your DataFrame and 'column_name' is the name of the column you want to filldf['column_name'] = df['column_name'].fillna(pd.np.nan)", "url": "93c0c2ede9a5c8a8b970af18721497ae", "gt": "def fill_nulls ( self , col : str ) : n = [ None , \"\" ] try : self . df [ col ] = self . df [ col ] . replace ( n , nan ) except Exception as e : self . err ( e )"}, {"nl_input": "Compute boxplot for given pandas Series .", "code_input": "import matplotlib.pyplot as pltdef compute_boxplot(series):    plt.boxplot(series)    plt.show()# Test the functiondata = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]compute_boxplot(data)", "url": "8dd4b555f0e59a0dec7e2a588e55945c", "gt": "def compute_boxplot ( self , series ) : from matplotlib . cbook import boxplot_stats series = series [ series . notnull ( ) ] if len ( series . values ) == 0 : return { } elif not is_numeric_dtype ( series ) : return self . non_numeric_stats ( series ) stats = boxplot_stats ( list ( series . values ) ) [ 0 ] stats [ 'count' ] = len ( series . values ) stats [ 'fliers' ] = \"|\" . join ( map ( str , stats [ 'fliers' ] ) ) return stats"}, {"nl_input": "Returns the index of a geometry in a list of geometries avoiding expensive equality checks of in operator .", "code_input": "def find_geometry(geometries, target):    for i, geometry in enumerate(geometries):        if geometry == target:            return i    return -1", "url": "aebc38a583a508530af17ee1c8fef11f", "gt": "def find_geom ( geom , geoms ) : for i , g in enumerate ( geoms ) : if g is geom : return i"}, {"nl_input": "Transform CamelCase naming convention into C - ish convention .", "code_input": "def camel_to_c_ish(camel_case_string):    # Split the string into words    words = camel_case_string.split('_')    # Capitalize the first word and join the rest with a space    c_ish_string = words[0].lower() + ''.join(word.capitalize() for word in words[1:])    return c_ish_string# Test the functionprint(camel_to_c_ish('camelCaseString'))", "url": "245f32e66d5c23e21c45f22693852c11", "gt": "def uncamel ( name ) : s1 = re . sub ( '(.)([A-Z][a-z]+)' , r'\\1_\\2' , name ) return re . sub ( '([a-z0-9])([A-Z])' , r'\\1_\\2' , s1 ) . lower ( )"}, {"nl_input": "Determine the number of leaves in a tree", "code_input": "def count_leaves(n):    if n == 0:        return 0    else:        return 2**(n-1) + count_leaves(n-1)# Test the functionprint(count_leaves(3))  # Output: 7", "url": "7003757d630c03cf7dd68203952cd4cf", "gt": "def num_leaves ( tree ) : if tree . is_leaf : return 1 else : return num_leaves ( tree . left_child ) + num_leaves ( tree . right_child )"}, {"nl_input": "Use openpyxl to read an Excel file .", "code_input": "from openpyxl import load_workbook# Load the workbookwb = load_workbook(filename='your_file.xlsx')# Select the active worksheetws = wb.active# Access a cell by its row and columncell = ws.cell(row=1, column=1)# Print the value of the cellprint(cell.value)# Close the workbookwb.close()", "url": "3cd62873f26fd670aeecec18cc0dd297", "gt": "def _openpyxl_read_xl ( xl_path : str ) : try : wb = load_workbook ( filename = xl_path , read_only = True ) except : raise else : return wb"}, {"nl_input": "r Like rotate but modifies l in - place .", "code_input": "def rotate(l, k):    k = k % len(l)    l[:] = l[k:] + l[:k]# Test the functionl = [1, 2, 3, 4, 5]rotate(l, 2)print(l)  # Output: [3, 4, 5, 1, 2]", "url": "707569fdd77ebde2ce9e44aeb15df944", "gt": "def iprotate ( l , steps = 1 ) : if len ( l ) : steps %= len ( l ) if steps : firstPart = l [ : steps ] del l [ : steps ] l . extend ( firstPart ) return l"}, {"nl_input": "Recursively converts iterables into tuples .", "code_input": "def convert_to_tuple(iterable):    if isinstance(iterable, (list, tuple, set)):        return tuple(convert_to_tuple(i) for i in iterable)    else:        return iterable", "url": "aea6b9304a9b41f33141846e80e9d158", "gt": "def tuplize ( nested ) : if isinstance ( nested , str ) : return nested try : return tuple ( map ( tuplize , nested ) ) except TypeError : return nested"}, {"nl_input": "Ensures preceding predicates ( specifically : meth : called_with () ) result in * expected_exception * being raised and the string representation of * expected_exception * must match regular expression * expected_regexp * .", "code_input": "import unittestclass TestPredicates(unittest.TestCase):    def test_predicates(self):        # Assuming the function is defined as follows        def method_to_test():            # Assuming the function calls another function            called_with()        # Assuming the function is defined as follows        def called_with():            raise Exception(\"Expected Exception\")        # Assuming the function is defined as follows        def method_to_test():            # Assuming the function calls another function            called_with()        # Assuming the function is defined as follows        def called_with():            raise Exception(\"Expected Exception\")        # Assuming the function is defined as follows        def method_to_test():            # Assuming the function calls another function            called_with()        # Assuming the function is defined as follows", "url": "910b81e1c0bbb58ca384ea2eccf81621", "gt": "def raises_regex ( self , expected_exception , expected_regexp ) : return unittest_case . assertRaisesRegexp ( expected_exception , expected_regexp , self . _orig_subject , * self . _args , * * self . _kwargs )"}, {"nl_input": "Args : x : iterable of strings", "code_input": "def string_lengths(x):    return [(i, len(i)) for i in x]", "url": "24e9010513628fcbcbc40bc6617d3e5c", "gt": "def gen_lower ( x : Iterable [ str ] ) -> Generator [ str , None , None ] : for string in x : yield string . lower ( )"}, {"nl_input": "Remove resource instance from internal cache", "code_input": "class Cache:    def __init__(self):        self.cache = {}    def get(self, key):        # Get the resource instance from the cache        return self.cache.get(key)    def put(self, key, value):        # Put the resource instance into the cache        self.cache[key] = value    def remove(self, key):        # Remove the resource instance from the cache        if key in self.cache:            del self.cache[key]# Usagecache = Cache()cache.put('key1', 'value1')print(cache.get('key1'))  # Output: value1cache.remove('key1')print(cache.get('key1'))  # Output: None", "url": "bf6a4144ae873567dfbd61579c2bba94", "gt": "def __delitem__ ( self , resource ) : self . __caches [ type ( resource ) ] . pop ( resource . get_cache_internal_key ( ) , None )"}, {"nl_input": "Convert this confusion matrix into a 2x2 plain list of values .", "code_input": "def confusion_matrix_to_list(cm):    return [cm[i][j] for i in range(len(cm)) for j in range(len(cm[i]))]# Test the functioncm = [[10, 20], [30, 40]]print(confusion_matrix_to_list(cm))", "url": "c86694b645e5ae2f3a398a6ffb38c3c1", "gt": "def to_list ( self ) : return [ [ int ( self . table . cell_values [ 0 ] [ 1 ] ) , int ( self . table . cell_values [ 0 ] [ 2 ] ) ] , [ int ( self . table . cell_values [ 1 ] [ 1 ] ) , int ( self . table . cell_values [ 1 ] [ 2 ] ) ] ]"}, {"nl_input": "Synthesize white noise", "code_input": "import numpy as npdef generate_white_noise(duration, sample_rate):    time = np.arange(0, duration, 1/sample_rate)    white_noise = np.random.randn(len(time))    return time, white_noiseduration = 1  # in secondssample_rate = 44100  # samples per secondtime, white_noise = generate_white_noise(duration, sample_rate)", "url": "f262d61c7690f2df3b731ba862e94301", "gt": "def synthesize ( self , duration ) : sr = self . samplerate . samples_per_second seconds = duration / Seconds ( 1 ) samples = np . random . uniform ( low = - 1. , high = 1. , size = int ( sr * seconds ) ) return AudioSamples ( samples , self . samplerate )"}, {"nl_input": "disassemble Python byte - code file ( . pyc )", "code_input": "import disdef foo(x):    return x * 2code_object = compile('foo(4)', '<string>', 'exec')dis.dis(code_object)", "url": "765a09c3a704cf281562a8a77a1f8be0", "gt": "def disassemble_file ( filename , outstream = None ) : filename = check_object_path ( filename ) ( version , timestamp , magic_int , co , is_pypy , source_size ) = load_module ( filename ) if type ( co ) == list : for con in co : disco ( version , con , outstream ) else : disco ( version , co , outstream , is_pypy = is_pypy ) co = None"}, {"nl_input": "Return a flatten version of the nested argument", "code_input": "def flatten(lst):    result = []    for i in lst:        if isinstance(i, list):            result.extend(flatten(i))        else:            result.append(i)    return result", "url": "746e950661be8d29bb8cf497c2bb802a", "gt": "def flatten ( nested ) : flat_return = list ( ) def __inner_flat ( nested , flat ) : for i in nested : __inner_flat ( i , flat ) if isinstance ( i , list ) else flat . append ( i ) return flat __inner_flat ( nested , flat_return ) return flat_return"}, {"nl_input": "Asynchronously run the worker does not close connections . Useful when testing .", "code_input": "import aiohttpimport asyncioasync def worker(session, url):    async with session.get(url) as response:        return await response.text()async def main():    async with aiohttp.ClientSession() as session:        tasks = [worker(session, 'http://python.org/') for _ in range(10)]        await asyncio.gather(*tasks)loop = asyncio.get_event_loop()loop.run_until_complete(main())", "url": "74bfcc70541e0daebb0f4db57e3b2a94", "gt": "async def async_run ( self ) -> None : self . main_task = self . loop . create_task ( self . main ( ) ) await self . main_task"}, {"nl_input": "Path to tensorflow_datasets directory .", "code_input": "import pathlib# Get the current working directorycwd = pathlib.Path.cwd()# Get the path to the TensorFlow Datasets directorytensorflow_datasets_dir = cwd / 'tensorflow_datasets'# Print the pathprint(tensorflow_datasets_dir)", "url": "64b730a598a02b60d9a4b7edcc0c6a63", "gt": "def tfds_dir ( ) : return os . path . dirname ( os . path . dirname ( os . path . dirname ( __file__ ) ) )"}, {"nl_input": "Converts from hex to hsv", "code_input": "def hex_to_hsv(hex_color):    # Remove the '#' character from the hex color code    hex_color = hex_color.lstrip('#')    # Convert the hex color code to decimal    decimal_color = int(hex_color, 16)    # Separate the red, green, and blue values    red = (decimal_color >> 16) % 256    green = (decimal_color >> 8) % 256    blue = decimal_color % 256    # Convert the decimal values to floating point    red_float = red / 255.0    green_float = green / 255.0    blue_float = blue / 255.0    # Calculate the maximum and minimum of the RGB values    max_val = max(red_float, green_float, blue_float)    min_val = min(red_float, green_float", "url": "b1e30dc54d4a7c52b1b808729dfb1ec3", "gt": "def hex_to_hsv ( color ) : color = normalize ( color ) color = color [ 1 : ] # color=tuple(ord(c)/255.0 for c in color.decode('hex')) color = ( int ( color [ 0 : 2 ] , base = 16 ) / 255.0 , int ( color [ 2 : 4 ] , base = 16 ) / 255.0 , int ( color [ 4 : 6 ] , base = 16 ) / 255.0 ) return colorsys . rgb_to_hsv ( * color )"}, {"nl_input": "Used when the plot method defined does not create a figure nor calls save_plot Then the plot method has to use self . fig", "code_input": "import matplotlib.pyplot as pltclass MyClass:    def __init__(self):        self.fig = None    def plot(self):        if self.fig is None:            self.fig, self.ax = plt.subplots()        self.ax.plot([1, 2, 3, 4])        self.ax.set_ylabel('some numbers')        if self.fig is not None:            self.fig.savefig('my_plot.png')        return self.fig", "url": "f1fef8351e7337c7f820cb898d402168", "gt": "def plot_and_save ( self , * * kwargs ) : self . fig = pyplot . figure ( ) self . plot ( ) self . axes = pyplot . gca ( ) self . save_plot ( self . fig , self . axes , * * kwargs ) pyplot . close ( self . fig )"}, {"nl_input": "Return the size of a multidimansional array .", "code_input": "def array_size(array):    return len(array)# Test the functionarray = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]print(array_size(array))  # Output: 3", "url": "3658ef914c025d17376c894d11f4e034", "gt": "def array_dim ( arr ) : dim = [ ] while True : try : dim . append ( len ( arr ) ) arr = arr [ 0 ] except TypeError : return dim"}, {"nl_input": "Build documentation as HTML .", "code_input": "import osimport sysimport sphinxfrom sphinx.application import Sphinxdef build_html_docs(source_dir, build_dir):    # Create a Sphinx application    app = Sphinx(        source_dir=source_dir,        build_dir=build_dir,        warning=True,        quiet=True,        builder='html',        doctitle_separator='<',        project='My Project',        version='1.0',        language='en',        master_doc='index',        extensions_dirs=['sphinx.ext.autodoc', 'sphinx.ext.in", "url": "a687d18eb86da6fe54b7cfe32af45a6e", "gt": "def build ( ctx ) : return_code = run_sphinx ( ctx . obj [ 'root_dir' ] ) if return_code > 0 : sys . exit ( return_code )"}, {"nl_input": "Connects to an Access database via ODBC with the DSN prespecified .", "code_input": "import pyodbc# Define the DSNdsn = 'your_dsn'# Create a connectionconn = pyodbc.connect(dsn)# Create a cursorcursor = conn.cursor()# Execute a querycursor.execute('SELECT * FROM your_table')# Fetch all the rowsrows = cursor.fetchall()# Print the rowsfor row in rows:    print(row)# Close the connectionconn.close()", "url": "4b906d8d602bbb965d25996d5a4c5cb1", "gt": "def connect_to_database_odbc_access ( self , dsn : str , autocommit : bool = True ) -> None : self . connect ( engine = ENGINE_ACCESS , interface = INTERFACE_ODBC , dsn = dsn , autocommit = autocommit )"}, {"nl_input": "Return lines of a file with whitespace removed", "code_input": "def remove_whitespace(file_name):    with open(file_name, 'r') as file:        lines = file.readlines()    lines_without_whitespace = [line.replace(' ', '') for line in lines]    return lines_without_whitespace# Usageprint(remove_whitespace('your_file.txt'))", "url": "4cd26ba017dabe234b6b960e4c174cd7", "gt": "def get_stripped_file_lines ( filename ) : try : lines = open ( filename ) . readlines ( ) except FileNotFoundError : fatal ( \"Could not open file: {!r}\" . format ( filename ) ) return [ line . strip ( ) for line in lines ]"}, {"nl_input": "", "code_input": "SELECT * FROM table_name WHERE column_name = 'value';", "url": "7b52bc293ffd1b3acabf6268fe94a913", "gt": "def lines ( self ) : if self . _lines is None : self . _lines = self . obj . content . splitlines ( ) return self . _lines"}, {"nl_input": "Helper to draw lines connecting a set of nodes that are scaled for the Screen .", "code_input": "import matplotlib.pyplot as plt# Assuming you have a list of nodesnodes = [(x, y) for x in range(1, 10) for y in range(1, 10)]# Create a figure and a set of subplotsfig, ax = plt.subplots()# Connect the nodesfor i in range(len(nodes)):    # Connect the current node to the next one    ax.plot([nodes[i][0], nodes[i+1][0]], [nodes[i][1], nodes[i+1][1]], color='black')# Show the plotplt.show()", "url": "c1c960991a9d910480d00ff6f90db309", "gt": "def _draw_lines_internal ( self , coords , colour , bg ) : for i , ( x , y ) in enumerate ( coords ) : if i == 0 : self . _screen . move ( x , y ) else : self . _screen . draw ( x , y , colour = colour , bg = bg , thin = True )"}, {"nl_input": "Return the names of all callable attributes of an object", "code_input": "def get_callable_attributes(obj):    return [attr for attr in dir(obj) if callable(getattr(obj, attr))]# Test the functionclass Test:    def method1(self):        pass    def method2(self):        passprint(get_callable_attributes(Test))", "url": "ca8cd1bc1e11c8fd1689d1abe3f6d04b", "gt": "def get_methods ( * objs ) : return set ( attr for obj in objs for attr in dir ( obj ) if not attr . startswith ( '_' ) and callable ( getattr ( obj , attr ) ) )"}, {"nl_input": "Checks if a string is quoted : param arg : the string being checked for quotes : return : True if a string is quoted", "code_input": "def is_quoted(arg):    return arg[0] == '\"' and arg[-1] == '\"'", "url": "cfbbfbdb5e84890f7b9938a79629e0e2", "gt": "def is_quoted ( arg : str ) -> bool : return len ( arg ) > 1 and arg [ 0 ] == arg [ - 1 ] and arg [ 0 ] in constants . QUOTES"}, {"nl_input": "Move datetime 1 year in the chosen direction . unit is a no - op to keep the API the same as the day case", "code_input": "from datetime import datetime, timedeltadef move_year(years, direction, unit):    now = datetime.now()    if direction == 'forward':        if unit == 'day':            new_date = now + timedelta(days=years)        elif unit == 'year':            new_date = now + timedelta(years=years)    elif direction == 'backward':        if unit == 'day':            new_date = now - timedelta(days=years)        elif unit == 'year':            new_date = now - timedelta(years=years)    return new_date# Test the functionprint(move_year(1, 'forward', 'day'))print(move_year(1, 'backward',", "url": "83c7e1fd8666e261b69048f44f984a14", "gt": "def move_datetime_year ( dt , direction , num_shifts ) : delta = relativedelta ( years = + num_shifts ) return _move_datetime ( dt , direction , delta )"}, {"nl_input": "Adds execute permission to file . : param filename : : return :", "code_input": "import osdef add_execute_permission(filename):    if os.path.exists(filename):        os.chmod(filename, os.stat(filename).st_mode | os.X_OK)        return True    else:        return False# Test the functionprint(add_execute_permission('filename'))", "url": "5695327040bd9879c8c5374e42e55c3d", "gt": "def chmod_add_excute ( filename ) : st = os . stat ( filename ) os . chmod ( filename , st . st_mode | stat . S_IEXEC )"}, {"nl_input": "Remove the element from a set lists or dict . >>> L = [ Lucy ] ; S = set ( [ Sky ] ) ; D = { Diamonds : True } ; >>> remove_once ( L Lucy ) ; remove_once ( S Sky ) ; remove_once ( D Diamonds ) ; >>> print L S D [] set ( [] ) {}", "code_input": "def remove_once(collection, element):    if element in collection:        collection.remove(element)    return collectionL = ['Lucy']S = set(['Sky'])D = {'Diamonds': True}L = remove_once(L, 'Lucy')S = remove_once(S, 'Sky')D = remove_once(D, 'Diamonds')print(L)print(S)print(D)print(set([]))print({})", "url": "0a08a131b7f20c6ae80cbd8db43c9210", "gt": "def remove_once ( gset , elem ) : remove = getattr ( gset , 'remove' , None ) if remove is not None : remove ( elem ) else : del gset [ elem ] return elem"}, {"nl_input": ": param sequence : Any sequence whose elements can be evaluated as booleans . : returns : true if all elements of the sequence satisfy True and x .", "code_input": "def all_elements_are_true(sequence):    for element in sequence:        if not element:            return False    return True", "url": "f1fa86112e0e73f4f4a31cbe14f04a6b", "gt": "def All ( sequence ) : return bool ( reduce ( lambda x , y : x and y , sequence , True ) )"}, {"nl_input": "Get the first sunday of a month .", "code_input": "import datetimedef first_sunday_of_month():    today = datetime.date.today()    if today.weekday() == 6:  # if today is Sunday        first_sunday = today + datetime.timedelta(days=2)  # get the date of the next Monday    else:        first_sunday = today + datetime.timedelta(days=(7 - today.weekday()) % 7)  # get the date of the first Sunday of the month    return first_sundayprint(first_sunday_of_month())", "url": "49aefd290af2372c6b5eb570281c6ce8", "gt": "def first_sunday ( self , year , month ) : date = datetime ( year , month , 1 , 0 ) days_until_sunday = 6 - date . weekday ( ) return date + timedelta ( days = days_until_sunday )"}, {"nl_input": "Adds the argument variable as one of the input variable", "code_input": "def add_to_list(input_list, argument):    input_list.append(argument)    return input_list", "url": "26565a67fd195231572afee1165f9826", "gt": "def add_input_variable ( self , var ) : assert ( isinstance ( var , Variable ) ) self . input_variable_list . append ( var )"}, {"nl_input": "Wrapper for iterating numpy array", "code_input": "import numpy as np# Create a numpy arrayarr = np.array([1, 2, 3, 4, 5])# Wrap around an iterating over the arrayfor i in arr:    print(i)", "url": "84b81599f848ba0a0de34034369ecd66", "gt": "def _npiter ( arr ) : for a in np . nditer ( arr , flags = [ \"refs_ok\" ] ) : c = a . item ( ) if c is not None : yield c"}, {"nl_input": "split string * s * into list of strings no longer than * length *", "code_input": "def split_string(s, length):    return [s[i:i+length] for i in range(0, len(s), length)]# Test the functions = \"Hello, world!\"length = 3print(split_string(s, length))", "url": "fe1575ac247db28014a9b3ed32f060c3", "gt": "def split_len ( s , length ) : return [ s [ i : i + length ] for i in range ( 0 , len ( s ) , length ) ]"}, {"nl_input": "Take a date object and return the first day of the month .", "code_input": "from datetime import datetime, timedeltadef first_day_of_month(date):    first_day = date.replace(day=1)    if date.weekday() < 5:        first_day -= timedelta(days=date.weekday())    else:        first_day -= timedelta(days=(7 - date.weekday() % 7))    return first_day# Test the functiondate = datetime.now()print(first_day_of_month(date))", "url": "74483d2e3e4816f59f302670fc2add82", "gt": "def monthly ( date = datetime . date . today ( ) ) : return datetime . date ( date . year , date . month , 1 )"}, {"nl_input": "Convert to float if object is a float string .", "code_input": "def convert_to_float(obj):    try:        return float(obj)    except ValueError:        return obj", "url": "cf2e8a81dd31fa2f9c43e976123e281e", "gt": "def _tofloat ( obj ) : if \"inf\" in obj . lower ( ) . strip ( ) : return obj try : return int ( obj ) except ValueError : try : return float ( obj ) except ValueError : return obj"}, {"nl_input": "Pyglet specific key press callback . Forwards and translates the events to : py : func : keyboard_event", "code_input": "import pyglet# Create a windowwindow = pyglet.window.Window()# Create a labellabel = pyglet.text.Label('Press any key',                          font_name='Arial',                          font_size=20,                          color=(0, 0, 0, 255))# Create a function to handle keyboard eventsdef keyboard_event(key, modifiers):    print(f'Key {key} pressed.')# Bind the keyboard event to the windowwindow.push_handlers(on_key_press=keyboard_event)# Run the main event looppyglet.app.run()", "url": "b9f179a182e7f371684191f4d2a4434d", "gt": "def on_key_press ( self , symbol , modifiers ) : self . keyboard_event ( symbol , self . keys . ACTION_PRESS , modifiers )"}, {"nl_input": "Returns a string representing a numpy array of 0 s and 1 s", "code_input": "import numpy as npdef generate_array(size):    return np.random.choice([0, 1], size=size)# Test the functionprint(generate_array(10))", "url": "59ba4239d919130c70a0976daa47eb7d", "gt": "def bitsToString ( arr ) : s = array ( 'c' , '.' * len ( arr ) ) for i in xrange ( len ( arr ) ) : if arr [ i ] == 1 : s [ i ] = '*' return s"}, {"nl_input": ": param string : String can be type resource or python case", "code_input": "def convert_to_lowercase(param_string):    return param_string.lower()", "url": "66bffc09e421f8b89cbcc1bc10580629", "gt": "def python ( string : str ) : return underscore ( singularize ( string ) if Naming . _pluralize ( string ) else string )"}, {"nl_input": "Normalize time in arbitrary timezone to UTC naive object .", "code_input": "from datetime import datetime, timezonedef normalize_time(time, timezone_str):    # Parse the timezone string    timezone_obj = timezone(timezone_str)    # Get the current time in the specified timezone    current_time = datetime.now(timezone_obj)    # Convert the current time to UTC naive object    utc_time = current_time.astimezone(timezone.utc)    return utc_time# Test the functiontime = \"+03:00\"  # Time in the specified timezonetimezone_str = \"Asia/Kolkata\"  # Timezone stringprint(normalize_time(time, timezone_str))", "url": "6ca260fb0f4204fff966670dd6b53076", "gt": "def normalize_time ( timestamp ) : offset = timestamp . utcoffset ( ) if offset is None : return timestamp return timestamp . replace ( tzinfo = None ) - offset"}, {"nl_input": "Combine data and a fits header to write a fits file .", "code_input": "import astropy.tableimport astropy.io.fits# Assuming you have a table and a headertable = astropy.table.Table()header = astropy.io.fits.Header()# Add data to the tabletable.add_column(data=[1, 2, 3, 4, 5], name='DATA')# Add header to the fits fileheader.add_key('TELESCOPE', 'TELESCOPE', 'Space Telescope')header.add_key('OBJECT', 'OBJECT', 'Moon')header.add_key('DATE', 'DATE', '2022-01-01')# Write the fits fileastropy.io.fits.writeto('output.fits', data=table, header=header)", "url": "48ad11d2bff0c767854ed2802f661500", "gt": "def write_fits ( data , header , file_name ) : hdu = fits . PrimaryHDU ( data ) hdu . header = header hdulist = fits . HDUList ( [ hdu ] ) hdulist . writeto ( file_name , overwrite = True ) logging . info ( \"Wrote {0}\" . format ( file_name ) ) return"}, {"nl_input": "Print dicttree in Json - like format . keys are sorted", "code_input": "import jsondef print_dict_tree_in_json(d, indent=0):    for key, value in sorted(d.items()):        print('\\t' * indent + str(key))        if isinstance(value, dict):            print_dict_tree_in_json(value, indent+1)        else:            print('\\t' * (indent+1) + str(value))# Test the functiondata = {    'name': 'John',    'age': 30,    'children': {        'child1': {            'name': 'Alice',            'age': 5        },        'child2': {            'name': 'Bob',            'age': 7        }    }}print_dict_tree_in_json(data)", "url": "bbb8c24e82437ea03fccdc924a99d399", "gt": "def prettyprint ( d ) : print ( json . dumps ( d , sort_keys = True , indent = 4 , separators = ( \",\" , \": \" ) ) )"}, {"nl_input": "Remove empty utterances from a list of utterances Args : utterances : The list of utterance we are processing", "code_input": "def remove_empty_utterances(utterances):    return [utterance for utterance in utterances if utterance]utterances = ['Hello', '', 'World', '']print(remove_empty_utterances(utterances))", "url": "5ca8d1be36d4955478ff4ef72fbc653a", "gt": "def remove_empty_text ( utterances : List [ Utterance ] ) -> List [ Utterance ] : return [ utter for utter in utterances if utter . text . strip ( ) != \"\" ]"}, {"nl_input": "Return whether the handler is using sys . stdout .", "code_input": "import sysdef is_using_stdout(handler):    return handler is sys.stdout", "url": "2d584925f28ca1a569c556b3cb0b23bb", "gt": "def _using_stdout ( self ) : if WINDOWS and colorama : # Then self.stream is an AnsiToWin32 object. return self . stream . wrapped is sys . stdout return self . stream is sys . stdout"}, {"nl_input": "Check if the file - like object is readable .", "code_input": "def is_readable(file):    try:        file.read()        file.seek(0)        return True    except:        return False", "url": "ff74b00f4c8a98fb9cf3a85ef310f5bc", "gt": "def is_readable ( fp , size = 1 ) : read_size = len ( fp . read ( size ) ) fp . seek ( - read_size , 1 ) return read_size == size"}, {"nl_input": "Get the modified time of the RPM Database .", "code_input": "import sqlite3# Connect to the RPM databaseconn = sqlite3.connect('/var/lib/rpm/rpmdb.sqlite')c = conn.cursor()# Execute a query to get the last update timec.execute(\"SELECT last_update FROM rpmdb_version\")# Fetch the resultlast_update = c.fetchone()# Print the last update timeprint(last_update[0])# Close the connectionconn.close()", "url": "6f2c6c2911c241095457edad8d4f610c", "gt": "def _get_mtime ( ) : return os . path . exists ( RPM_PATH ) and int ( os . path . getmtime ( RPM_PATH ) ) or 0"}, {"nl_input": "Iterable - first replacement of Python s built - in map () function .", "code_input": "def first_replacement(iterable):    for i in iterable:        return i# Test the functionprint(first_replacement([1, 2, 3, 4, 5]))  # Output: 1", "url": "a7edaf5497f4d1c28abc87eedd67ec8f", "gt": "def map ( cls , iterable , func , * a , * * kw ) : return cls ( func ( x , * a , * * kw ) for x in iterable )"}, {"nl_input": "Short Time Fourier Transform for real data keeping the full FFT block .", "code_input": "import numpy as npfrom scipy.signal import stftdef short_time_fourier_transform(signal, window):    # Compute the STFT    f, t, Zxx = stft(signal, window, nperseg=1024, noverlap=512)    # Return the STFT    return f, t, Zxx", "url": "dc43a25a987b9cb527a790deaae7be02", "gt": "def stft ( func = None , * * kwparams ) : from numpy . fft import fft , ifft ifft_r = lambda * args : ifft ( * args ) . real return stft . base ( transform = fft , inverse_transform = ifft_r ) ( func , * * kwparams )"}, {"nl_input": "return True if the current distribution is running on debian like OS .", "code_input": "import platformdef is_debian_based():    return platform.system().lower() == 'debian'print(is_debian_based())", "url": "05385bcc31475b348629045db7ae74b2", "gt": "def is_archlinux ( ) : if platform . system ( ) . lower ( ) == 'linux' : if platform . linux_distribution ( ) == ( '' , '' , '' ) : # undefined distribution. Fixed in python 3. if os . path . exists ( '/etc/arch-release' ) : return True return False"}, {"nl_input": "Removes // - comments and single - line C - style / * * / comments .", "code_input": "def remove_comments(code):    lines = code.split('\\n')    new_lines = []    in_string = False    in_comment = False    for line in lines:        new_line = []        for i, char in enumerate(line):            if char == '\"':                in_string = not in_string            elif char == '/' and not in_string:                if line[i + 1] == '/' and not in_comment:                    in_comment = True                elif line[i + 1] == '*' and not in_comment:                    in_comment = True                    i += 1                    while i < len(line) and not (line[i] == '*' and line[i + 1] == '/'):                        i += 1                else:                    new_line.append(char)            elif in_comment and not line[i + 1]:                in_comment = False                continue           ", "url": "6e369a16a8e70d37aa500da1cf9eff39", "gt": "def CleanseComments ( line ) : commentpos = line . find ( '//' ) if commentpos != - 1 and not IsCppString ( line [ : commentpos ] ) : line = line [ : commentpos ] . rstrip ( ) # get rid of /* ... */ return _RE_PATTERN_CLEANSE_LINE_C_COMMENTS . sub ( '' , line )"}, {"nl_input": "Tells Windows this is an independent application with an unique icon on task bar .", "code_input": "import win32guiimport win32conimport win32apidef create_taskbar_icon(icon_path, window_title):    icon = win32gui.ExtractIcon(icon_path, 0)    icon_dib = win32ui.CreateBitmapFromHandle(icon)    icon_dc = icon_dib.GetDC()    bmp_mem_dc = icon_dc.CreateCompatibleDC()    bmp_width = icon_dib.bmWidth    bmp_height = icon_dib.bmHeight    win32gui.DeleteObject(icon_dc.GetObject(win32con.HANDLE_TO_BITMAP))    hicon = win32gui.CreateIconIndirect(bmp_mem_dc, (0,0, bmp_width", "url": "3c6813b3e153505df450e4718d17865b", "gt": "def setAsApplication ( myappid ) : if os . name == 'nt' : import ctypes ctypes . windll . shell32 . SetCurrentProcessExplicitAppUserModelID ( myappid )"}, {"nl_input": "see doc in Term class", "code_input": "class Term:    def __init__(self, doc):        self.doc = doc    def get_doc(self):        return self.doc# Create an instance of the Term classterm = Term(\"This is a document string.\")# Use the get_doc method to get the document stringprint(term.get_doc())", "url": "2c1a6a5126487b41335a09e81eadf164", "gt": "def get_size ( self ) : self . curses . setupterm ( ) return self . curses . tigetnum ( 'cols' ) , self . curses . tigetnum ( 'lines' )"}, {"nl_input": "Generates a count of the number of times each unique item appears in a list", "code_input": "def count_items(lst):    count_dict = {}    for item in lst:        if item in count_dict:            count_dict[item] += 1        else:            count_dict[item] = 1    return count_dict# Test the functionlst = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5]print(count_items(lst))", "url": "0b667a6f675e931da772a1275fa53ee2", "gt": "def count_list ( the_list ) : count = the_list . count result = [ ( item , count ( item ) ) for item in set ( the_list ) ] result . sort ( ) return result"}, {"nl_input": "Removes all non - printable characters from a text string", "code_input": "def remove_non_printable(text):    return ''.join(ch for ch in text if ch.isprintable())text = \"Hello, World!\"print(remove_non_printable(text))", "url": "0f171b4626d9f0ea2a003661289af42f", "gt": "def clean ( ctx , text ) : text = conversions . to_string ( text , ctx ) return '' . join ( [ c for c in text if ord ( c ) >= 32 ] )"}, {"nl_input": "Converts XY point from Spherical Mercator EPSG : 900913 to lat / lon in WGS84 Datum", "code_input": "import pyprojdef convert_to_wgs84(x, y):    # Define the projections    srs_wgs84 = pyproj.Proj(init='epsg:4326')  # WGS84    srs_mercator = pyproj.Proj(init='epsg:900913')  # Spherical Mercator    # Convert the point from Spherical Mercator to WGS84    lon, lat = pyproj.transform(srs_mercator, srs_wgs84, x, y)    return lat, lon", "url": "1bc345e3253ff84cfda626f47ab1a8df", "gt": "def metres2latlon ( mx , my , origin_shift = 2 * pi * 6378137 / 2.0 ) : lon = ( mx / origin_shift ) * 180.0 lat = ( my / origin_shift ) * 180.0 lat = 180 / pi * ( 2 * atan ( exp ( lat * pi / 180.0 ) ) - pi / 2.0 ) return lat , lon"}, {"nl_input": "Print the header for the CSV table .", "code_input": "import csvdef print_csv_header(file_name):    with open(file_name, 'r') as file:        reader = csv.reader(file)        headers = next(reader)        print(','.join(headers))print_csv_header('your_file.csv')", "url": "065a776db0489e0d6071522739dc609d", "gt": "def printheader ( h = None ) : writer = csv . writer ( sys . stdout ) writer . writerow ( header_fields ( h ) )"}, {"nl_input": "Calculate overlap count between the values of two dictionaries", "code_input": "def overlap_count(dict1, dict2):    overlap = sum(1 for key in dict1 if key in dict2)    return overlap# Test the functiondict1 = {'a': 1, 'b': 2, 'c': 3, 'd': 4}dict2 = {'b': 2, 'c': 3, 'd': 4, 'e': 5}print(overlap_count(dict1, dict2))  # Output: 3", "url": "c8478233dae0b972efc02759fdfebc63", "gt": "def _calc_overlap_count ( markers1 : dict , markers2 : dict , ) : overlaps = np . zeros ( ( len ( markers1 ) , len ( markers2 ) ) ) j = 0 for marker_group in markers1 : tmp = [ len ( markers2 [ i ] . intersection ( markers1 [ marker_group ] ) ) for i in markers2 . keys ( ) ] overlaps [ j , : ] = tmp j += 1 return overlaps"}, {"nl_input": "Saves a value to session .", "code_input": "from flask import Flask, sessionapp = Flask(__name__)app.config['SECRET_KEY'] = 'my_secret_key'@app.route('/set_value', methods=['POST'])def set_value():    session['key'] = 'value'    return 'Value has been set'if __name__ == '__main__':    app.run(debug=True)", "url": "d8d33578fcd0ad196398b5dd87568b3f", "gt": "def _session_set ( self , key , value ) : self . session [ self . _session_key ( key ) ] = value"}, {"nl_input": "Read text from stdin and print a helpful message for ttys .", "code_input": "import sysdef read_stdin():    for line in sys.stdin:        print(f\"You said: {line.strip()}\")if __name__ == \"__main__\":    read_stdin()", "url": "e0733d51ee06d0addebb4595beb97e0b", "gt": "def read_stdin ( ) : if sys . stdin . isatty ( ) and sys . stdout . isatty ( ) : print ( '\\nReading from stdin until end of file (Ctrl + D)...' ) return sys . stdin . read ( )"}, {"nl_input": "shows JSON indented representation of d", "code_input": "import json# Define the dictionaryd = {    'name': 'John',    'age': 30,    'city': 'New York'}# Use json.dumps() to convert the dictionary to a JSON string, with indentation for readabilityjson_str = json.dumps(d, indent=4)# Print the JSON stringprint(json_str)", "url": "790cc6142b91109d4d9d5a64f0ec5b3b", "gt": "def pretty_dict_str ( d , indent = 2 ) : b = StringIO ( ) write_pretty_dict_str ( b , d , indent = indent ) return b . getvalue ( )"}, {"nl_input": "Wrapper on iter method callback gets an iterator result", "code_input": "def callback(item):    # This is your callback function. It should return a value.    return item * 2def iter_method_callback(iterable):    # Use map to apply the callback to each item in the iterable.    return list(map(callback, iterable))# Test the functioniterable = [1, 2, 3, 4, 5]print(iter_method_callback(iterable))  # Output: [2, 4, 6, 8, 10]", "url": "a7ae1c18c06bd04b301a3a9dd6511232", "gt": "def find_all ( self , string , callback ) : for index , output in self . iter ( string ) : callback ( index , output )"}, {"nl_input": "Break lists into small lists for processing : w", "code_input": "def divide_list(lst):    return [lst[i:i+5] for i in range(0, len(lst), 5)]lst = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]print(divide_list(lst))", "url": "7d97cc48df768552ecb833ac5da561e1", "gt": "def chunked_list ( _list , _chunk_size = 50 ) : for i in range ( 0 , len ( _list ) , _chunk_size ) : yield _list [ i : i + _chunk_size ]"}, {"nl_input": "Return all ( and only ) the uppercase chars in the given string .", "code_input": "def find_uppercase_chars(s):    return ''.join(c for c in s if c.isupper())# Test the functionprint(find_uppercase_chars(\"Hello World!\"))", "url": "c7986d1e5882fe056f16ccd5a932d84e", "gt": "def uppercase_chars ( string : any ) -> str : return '' . join ( [ c if c . isupper ( ) else '' for c in str ( string ) ] )"}, {"nl_input": "Compiles to native Python bytecode and runs program returning the topmost value on the stack .", "code_input": "import disdef compile_and_execute():    code = \"\"\"    def add(x, y):        return x + y    print(add(1, 2))    \"\"\"    bytecode = compile(code, \"<string>\", \"exec\")    exec(bytecode)compile_and_execute()", "url": "cd6c0b5919ed35ca54f03aed7155d59c", "gt": "def xeval ( source , optimize = True ) : native = xcompile ( source , optimize = optimize ) return native ( )"}, {"nl_input": "Get a property by name", "code_input": "class Person:    def __init__(self, name, age):        self.name = name        self.age = age    def get_property(self, property_name):        if property_name == 'name':            return self.name        elif property_name == 'age':            return self.age        else:            return \"Property not found\"# Create an object of Personperson = Person('John', 25)# Get the property 'name'print(person.get_property('name'))# Get the property 'age'print(person.get_property('age'))# Get the property 'address'print(person.get_property('address'))", "url": "6991aa2924b52404ff77faa2b677d3e2", "gt": "def get_property_by_name ( pif , name ) : return next ( ( x for x in pif . properties if x . name == name ) , None )"}, {"nl_input": "Is an object iterable like a list ( and not a string ) ?", "code_input": "class MyIterable:    def __init__(self, data):        self.data = data        self.index = 0    def __iter__(self):        return self    def __next__(self):        if self.index >= len(self.data):            raise StopIteration        result = self.data[self.index]        self.index += 1        return result# Testingmy_iterable = MyIterable([1, 2, 3, 4, 5])for item in my_iterable:    print(item)", "url": "e8d906db3eac56229992dd6701dafd90", "gt": "def listlike ( obj ) : return hasattr ( obj , \"__iter__\" ) and not issubclass ( type ( obj ) , str ) and not issubclass ( type ( obj ) , unicode )"}, {"nl_input": "transpose matrix", "code_input": "def transpose(matrix):    return [[row[i] for row in matrix] for i in range(len(matrix[0]))]# Test the functionmatrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]print(transpose(matrix))", "url": "f72094ee819dfe55ef594b4d29424ad0", "gt": "def transpose ( table ) : t = [ ] for i in range ( 0 , len ( table [ 0 ] ) ) : t . append ( [ row [ i ] for row in table ] ) return t"}, {"nl_input": "", "code_input": "SELECT * FROM table_name WHERE column_name = 'value';", "url": "1af4bba3546dc398bb5ed2f79e80596b", "gt": "def get_unique_indices ( df , axis = 1 ) : return dict ( zip ( df . columns . names , dif . columns . levels ) )"}, {"nl_input": "Matrix solve op .", "code_input": "import numpy as np# Define the matrixA = np.array([[1, 2], [3, 4]])# Define the vectorb = np.array([1, 2])# Solve the matrix equationx = np.linalg.solve(A, b)print(x)", "url": "5877389d9eb25b563ada6e2220248ba5", "gt": "def MatrixSolve ( a , rhs , adj ) : return np . linalg . solve ( a if not adj else _adjoint ( a ) , rhs ) ,"}, {"nl_input": "Return the absolute path to the directory containing the package data .", "code_input": "import osdef get_package_dir():    return os.path.dirname(os.path.abspath(__file__))print(get_package_dir())", "url": "b49f6af022fb00932348cc036f786a2c", "gt": "def data_directory ( ) : package_directory = os . path . abspath ( os . path . dirname ( __file__ ) ) return os . path . join ( package_directory , \"data\" )"}, {"nl_input": "Escapes a filesystem path for use as a command - line argument", "code_input": "import osimport sysdef escape_path(path):    return os.path.abspath(os.path.expanduser(path))if __name__ == \"__main__\":    if len(sys.argv) != 2:        print(\"Usage: {} PATH\".format(sys.argv[0]))        sys.exit(1)    path = sys.argv[1]    escaped_path = escape_path(path)    print(escaped_path)", "url": "c717888ec77092e7b6e56415d851e2be", "gt": "def escapePathForShell ( path ) : if platform . system ( ) == 'Windows' : return '\"{}\"' . format ( path . replace ( '\"' , '\"\"' ) ) else : return shellescape . quote ( path )"}, {"nl_input": "Pretty printing for numpy matrix X", "code_input": "import numpy as np# Create a numpy matrixX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])# Use the 'pretty' method to pretty print the matrixprint(np.set_printoptions(precision=3))print(X)", "url": "144142c4f682e2fc8c47507a12eb8b46", "gt": "def print_matrix ( X , decimals = 1 ) : for row in np . round ( X , decimals = decimals ) : print ( row )"}, {"nl_input": "Finds first file in path whose filename matches pattern ( via : func : fnmatch . fnmatch ) or raises : exc : IndexError .", "code_input": "import osimport fnmatchdef find_file(path, pattern):    for root, dirs, files in os.walk(path):        for file in fnmatch.filter(files, pattern):            return os.path.join(root, file)    raise IndexError(\"No file found in path that matches the pattern\")# Usagepath = \"/path/to/search\"pattern = \"*.txt\"print(find_file(path, pattern))", "url": "4c136dbf27a5d08891bc2d374574506d", "gt": "def find_first ( pattern : str , path : str ) -> str : try : return find ( pattern , path ) [ 0 ] except IndexError : log . critical ( '''Couldn't find \"{}\" in \"{}\"''' , pattern , path ) raise"}, {"nl_input": "Create a shared memory array with the same shape and type as a given array filled with value .", "code_input": "import multiprocessing as mpimport numpy as np# Define the shared arrayshared_array = mp.Array('shared_array', np.int32(0))def fill_array(array):    # Fill the array with some values    for i in range(len(array)):        array[i] = idef create_shared_array(array):    # Create a shared array with the same shape and type as the given array    shared_array[:] = array[:]if __name__ == '__main__':    # Create a parent process    parent_process = mp.Process(target=fill_array, args=(shared_array,))    parent_process.start()    parent_process.join()    # Create a child process    child_process = mp.Process(target=create_shared_array", "url": "7022cdc7764380a374323ec964b9e1d1", "gt": "def full_like ( array , value , dtype = None ) : shared = empty_like ( array , dtype ) shared [ : ] = value return shared"}, {"nl_input": "Perform a simple check if the value is callable .", "code_input": "def is_callable(value):    try:        return callable(value)    except TypeError:        return False# Test the functionprint(is_callable(None))  # Falseprint(is_callable(123))  # Falseprint(is_callable('test'))  # Falseprint(is_callable(abs))  # Trueprint(is_callable(lambda x: x))  # True", "url": "3f6168cffe8cb21984c6a12267502db1", "gt": "def callable_validator ( v : Any ) -> AnyCallable : if callable ( v ) : return v raise errors . CallableError ( value = v )"}, {"nl_input": "manually set the default figure size of plots :: Arguments :: x ( float ) : x - axis size y ( float ) : y - axis size aspect ( float ) : aspect ratio scalar", "code_input": "import matplotlib.pyplot as pltdef set_figure_size(x, y, aspect):    plt.figure(figsize=(x, y))    plt.gca().set_aspect(aspect)", "url": "cdb682fdaddf92e4c85ac1006ec2f2ac", "gt": "def figsize ( x = 8 , y = 7. , aspect = 1. ) : # update rcparams with adjusted figsize params mpl . rcParams . update ( { 'figure.figsize' : ( x * aspect , y ) } )"}, {"nl_input": "Truncates a value to a number of decimals places", "code_input": "def truncate_value(value, num_decimals):    return round(value, num_decimals)# Test the functionprint(truncate_value(12.3456, 2))  # Output: 12.35", "url": "a9f00f4b4472333451594b653fd3ddf4", "gt": "def truncate ( value : Decimal , n_digits : int ) -> Decimal : return Decimal ( math . trunc ( value * ( 10 ** n_digits ) ) ) / ( 10 ** n_digits )"}, {"nl_input": "Get string from file .", "code_input": "def get_string_from_file(file_path):    with open(file_path, 'r') as file:        return file.read()# Usagefile_content = get_string_from_file('path_to_your_file.txt')print(file_content)", "url": "3a909aebbf2e4e790a70a9a6a5aeb917", "gt": "def get_file_string ( filepath ) : with open ( os . path . abspath ( filepath ) ) as f : return f . read ( )"}, {"nl_input": "Callback to redraw the plot to reflect the new parameter values .", "code_input": "import matplotlib.pyplot as plt# Assume we have a function that returns a list of parameter valuesdef get_parameter_values():    # This is a placeholder, replace with your actual function    return [1, 2, 3, 4, 5]# Assume we have a function that redraws the plotdef redraw_plot():    # Get the new parameter values    parameter_values = get_parameter_values()    # Create a new figure    plt.figure()    # Plot the parameter values    plt.plot(parameter_values)    # Refresh the plot    plt.draw()# Call the redraw_plot functionredraw_plot()", "url": "051279ae1faa9b3e8ad99859217a31a9", "gt": "def _update_plot ( self , _ ) : # Since all sliders call this same callback without saying who they are # I need to update the values for all parameters. This can be # circumvented by creating a seperate callback function for each # parameter. for param in self . model . params : param . value = self . _sliders [ param ] . val for indep_var , dep_var in self . _projections : self . _update_specific_plot ( indep_var , dep_var )"}, {"nl_input": "Verifies that a string path actually exists and is a file", "code_input": "import osdef is_file(path):    if os.path.isfile(path):        return True    else:        return False", "url": "2eb8c1c213084c2d6663d2798151922e", "gt": "def valid_file ( path : str ) -> bool : path = Path ( path ) . expanduser ( ) log . debug ( \"checking if %s is a valid file\" , path ) return path . exists ( ) and path . is_file ( )"}, {"nl_input": "Returns a random positive integer ( for a Django PositiveIntegerField )", "code_input": "import randomfrom django.db import modelsclass MyModel(models.Model):    my_field = models.PositiveIntegerField()    def generate_random_positive_integer(self):        return random.randint(1, self.my_field)", "url": "85d319ea47a8b2db80fd83fa200969b4", "gt": "def positive_integer ( anon , obj , field , val ) : return anon . faker . positive_integer ( field = field )"}, {"nl_input": "Calculates the average price between two asset states .", "code_input": "def calculate_average_price(asset1_prices, asset2_prices):    total_price = sum(asset1_prices) + sum(asset2_prices)    average_price = total_price / (len(asset1_prices) + len(asset2_prices))    return average_price# Assuming you have two lists of prices for two assetsasset1_prices = [100, 200, 150, 80, 120]asset2_prices = [110, 220, 160, 90, 130]average_price = calculate_average_price(asset1_prices, asset2_prices)print(\"The average price between the two assets is:\", average_price)", "url": "6c4b912ed406d1c613c8c86898501f18", "gt": "def average_price ( quantity_1 , price_1 , quantity_2 , price_2 ) : return ( quantity_1 * price_1 + quantity_2 * price_2 ) / ( quantity_1 + quantity_2 )"}, {"nl_input": "Plot a smoothed ( by kernel density estimate ) histogram . : type data : numpy array : param data : An array containing the data to be plotted", "code_input": "import numpy as npimport matplotlib.pyplot as pltfrom scipy.stats import gaussian_kdedef plot_smoothed_histogram(data):    # Create a kernel density estimate    kde = gaussian_kde(data)    # Create a range of x values for the histogram    x = np.linspace(data.min(), data.max(), 100)    # Plot the histogram    plt.hist(data, density=True, alpha=0.5, bins=30,             label='Smoothed Histogram')    # Plot the kernel density estimate    plt.plot(x, kde(x), label='Kernel Density Estimate')    # Add labels and title    plt.xlabel('Data')    plt.ylabel('Frequency')    plt.title('Smoothed Histogram and Kernel Density", "url": "20d4c9337731d52fe439d7ae337e6913", "gt": "def plot_kde ( data , ax , title = None , color = 'r' , fill_bt = True ) : if isinstance ( data , list ) : data = np . asarray ( data ) e = kde . KDEUnivariate ( data . astype ( np . float ) ) e . fit ( ) ax . plot ( e . support , e . density , color = color , alpha = 0.9 , linewidth = 2.25 ) if fill_bt : ax . fill_between ( e . support , e . density , alpha = .35 , zorder = 1 , antialiased = True , color = color ) if title is not None : t = ax . set_title ( title ) t . set_y ( 1.05 )"}, {"nl_input": "Fill all null values with NaN values in a column . Null values are None or en empty string", "code_input": "import pandas as pd# Assuming df is your DataFrame and 'column_name' is the name of the column you want to filldf['column_name'] = df['column_name'].fillna(pd.np.nan)", "url": "93c0c2ede9a5c8a8b970af18721497ae", "gt": "def fill_nulls ( self , col : str ) : n = [ None , \"\" ] try : self . df [ col ] = self . df [ col ] . replace ( n , nan ) except Exception as e : self . err ( e )"}, {"nl_input": "Return this consoles current blend mode .", "code_input": "import cursesdef main(stdscr):    # Clear screen    stdscr.clear()    # Print message    stdscr.addstr(0, 0, \"Current blend mode: \")    # Refresh screen    stdscr.refresh()    # Get input    stdscr.getch()curses.wrapper(main)", "url": "b58a4d28bb6598443049dbbc4bbf8e92", "gt": "def console_get_background_flag ( con : tcod . console . Console ) -> int : return int ( lib . TCOD_console_get_background_flag ( _console ( con ) ) )"}, {"nl_input": "Helper to get bins for histplot .", "code_input": "import numpy as npdef get_bins(data, num_bins):    \"\"\"    Helper function to get bins for histplot.    Parameters:    data (array): The data to be plotted.    num_bins (int): The number of bins to use.    Returns:    array: The bins for the histplot.    \"\"\"    min_val = np.min(data)    max_val = np.max(data)    bin_width = (max_val - min_val) / num_bins    bins = [min_val + i*bin_width for i in range(num_bins+1)]    return bins", "url": "9f884647cf34443dee2bc6ff92f875c3", "gt": "def _histplot_bins ( column , bins = 100 ) : col_min = np . min ( column ) col_max = np . max ( column ) return range ( col_min , col_max + 2 , max ( ( col_max - col_min ) // bins , 1 ) )"}, {"nl_input": "Determine if two revisions have actually changed .", "code_input": "def revisions_have_changed(rev1, rev2):    return rev1 != rev2", "url": "ffef61824d78a9266d404137a97101b1", "gt": "def default_diff ( latest_config , current_config ) : # Pop off the fields we don't care about: pop_no_diff_fields ( latest_config , current_config ) diff = DeepDiff ( latest_config , current_config , ignore_order = True ) return diff"}, {"nl_input": "Run Python test cases against Java runtime classes .", "code_input": "import unittest# Assume we have a class in Javaclass JavaClass:    def __init__(self, value):        self.value = value    def add(self, other):        return JavaClass(self.value + other.value)# Now we can test this class in Pythonclass TestJavaClass(unittest.TestCase):    def test_add(self):        java_class = JavaClass(5)        other = JavaClass(3)        result = java_class.add(other)        self.assertEqual(result.value, 8)if __name__ == '__main__':    unittest.main()", "url": "02839b0594938f5a9b149e4eb63f9dcf", "gt": "def test_python_java_rt ( ) : sub_env = { 'PYTHONPATH' : _build_dir ( ) } log . info ( 'Executing Python unit tests (against Java runtime classes)...' ) return jpyutil . _execute_python_scripts ( python_java_rt_tests , env = sub_env )"}, {"nl_input": "Wait until all queued messages are sent .", "code_input": "import asyncioasync def wait_until_all_queued_messages_are_sent():    # Here you would typically check the status of the queued messages    # For the sake of this example, we'll just assume that all messages are sent    all_messages_sent = True    while not all_messages_sent:        # Wait for a short period of time        await asyncio.sleep(0.1)        # Check the status of the queued messages        # In a real-world application, you would likely have a more complex check        all_messages_sent = check_queued_messages_status()    print(\"All queued messages are sent\")# Run the coroutineasyncio.run(wait_until_all_queued_messages_are_sent())", "url": "09a15b5addf9063f3d0c6597aa38a5d0", "gt": "def wait_send ( self , timeout = None ) : self . _send_queue_cleared . clear ( ) self . _send_queue_cleared . wait ( timeout = timeout )"}, {"nl_input": "Converts a skew - symmetric cross - product matrix to its corresponding vector . Only works for 3x3 matrices .", "code_input": "import numpy as npdef skew_symmetric_cross_product_to_vector(matrix):    if matrix.shape != (3, 3):        raise ValueError(\"Input matrix must be a 3x3 matrix\")    vector = np.zeros(3)    vector[0] = matrix[2, 1] - matrix[1, 2]    vector[1] = matrix[0, 2] - matrix[2, 0]    vector[2] = matrix[1, 0] - matrix[0, 1]    return vector", "url": "ea96df64c6665e80be6a7d81f07c7a4f", "gt": "def deskew ( S ) : x = np . zeros ( 3 ) x [ 0 ] = S [ 2 , 1 ] x [ 1 ] = S [ 0 , 2 ] x [ 2 ] = S [ 1 , 0 ] return x"}, {"nl_input": "Given HTML markup return a list of hrefs for each anchor tag .", "code_input": "from bs4 import BeautifulSoupdef find_hrefs(html_markup):    soup = BeautifulSoup(html_markup, 'html.parser')    hrefs = [a['href'] for a in soup.find_all('a', href=True)]    return hrefs", "url": "a0295573f1dcf89a25aa9337bd3f9207", "gt": "def get_anchor_href ( markup ) : soup = BeautifulSoup ( markup , 'lxml' ) return [ '%s' % link . get ( 'href' ) for link in soup . find_all ( 'a' ) ]"}, {"nl_input": "convert a ctypes structure to a dictionary", "code_input": "import ctypes# Define the ctypes structureclass MyStruct(ctypes.Structure):    _fields = [        ('field1', ctypes.c_int),        ('field2', ctypes.c_float),        ('field3', ctypes.c_char_p),    ]# Create an instance of the ctypes structureinstance = MyStruct(field1=1, field2=2.0, field3=b'test')# Convert the ctypes structure to a dictionarydict_instance = dict(instance)print(dict_instance)", "url": "3e40d7e81d715f046db351aee91b0c62", "gt": "def struct2dict ( struct ) : return { x : getattr ( struct , x ) for x in dict ( struct . _fields_ ) . keys ( ) }"}, {"nl_input": "Wrap text in an ansi escape sequence", "code_input": "def ansi_wrap(text, width):    return '\\n'.join([line.rjust(width) for line in text.split('\\n')])# Test the functiontext = \"\"\"Lorem ipsum dolor sit amet, consectetur adipiscing elit.           Integer nec odio. In semper, massa ac convallis commodo,           tortor mauris condimentum nibh, ut fermentum massa justo sit           amet risus. Donec egestas. Aliquam tincidunt mauris eu risus.           Maecenas luctus. Integer tempor. Donec pretium vulputate           lectus. Nulla at semper tellus, at lorem ut mi.           Mauris elementum mauris vitae lectus.           Etiam sit amet lectus. Quisque sit amet est et massa           mattis porta.           In enim a", "url": "361543bea6004540b3a709ec2b6f852f", "gt": "def ansi ( color , text ) : code = COLOR_CODES [ color ] return '\\033[1;{0}m{1}{2}' . format ( code , text , RESET_TERM )"}, {"nl_input": "Shape a list of lists into the appropriate shape and data type", "code_input": "def shape_list(lst):    # Check if the list is empty    if not lst:        return []    # Get the first element of the list    first_element = lst[0]    # If the first element is a list, recursively call the function    if isinstance(first_element, list):        return [shape_list(first_element)]    # If the first element is not a list, create a new list with the first element    else:        return [first_element]# Test the functionlst = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]print(shape_list(lst))", "url": "75029e9b5315bf8366b2c9d646b179e4", "gt": "def shape_list ( l , shape , dtype ) : return np . array ( l , dtype = dtype ) . reshape ( shape )"}, {"nl_input": "Print all rows in this result query .", "code_input": "import pandas as pd# Assuming df is your DataFrame# df = pd.read_sql_query(\"SELECT * FROM your_table\", conn)# Print all rowsprint(df)", "url": "3cb2ed3d1f3f748abda37ef3aefc286e", "gt": "def print_runs ( query ) : if query is None : return for tup in query : print ( ( \"{0} @ {1} - {2} id: {3} group: {4}\" . format ( tup . end , tup . experiment_name , tup . project_name , tup . experiment_group , tup . run_group ) ) )"}, {"nl_input": "Return lines of a file with whitespace removed", "code_input": "def remove_whitespace(file_name):    with open(file_name, 'r') as file:        lines = file.readlines()    lines_without_whitespace = [line.replace(' ', '') for line in lines]    return lines_without_whitespace# Usageprint(remove_whitespace('your_file.txt'))", "url": "4cd26ba017dabe234b6b960e4c174cd7", "gt": "def get_stripped_file_lines ( filename ) : try : lines = open ( filename ) . readlines ( ) except FileNotFoundError : fatal ( \"Could not open file: {!r}\" . format ( filename ) ) return [ line . strip ( ) for line in lines ]"}, {"nl_input": "Manufacture decorator that filters return value with given function .", "code_input": "def filter_decorator(func):    def wrapper(*args, **kwargs):        result = func(*args, **kwargs)        return [value for value in result if value > 0]    return wrapper@filter_decoratordef get_positive_values(numbers):    return numbersnumbers = [1, -2, 3, -4, 5]print(get_positive_values(numbers))", "url": "a86e59f13d1de0744181898183974b07", "gt": "def apply ( filter ) : def decorator ( callable ) : return lambda * args , * * kwargs : filter ( callable ( * args , * * kwargs ) ) return decorator"}, {"nl_input": "Sort the list into natural alphanumeric order .", "code_input": "def sort_list(lst):    return sorted(lst, key=lambda x: str(x))# Test the functionlst = [123, 45, 67, 1, 2, 100, 500, 200, 10, 5]print(sort_list(lst))", "url": "e8ba965e00c981d460681f001f1b646b", "gt": "def natural_sort ( list , key = lambda s : s ) : def get_alphanum_key_func ( key ) : convert = lambda text : int ( text ) if text . isdigit ( ) else text return lambda s : [ convert ( c ) for c in re . split ( '([0-9]+)' , key ( s ) ) ] sort_key = get_alphanum_key_func ( key ) list . sort ( key = sort_key )"}, {"nl_input": "Get a random ( i . e . unique ) string identifier", "code_input": "import randomimport stringdef generate_unique_string(length):    letters = string.ascii_letters + string.digits    return ''.join(random.choice(letters) for i in range(length))# Test the functionprint(generate_unique_string(10))", "url": "25a29e374311824cbed549355d28c30b", "gt": "def _get_random_id ( ) : symbols = string . ascii_uppercase + string . ascii_lowercase + string . digits return '' . join ( random . choice ( symbols ) for _ in range ( 15 ) )"}, {"nl_input": "Convert list of key value lists to dict", "code_input": "def convert_to_dict(lst):    return {k: v for k, v in lst}# Test the functionlst = [('a', 1), ('b', 2), ('c', 3)]print(convert_to_dict(lst))", "url": "1b73a949780175c73d5778ca8e2f5b2e", "gt": "def list_of_lists_to_dict ( l ) : d = { } for key , val in l : d . setdefault ( key , [ ] ) . append ( val ) return d"}, {"nl_input": "string dict / object / value to JSON", "code_input": "import json# Define a dictionarydict_data = {\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}# Convert the dictionary to a JSON stringjson_data = json.dumps(dict_data)# Print the JSON stringprint(json_data)", "url": "a9048b56499578414cb6dca3141d871d", "gt": "def string ( value ) -> str : return system_json . dumps ( Json ( value ) . safe_object ( ) , ensure_ascii = False )"}, {"nl_input": "Handle conversion of pymongo cursor into a JSON object formatted for UI consumption", "code_input": "import jsondef cursor_to_json(cursor):    result = []    for doc in cursor:        result.append(doc)    return json.dumps(result)", "url": "82821e87505d717d99a5a6982e80b533", "gt": "def _obj_cursor_to_dictionary ( self , cursor ) : if not cursor : return cursor cursor = json . loads ( json . dumps ( cursor , cls = BSONEncoder ) ) if cursor . get ( \"_id\" ) : cursor [ \"id\" ] = cursor . get ( \"_id\" ) del cursor [ \"_id\" ] return cursor"}, {"nl_input": "writes a string to file", "code_input": "def write_to_file(filename, content):    with open(filename, 'w') as file:        file.write(content)# Test the functionwrite_to_file('test.txt', 'Hello, World!')", "url": "cfe10971d3e9565b10d9a8da615d0b58", "gt": "def write_str2file ( pathname , astr ) : fname = pathname fhandle = open ( fname , 'wb' ) fhandle . write ( astr ) fhandle . close ( )"}, {"nl_input": "Args : img ( PIL Image ) : Image to be padded .", "code_input": "from PIL import Imagedef pad_image(img, size):    width, height = img.size    if width > height:        left = (width - height) // 2        upper = 0        right = width - left        lower = height    else:        upper = (height - width) // 2        left = 0        right = height - upper        lower = width    img = img.crop((left, upper, right, lower))    new_img = Image.new('RGB', (size, size), (255, 255, 255))    new_img.paste(img, (0, 0))    return new_img# Example usage:img = Image.open('path_to_your_image.jpg')padded_img = pad_image(img, 256)padded_img.save('", "url": "9a8806be60753c5afc2c2886b26a8147", "gt": "def __call__ ( self , img ) : return F . pad ( img , self . padding , self . fill , self . padding_mode )"}, {"nl_input": "Close connection with the database", "code_input": "import sqlite3# Connect to the databaseconn = sqlite3.connect('my_database.db')# Create a cursor objectcur = conn.cursor()# Execute a querycur.execute(\"SELECT * FROM my_table\")# Fetch all the rowsrows = cur.fetchall()# Close the connectionconn.close()", "url": "01b6ef83cb7b0e20fe4063575ba37afc", "gt": "def close_database_session ( session ) : try : session . close ( ) except OperationalError as e : raise DatabaseError ( error = e . orig . args [ 1 ] , code = e . orig . args [ 0 ] )"}, {"nl_input": "Return True if created today .", "code_input": "from datetime import datetimedef is_created_today(obj):    if hasattr(obj, 'created_at'):        return obj.created_at.date() == datetime.now().date()    else:        return False", "url": "5e650f644d8fd521a2fb566997bac200", "gt": "def created_today ( self ) : if self . datetime . date ( ) == datetime . today ( ) . date ( ) : return True return False"}, {"nl_input": "r Clean up whitespace in column names . See better version at pugnlp . clean_columns", "code_input": "def clean_columns(df):    df.columns = df.columns.str.replace(' ', '_')    return df", "url": "30bf76a15a72979f26c21ec5492d7e9e", "gt": "def normalize_column_names ( df ) : columns = df . columns if hasattr ( df , 'columns' ) else df columns = [ c . lower ( ) . replace ( ' ' , '_' ) for c in columns ] return columns"}, {"nl_input": "Start a Pdb instance at the calling frame with stdout routed to sys . __stdout__ .", "code_input": "import pdbimport sysdef start_pdb():    frame = sys._getframe(1)  # Get the calling frame    pdb.set_trace()  # Start the Pdb instance    return frame# Call the functionframe = start_pdb()", "url": "0a05a5da32b1fb72cca49d13dc8e3410", "gt": "def set_trace ( ) : # https://github.com/nose-devs/nose/blob/master/nose/tools/nontrivial.py pdb . Pdb ( stdout = sys . __stdout__ ) . set_trace ( sys . _getframe ( ) . f_back )"}, {"nl_input": "Save variable on given path using Pickle Args : variable : what to save path ( str ) : path of the output", "code_input": "import pickledef save_variable(variable, path):    with open(path, 'wb') as f:        pickle.dump(variable, f)# Usagevariable = \"Hello, World!\"path = \"output.pkl\"save_variable(variable, path)", "url": "c2a530e3185141f26984493fe461a1e4", "gt": "def save ( variable , filename ) : fileObj = open ( filename , 'wb' ) pickle . dump ( variable , fileObj ) fileObj . close ( )"}, {"nl_input": "Stops the analysis as soon as possible .", "code_input": "# This is a comment# This is a simple Python program# This is a loop that will run as long as the condition is truewhile True:    # This is a comment    # This is a simple Python code    # This is a simple if statement    if condition:        # This is a comment        # This is a simple Python code        # This is a simple print statement        print(\"The condition is true\")        # This is a comment        # This is a simple Python code        # This is a simple break statement        break    # This is a comment    # This is a simple Python code    # This is a simple print statement    print(\"The condition is not true\")# This is a comment# This is a simple Python code# This is a simple print statementprint(\"The loop has ended\")", "url": "ffe1a2a9c49e02611417c3d70568ca6c", "gt": "def stop ( self ) -> None : if self . _stop and not self . _posted_kork : self . _stop ( ) self . _stop = None"}, {"nl_input": "filter for dict note f should have signature : f :: key - > value - > bool", "code_input": "def filter_dict(d, f):    return {k: v for k, v in d.items() if f(k, v)}# Test the functiond = {'a': True, 'b': False, 'c': True, 'd': False}print(filter_dict(d, lambda k, v: v))  # Output: {'c': True, 'd': False}", "url": "f241dcba436401f13b432446f7acf74c", "gt": "def _ ( f , x ) : return { k : v for k , v in x . items ( ) if f ( k , v ) }"}, {"nl_input": "Checks if the given type is an enum type .", "code_input": "from enum import Enumdef is_enum(obj):    return isinstance(obj, Enum)# Testprint(is_enum(1))  # Falseprint(is_enum('a'))  # Falseprint(is_enum(type('a')))  # True", "url": "8f828b31221d8d3d250582d6e33119d8", "gt": "def is_enum_type ( type_ ) : return isinstance ( type_ , type ) and issubclass ( type_ , tuple ( _get_types ( Types . ENUM ) ) )"}, {"nl_input": "Serialises a protobuf object as json", "code_input": "import protobufimport json# Assuming you have a protobuf object named 'message'protobuf_object = protobuf.load(open('path_to_your_protobuf_file', 'rb').read())# Serializing the protobuf object to jsonjson_object = json.dumps(protobuf_object)# Writing the json object to a filewith open('path_to_your_json_file', 'w') as f:    f.write(json_object)", "url": "ae464d2f99fa7222e80bee299a792d9f", "gt": "def toJson ( protoObject , indent = None ) : # Using the internal method because this way we can reformat the JSON js = json_format . MessageToDict ( protoObject , False ) return json . dumps ( js , indent = indent )"}, {"nl_input": "return the key from the request", "code_input": "def get_key_from_request(request):    # Check if the request is a dictionary    if not isinstance(request, dict):        return \"Error: Request is not a dictionary\"    # If the request is a dictionary, return the key    return list(request.keys())[0]# Test the functionrequest = {\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}print(get_key_from_request(request))  # Output: name", "url": "b20b2cbf97fe0d5450903f1b53292657", "gt": "def get ( key , default = None ) : data = get_form ( ) or get_query_string ( ) return data . get ( key , default )"}, {"nl_input": "Converts the string representation of a json number into its python object equivalent an int long float or whatever type suits .", "code_input": "import jsonimport astdef convert_json_number(json_number):    # Parse the JSON number as a string    json_str = json.dumps(json_number)    # Evaluate the JSON number as a literal expression    json_obj = ast.literal_eval(json_str)    return json_obj", "url": "e7bad2f188ea39babea17d023e47e629", "gt": "def default_number_converter ( number_str ) : is_int = ( number_str . startswith ( '-' ) and number_str [ 1 : ] . isdigit ( ) ) or number_str . isdigit ( ) # FIXME: this handles a wider range of numbers than allowed by the json standard, # etc.: float('nan') and float('inf'). But is this a problem? return int ( number_str ) if is_int else float ( number_str )"}, {"nl_input": "Conform Series to new index with optional filling logic .", "code_input": "import pandas as pd# Assuming df is your DataFrame and new_index is your new indexdf = pd.DataFrame({    'A': [1, 2, 3],    'B': [4, 5, 6]})new_index = pd.Index([0, 1, 2, 3, 4])# Use the reindex function to conform the series to the new indexdf = df.reindex(new_index)# Fill the missing values with a specific valuedf.fillna(0, inplace=True)print(df)", "url": "feb258741d3bed95c3717ef0f1fccc39", "gt": "def reindex_axis ( self , labels , axis = 0 , * * kwargs ) : # for compatibility with higher dims if axis != 0 : raise ValueError ( \"cannot reindex series on non-zero axis!\" ) msg = ( \"'.reindex_axis' is deprecated and will be removed in a future \" \"version. Use '.reindex' instead.\" ) warnings . warn ( msg , FutureWarning , stacklevel = 2 ) return self . reindex ( index = labels , * * kwargs )"}, {"nl_input": "Print a colored string to the target handle .", "code_input": "from colorama import Fore, init# Initialize coloramainit()# Print a colored stringprint(Fore.GREEN + 'This is a green colored string.')print(Fore.RED + 'This is a red colored string.')print(Fore.YELLOW + 'This is a yellow colored string.')print(Fore.BLUE + 'This is a blue colored string.')print(Fore.MAGENTA + 'This is a magenta colored string.')print(Fore.CYAN + 'This is a cyan colored string.')print(Fore.WHITE + 'This is a white colored string.')", "url": "5e7880a46ffa2a7b19d6212e49eb068b", "gt": "def cprint ( string , fg = None , bg = None , end = '\\n' , target = sys . stdout ) : _color_manager . set_color ( fg , bg ) target . write ( string + end ) target . flush ( ) # Needed for Python 3.x _color_manager . set_defaults ( )"}, {"nl_input": "Return a vector with the elements rounded to the given number of digits .", "code_input": "def round_numbers(numbers, digits):    return [round(num, digits) for num in numbers]", "url": "ce214949d37d2602b1bae63f9c7323a2", "gt": "def get_rounded ( self , digits ) : result = self . copy ( ) result . round ( digits ) return result"}, {"nl_input": "if we have a compatible fill_value and arr dtype then fill", "code_input": "import numpy as npdef fill_array(arr, fill_value):    if arr.dtype == fill_value.dtype:        arr.fill(fill_value)    else:        print(\"The data types of the array and the fill_value are not compatible.\")# Test the functionarr = np.array([1, 2, 3, 4, 5])fill_array(arr, 0)print(arr)arr = np.array([1, 2, 3, 4, 5, 6])fill_array(arr, 0)print(arr)", "url": "f62e3c00eea2ee9dfa9d98e0e1e50c53", "gt": "def _maybe_fill ( arr , fill_value = np . nan ) : if _isna_compat ( arr , fill_value ) : arr . fill ( fill_value ) return arr"}, {"nl_input": "Error handler", "code_input": "def error_handler(func):    def inner_function(*args, **kwargs):        try:            return func(*args, **kwargs)        except Exception as e:            print(f\"An error occurred: {e}\")    return inner_function@error_handlerdef divide(a, b):    return a / bprint(divide(10, 0))", "url": "82b961ae1166cc5272220f0ff3a4e2f0", "gt": "def on_error ( e ) : # pragma: no cover exname = { 'RuntimeError' : 'Runtime error' , 'Value Error' : 'Value error' } sys . stderr . write ( '{}: {}\\n' . format ( exname [ e . __class__ . __name__ ] , str ( e ) ) ) sys . stderr . write ( 'See file slam_error.log for additional details.\\n' ) sys . exit ( 1 )"}, {"nl_input": "Perform a simple check if the value is callable .", "code_input": "def is_callable(value):    try:        return callable(value)    except TypeError:        return False# Test the functionprint(is_callable(None))  # Falseprint(is_callable(123))  # Falseprint(is_callable('test'))  # Falseprint(is_callable(abs))  # Trueprint(is_callable(lambda x: x))  # True", "url": "3f6168cffe8cb21984c6a12267502db1", "gt": "def callable_validator ( v : Any ) -> AnyCallable : if callable ( v ) : return v raise errors . CallableError ( value = v )"}, {"nl_input": "Pretty print the object s representation .", "code_input": "import jsondef pretty_print(s):    return json.dumps(s, indent=4)s = {'name': 'John', 'age': 30, 'city': 'New York'}print(pretty_print(s))", "url": "c8a5512cc83335ec25437a84dcfb884a", "gt": "def pretty ( obj , verbose = False , max_width = 79 , newline = '\\n' ) : stream = StringIO ( ) printer = RepresentationPrinter ( stream , verbose , max_width , newline ) printer . pretty ( obj ) printer . flush ( ) return stream . getvalue ( )"}, {"nl_input": "Convert CamelCase to lower_and_underscore .", "code_input": "def convert_camel_case(camel_case_string):    lower_and_underscore_string = ''    for char in camel_case_string:        if char.isupper():            lower_and_underscore_string += '_'        lower_and_underscore_string += char.lower()    return lower_and_underscore_string# Test the functionprint(convert_camel_case('convertCamelCase'))", "url": "4af2cb83cba01f1a2877affc9f9af1fd", "gt": "def decamelise ( text ) : s = re . sub ( '(.)([A-Z][a-z]+)' , r'\\1_\\2' , text ) return re . sub ( '([a-z0-9])([A-Z])' , r'\\1_\\2' , s ) . lower ( )"}, {"nl_input": "Checks if the string is a palindrome ( https : // en . wikipedia . org / wiki / Palindrome ) .", "code_input": "def is_palindrome(s):    s = s.replace(' ', '')  # remove spaces    s = s.lower()  # convert to lowercase    s = ''.join(c for c in s if c.isalnum())  # remove non-alphanumeric characters    return s == s[::-1]  # compare the string with its reverse# Test the functionprint(is_palindrome('A man a plan a canal Panama'))  # Trueprint(is_palindrome('Not a palindrome'))  # False", "url": "0a8601aa40e8e29e9a34b4bfee20bdb0", "gt": "def is_palindrome ( string , strict = True ) : if is_full_string ( string ) : if strict : return reverse ( string ) == string return is_palindrome ( SPACES_RE . sub ( '' , string ) ) return False"}, {"nl_input": "Convert string from snake case to camel case .", "code_input": "def snake_to_camel(snake_str):    components = snake_str.split('_')    return ''.join(x.title() for x in components)# Test the functionprint(snake_to_camel('hello_world'))  # Output: HelloWorld", "url": "96f5c07d79e853ad64b6e045f2ea2e3b", "gt": "def snake_to_camel ( s : str ) -> str : fragments = s . split ( '_' ) return fragments [ 0 ] + '' . join ( x . title ( ) for x in fragments [ 1 : ] )"}, {"nl_input": "Primary entry point to turn kwargs into properties", "code_input": "class KwargsToProperties:    def __init__(self, **kwargs):        for key, value in kwargs.items():            setattr(self, key, value)# Usagekwargs_to_properties = KwargsToProperties(name='John', age=30)print(kwargs_to_properties.name)  # Output: Johnprint(kwargs_to_properties.age)   # Output: 30", "url": "0a32a04e8445904777f8caeebdb8fffd", "gt": "def updateFromKwargs ( self , properties , kwargs , collector , * * unused ) : properties [ self . name ] = self . getFromKwargs ( kwargs )"}, {"nl_input": "Context manager to temporarily disable certificate validation in the standard SSL library .", "code_input": "import sslimport urllib.requestclass SSLContextManager(object):    def __init__(self, context=ssl.create_default_context()):        self.context = context    def __enter__(self):        self.old_context = ssl.get_default_verify_paths()        ssl.get_default_verify_paths().load_cert_chain(            self.context.get_ca_certs_path())        ssl.get_default_verify_paths().load_privatekey(            self.context.get_privatekey_path())        ssl.get_default_verify_paths().load_ca_certs(            self.context.get_ca_certs_path())        self.context.check_hostname = False        self.context.verify_mode = ssl.CERT_NONE        return self    def __exit__(self, exc_type, exc_", "url": "e8d31bf9064cd469a1dc39294f7fe457", "gt": "def disable_cert_validation ( ) : current_context = ssl . _create_default_https_context ssl . _create_default_https_context = ssl . _create_unverified_context try : yield finally : ssl . _create_default_https_context = current_context"}, {"nl_input": "Returns the number of bytes to represent this dtype .", "code_input": "import numpy as npdef get_bytes_per_dtype(dtype):    return np.dtype(dtype).itemsizeprint(get_bytes_per_dtype('int32'))", "url": "991303bd65d07a7092b5456f65501117", "gt": "def size ( dtype ) : dtype = tf . as_dtype ( dtype ) if hasattr ( dtype , 'size' ) : return dtype . size return np . dtype ( dtype ) . itemsize"}, {"nl_input": "Parses hostname from URL . : param url : URL : return : hostname", "code_input": "import urllib.parsedef parse_hostname(url):    parsed_url = urllib.parse.urlparse(url)    hostname = parsed_url.netloc    return hostname# Test the functionurl = \"http://www.google.com\"print(parse_hostname(url))  # Output: www.google.com", "url": "13343f8f3c5515600e035d8cca7abd84", "gt": "def url_host ( url : str ) -> str : from urllib . parse import urlparse res = urlparse ( url ) return res . netloc . split ( ':' ) [ 0 ] if res . netloc else ''"}, {"nl_input": "Given a list ( l ) will removing duplicates from the list preserving the original order of the list . Assumes that the list entrie are hashable .", "code_input": "def remove_duplicates(l):    seen = set()    result = []    for item in l:        if item not in seen:            seen.add(item)            result.append(item)    return result", "url": "6156271232598d8b1fcc3d17b7f70287", "gt": "def dedup_list ( l ) : dedup = set ( ) return [ x for x in l if not ( x in dedup or dedup . add ( x ) ) ]"}, {"nl_input": "Helper for pulling a keyed value off various types of objects", "code_input": "def get_keyed_value(obj, key):    keyed_value_funcs = {        str: lambda s: s[key],        int: lambda i: i[key],        float: lambda f: f[key],        list: lambda l: l[key],        dict: lambda d: d[key]    }    func = keyed_value_funcs.get(type(obj))    if func:        return func(obj)    else:        raise TypeError(f\"Unsupported type: {type(obj)}\")# Test the functionprint(get_keyed_value(\"Hello\", \"l\"))  # Output: eprint(get_keyed_value(123, \"o\"))  # Output: 3print(get_keyed_value(123.45, \"o\")) ", "url": "b6bb535456a96c9b909bb499e8a0d64f", "gt": "def get_value ( key , obj , default = missing ) : if isinstance ( key , int ) : return _get_value_for_key ( key , obj , default ) return _get_value_for_keys ( key . split ( '.' ) , obj , default )"}, {"nl_input": "Writes the string to stdout", "code_input": "print(\"Hello, World!\")", "url": "130fea41886bd6573c8f66d1d1b1cc62", "gt": "def _stdout_raw ( self , s ) : print ( s , end = '' , file = sys . stdout ) sys . stdout . flush ( )"}, {"nl_input": "Gets RAM memory usage", "code_input": "import psutildef get_ram_memory_usage():    # Get the current process's memory info    process = psutil.Process()    # Get the memory info for the process's memory usage    memory_info = process.memory_info()    # Return the memory usage in bytes    return memory_info.rssprint(get_ram_memory_usage())", "url": "36e35aabc8ba46fc2ddb8e9843fbb19f", "gt": "def get_memory_usage ( ) : process = psutil . Process ( os . getpid ( ) ) mem = process . memory_info ( ) . rss return mem / ( 1024 * 1024 )"}, {"nl_input": "Return true if a value is a finite number .", "code_input": "def is_finite(value):    try:        float(value)        if value == int(value):            return False        else:            return True    except ValueError:        return False", "url": "20a9dee3715bfda8b9951585455866ce", "gt": "def is_finite ( value : Any ) -> bool : return isinstance ( value , int ) or ( isinstance ( value , float ) and isfinite ( value ) )"}, {"nl_input": "Returns the column mapped by db_field name", "code_input": "import sqlite3# Connect to the SQLite databaseconn = sqlite3.connect('my_database.db')# Create a cursor objectcur = conn.cursor()# Execute the querycur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")# Fetch all the table namestable_names = cur.fetchall()# Get the first table nametable_name = table_names[0][0]# Execute the query to get the column namescur.execute(f\"SELECT name FROM {table_name} LIMIT 0;\")# Fetch all the column namescolumn_names = cur.fetchall()# Get the first column namecolumn_name = column_names[0][0]# Print the column nameprint(column_name)# Close the connectionconn.close()", "url": "09fe8b23516543ed7b0beb4c00c2c151", "gt": "def _get_column_by_db_name ( cls , name ) : return cls . _columns . get ( cls . _db_map . get ( name , name ) )"}, {"nl_input": "Downsample x by factor using striding .", "code_input": "def downsample(x, factor):    return x[::factor]", "url": "4a46bee21402859242a82bb3267915e7", "gt": "def downsample_with_striding ( array , factor ) : return array [ tuple ( np . s_ [ : : f ] for f in factor ) ]"}, {"nl_input": "Cleanup the session if it was created here", "code_input": "from sqlalchemy import create_engine, MetaData, Table# Create a connection to the databaseengine = create_engine('sqlite:///mydatabase.db')# Reflect the existing database into a new modelmetadata = MetaData()metadata.reflect(engine)# Get the sessionSession = sessionmaker(bind=engine)session = Session()# Query the database to get the sessionsession_query = session.query(Table).filter(Table.name == 'my_session').first()# If the session exists, delete itif session_query:    session.delete(session_query)    session.commit()", "url": "a8a603e0ae848a1659ac97bbf97c393d", "gt": "def __del__ ( self ) : if self . _cleanup_session : self . _session . loop . run_until_complete ( self . _session . close ( ) )"}, {"nl_input": "Strips spaces : param x : : return :", "code_input": "def strip_spaces(x):    return x.strip()", "url": "5c2cb0d747482f06316ecf2034c1b403", "gt": "def strip_spaces ( x ) : x = x . replace ( b' ' , b'' ) x = x . replace ( b'\\t' , b'' ) return x"}, {"nl_input": "Index of the last occurrence of x in the sequence .", "code_input": "def last_occurrence(sequence, x):    return sequence[::-1].index(x)sequence = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]x = 1print(last_occurrence(sequence, x))", "url": "f0181095e2b214bca904dedc120dac57", "gt": "def _rindex ( mylist : Sequence [ T ] , x : T ) -> int : return len ( mylist ) - mylist [ : : - 1 ] . index ( x ) - 1"}, {"nl_input": "Pad the text .", "code_input": "def pad_text(text, length):    return text.ljust(length)text = \"Pad\"length = 10print(pad_text(text, length))", "url": "2182fa769b2e6aebf55d8607b1aeae43", "gt": "def _pad ( self , text ) : top_bottom = ( \"\\n\" * self . _padding ) + \" \" right_left = \" \" * self . _padding * self . PAD_WIDTH return top_bottom + right_left + text + right_left + top_bottom"}, {"nl_input": "Return a string with punctuation removed .", "code_input": "import stringdef remove_punctuation(input_string):    # Create a translator object to remove punctuation    translator = str.maketrans('', '', string.punctuation)    # Use the translator object to remove punctuation from the input string    no_punct = input_string.translate(translator)    return no_punct# Test the functionprint(remove_punctuation(\"Hello, World!\"))", "url": "05d248c97e02432ffcafa5fc4d135e4c", "gt": "def remove_punctuation ( text , exceptions = [ ] ) : all_but = [ r'\\w' , r'\\s' ] all_but . extend ( exceptions ) pattern = '[^{}]' . format ( '' . join ( all_but ) ) return re . sub ( pattern , '' , text )"}, {"nl_input": "Conveinience :", "code_input": "I'm sorry, but your query is unclear. Could you please provide more context or clarify what you're asking for? I'm here to help with any computer science-related questions you might have.", "url": "af7417dd34ffedc528d5b41aa79a25a3", "gt": "def get_tablenames ( cur ) : cur . execute ( \"SELECT name FROM sqlite_master WHERE type='table'\" ) tablename_list_ = cur . fetchall ( ) tablename_list = [ str ( tablename [ 0 ] ) for tablename in tablename_list_ ] return tablename_list"}, {"nl_input": "Coerce value to an JSON - compatible representation .", "code_input": "import jsondef coerce_to_json(obj):    return json.dumps(obj)# Test the functiondata = {    \"name\": \"John\",    \"age\": 30,    \"city\": \"New York\"}json_data = coerce_to_json(data)print(json_data)", "url": "ccb63a861341c1600c1672d2347c2a48", "gt": "def _bytes_to_json ( value ) : if isinstance ( value , bytes ) : value = base64 . standard_b64encode ( value ) . decode ( \"ascii\" ) return value"}, {"nl_input": "Discover the current time zone and it s standard string representation ( for source { d } ) .", "code_input": "import pytz# Get the current time zonecurrent_time_zone = pytz.timezone('Asia/Kolkata')# Get the current time in the current time zonecurrent_time = current_time_zone.localize(datetime.datetime.now())# Print the current timeprint(current_time)# Print the current time in a string formatprint(current_time.strftime('%Y-%m-%d %H:%M:%S'))", "url": "9a9656208511dc76df08f3417ff13f0b", "gt": "def get_timezone ( ) -> Tuple [ datetime . tzinfo , str ] : dt = get_datetime_now ( ) . astimezone ( ) tzstr = dt . strftime ( \"%z\" ) tzstr = tzstr [ : - 2 ] + \":\" + tzstr [ - 2 : ] return dt . tzinfo , tzstr"}, {"nl_input": "Strip whitespace from string columns .", "code_input": "def strip_whitespace(df):    # Iterate over each column in the DataFrame    for col in df.columns:        # Apply the strip() method to each element in the column        df[col] = df[col].apply(lambda x: x.strip())    return df", "url": "c614fa426ccf3da4b2087a058e08c051", "gt": "def strip_columns ( tab ) : for colname in tab . colnames : if tab [ colname ] . dtype . kind in [ 'S' , 'U' ] : tab [ colname ] = np . core . defchararray . strip ( tab [ colname ] )"}, {"nl_input": "Do all elements of x have a type from types?", "code_input": "def check_type(x, types):    for t in types:        if not all(isinstance(i, t) for i in x):            return False    return True", "url": "5ab579ff3b2ee7681b98e2869ba83148", "gt": "def _valid_other_type ( x , types ) : return all ( any ( isinstance ( el , t ) for t in types ) for el in np . ravel ( x ) )"}, {"nl_input": "Returns whether the specified element selector is present on the page .", "code_input": "from selenium import webdriverfrom selenium.webdriver.common.by import Bydef is_element_present(driver, selector):    try:        driver.find_element(By.CSS_SELECTOR, selector)        return True    except:        return False# Initialize the driverdriver = webdriver.Firefox()# Use the functionselector = '#myElement'print(is_element_present(driver, selector))# Close the driverdriver.quit()", "url": "9d5df68fdf38594b8242be10f8ee487c", "gt": "def is_element_present ( driver , selector , by = By . CSS_SELECTOR ) : try : driver . find_element ( by = by , value = selector ) return True except Exception : return False"}, {"nl_input": "Returns all column names and their data types as a list .", "code_input": "import sqlite3def get_column_names_and_types():    # Connect to the SQLite database    conn = sqlite3.connect('your_database.db')    # Create a cursor object    cur = conn.cursor()    # Fetch all column names and their data types    cur.execute(\"SELECT name, type FROM pragma_table_info('your_table')\")    # Fetch all rows    rows = cur.fetchall()    # Close the connection    conn.close()    # Return the column names and their data types    return rows# Call the functionprint(get_column_names_and_types())", "url": "1001aab66e7872b45d9825d901ea4412", "gt": "def dtypes ( self ) : return [ ( str ( f . name ) , f . dataType . simpleString ( ) ) for f in self . schema . fields ]"}, {"nl_input": "r Checks if l is a numpy array of integers", "code_input": "import numpy as npdef is_integer_array(l):    return isinstance(l, np.ndarray) and l.dtype == np.int64", "url": "4c44318e0564a3746341c25cb08796fb", "gt": "def is_int_vector ( l ) : if isinstance ( l , np . ndarray ) : if l . ndim == 1 and ( l . dtype . kind == 'i' or l . dtype . kind == 'u' ) : return True return False"}, {"nl_input": "Create a run . log within folder . This file contains the time of the latest successful run .", "code_input": "import osimport datetime# Get the current directorycurrent_dir = os.getcwd()# Create a log file in the current directorylog_file = os.path.join(current_dir, 'latest_run.log')# Get the current timenow = datetime.datetime.now()# Write the current time to the log filewith open(log_file, 'w') as f:    f.write(str(now))", "url": "8595eb12cbc332479f76bff0d5054589", "gt": "def create_run_logfile ( folder ) : with open ( os . path . join ( folder , \"run.log\" ) , \"w\" ) as f : datestring = datetime . datetime . utcnow ( ) . strftime ( \"%Y-%m-%d %H:%M:%S\" ) f . write ( \"timestamp: '%s'\" % datestring )"}, {"nl_input": "Try to read a value named key from the headers .", "code_input": "from flask import Flask, requestapp = Flask(__name__)@app.route('/')def home():    key = request.headers.get('key')    return f'The value of the key is: {key}'if __name__ == '__main__':    app.run(debug=True)", "url": "d0f81def36969915a8a8466379b2a7ab", "gt": "def get_from_headers ( request , key ) : value = request . headers . get ( key ) return to_native ( value )"}, {"nl_input": "Pull the value from the cookiejar .", "code_input": "import requests# Create a sessionsession = requests.Session()# Pull the value from the cookiejarcookie = session.cookies# Print the cookieprint(cookie)", "url": "7c99a79a7ad75ac06ade2a1e106df71a", "gt": "def parse_cookies ( self , req , name , field ) : return core . get_value ( req . COOKIES , name , field )"}, {"nl_input": "Returns a prettified version of the SQL as a list of lines to help in creating a useful diff between two SQL statements .", "code_input": "import sqlparsedef prettify_sql(sql):    return sqlparse.format(sql, reindent=True)", "url": "457aff9c7058c3ba33b7ae0d5386ee0f", "gt": "def prettifysql ( sql ) : pretty = [ ] for line in sql . split ( '\\n' ) : pretty . extend ( [ \"%s,\\n\" % x for x in line . split ( ',' ) ] ) return pretty"}, {"nl_input": "Parse a string as an integer encapsulating error handling .", "code_input": "def parse_string_as_int(s):    try:        return int(s)    except ValueError:        return None# Test the functionprint(parse_string_as_int(\"123\"))  # Output: 123print(parse_string_as_int(\"abc\"))  # Output: None", "url": "c69e122da2d2e1d72e89cfa0116a4f34", "gt": "def prsint ( string ) : string = stypes . stringToCharP ( string ) intval = ctypes . c_int ( ) libspice . prsint_c ( string , ctypes . byref ( intval ) ) return intval . value"}, {"nl_input": "Compiles to native Python bytecode and runs program returning the topmost value on the stack .", "code_input": "import disdef compile_and_execute():    code = \"\"\"    def add(x, y):        return x + y    print(add(1, 2))    \"\"\"    bytecode = compile(code, \"<string>\", \"exec\")    exec(bytecode)compile_and_execute()", "url": "cd6c0b5919ed35ca54f03aed7155d59c", "gt": "def xeval ( source , optimize = True ) : native = xcompile ( source , optimize = optimize ) return native ( )"}, {"nl_input": "Set value in bytearray to int", "code_input": "def bytearray_to_int(bytearray):    return int.from_bytes(bytearray, byteorder='big', signed=False)# Test the functionbytearray = bytearray([1, 2, 3, 4])print(bytearray_to_int(bytearray))  # Output: 1234", "url": "6fec9d169b0a9416a97ce4a338dd32d8", "gt": "def set_int ( bytearray_ , byte_index , _int ) : # make sure were dealing with an int _int = int ( _int ) _bytes = struct . unpack ( '2B' , struct . pack ( '>h' , _int ) ) bytearray_ [ byte_index : byte_index + 2 ] = _bytes return bytearray_"}, {"nl_input": "Add an object to Javascript .", "code_input": "In JavaScript, you can add an object to an array by using the `push()` method. Here is a simple example:```javascriptlet array = [1, 2, 3];let object = {name: 'John', age: 30};array.push(object);console.log(array);```In this example, the `push()` method is used to add the object to the end of the array. The `console.log(array);` line is used to print the updated array to the console.", "url": "3502745173b0a9b89ae0a7f4243ce2a3", "gt": "def add_to_js ( self , name , var ) : frame = self . page ( ) . mainFrame ( ) frame . addToJavaScriptWindowObject ( name , var )"}, {"nl_input": "Create a list of items seperated by seps .", "code_input": "def create_list(items, sep):    return items.split(sep)items = \"item1,item2,item3,item4\"sep = \",\"print(create_list(items, sep))", "url": "4d487dd5451d858ae1df55545338d20c", "gt": "def itemlist ( item , sep , suppress_trailing = True ) : return condense ( item + ZeroOrMore ( addspace ( sep + item ) ) + Optional ( sep . suppress ( ) if suppress_trailing else sep ) )"}, {"nl_input": "Utility function to create regexp for matching escaped separators in strings .", "code_input": "import redef create_regexp(separator):    # escape the separator    escaped_separator = re.escape(separator)    # create the regexp    regexp = re.compile(escaped_separator)    return regexp", "url": "c293149f21c05346b0edfd6e017c0a32", "gt": "def make_regex ( separator ) : return re . compile ( r'(?:' + re . escape ( separator ) + r')?((?:[^' + re . escape ( separator ) + r'\\\\]|\\\\.)+)' )"}, {"nl_input": "Return wrapper to named api method .", "code_input": "def api_method(param):    # Some API call here    return \"Result\"def api_method_wrapper(api_method, param):    result = api_method(param)    return result# Now you can use the wrapperresult = api_method_wrapper(api_method, \"Some parameter\")print(result)", "url": "941e68a199cee63e302662e2ce8fe281", "gt": "def __getattr__ ( self , name ) : return functools . partial ( self . _obj . request , self . _api_prefix + name )"}, {"nl_input": "Convert comma - delimited list / string into a list of strings", "code_input": "def convert_to_list(input_string):    return input_string.split(',')# Test the functioninput_string = \"item1,item2,item3,item4\"print(convert_to_list(input_string))", "url": "bef112878733e2d59a2929a7920b88a7", "gt": "def comma_delimited_to_list ( list_param ) : if isinstance ( list_param , list ) : return list_param if isinstance ( list_param , str ) : return list_param . split ( ',' ) else : return [ ]"}, {"nl_input": "Restore settings to default values .", "code_input": "def restore_settings():    # This function is a placeholder and will not work as expected without a specific context.    pass", "url": "3ba6b208b4ed697b5fe003d50b17d99c", "gt": "def restore_default_settings ( ) : global __DEFAULTS __DEFAULTS . CACHE_DIR = defaults . CACHE_DIR __DEFAULTS . SET_SEED = defaults . SET_SEED __DEFAULTS . SEED = defaults . SEED logging . info ( 'Settings reverted to their default values.' )"}, {"nl_input": "Finds parent folder of file", "code_input": "import osdef find_parent_folder(file_path):    parent_folder = os.path.abspath(os.path.join(file_path, os.pardir))    return parent_folder# Test the functionfile_path = \"/path/to/your/file\"print(find_parent_folder(file_path))", "url": "b020996768e441735bad95910a16907e", "gt": "def get_parent_folder_name ( file_path ) : return os . path . split ( os . path . split ( os . path . abspath ( file_path ) ) [ 0 ] ) [ - 1 ]"}, {"nl_input": "This removes newlines and multiple spaces from a string .", "code_input": "def remove_newlines_and_spaces(input_string):    return ' '.join(input_string.split())# Test the functioninput_string = \"This is a test string\\n with multiple   spaces   and newlines.\"print(remove_newlines_and_spaces(input_string))", "url": "ffaf50749737d70a6ecb6ce9b0f9ac24", "gt": "def normalize_value ( text ) : result = text . replace ( '\\n' , ' ' ) result = re . subn ( '[ ]{2,}' , ' ' , result ) [ 0 ] return result"}, {"nl_input": "Compute average gradient norm of an image", "code_input": "import cv2import numpy as npdef compute_average_gradient_norm(image):    # Compute the gradient of the image    dx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)    dy = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)    # Compute the gradient norm    gradient_norm = np.sqrt(dx**2 + dy**2)    # Compute the average gradient norm    average_gradient_norm = np.mean(gradient_norm)    return average_gradient_norm# Load the imageimage = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)# Compute the average gradient normaverage", "url": "11dee73808ab5dea87b4d7e3fe459006", "gt": "def average_gradient ( data , * kwargs ) : return np . average ( np . array ( np . gradient ( data ) ) ** 2 )"}, {"nl_input": "Return a tuple of ( start end ) indices of an item from its index .", "code_input": "def get_indices(lst, item):    start = lst.index(item)    end = len(lst) - lst[::-1].index(item) - 1    return (start, end)", "url": "82969a6dbd0cf5948252addf78f02f52", "gt": "def _get_item_position ( self , idx ) : start = 0 if idx == 0 else self . _index [ idx - 1 ] + 1 end = self . _index [ idx ] return start , end"}, {"nl_input": "Join the given iterable with", "code_input": "def join_iterable(iterable, delimiter):    return delimiter.join(iterable)# Test the functionprint(join_iterable(['apple', 'banana', 'cherry'], ' '))", "url": "d5cd6bdee354cd4c13e1317060fe6702", "gt": "def commajoin_as_strings ( iterable ) : return _ ( u',' ) . join ( ( six . text_type ( i ) for i in iterable ) )"}, {"nl_input": "Get adjacency matrix .", "code_input": "def adjacency_matrix(graph):    nodes = list(graph.keys())    matrix = []    for i in range(len(nodes)):        row = []        for j in range(len(nodes)):            if nodes[j] in graph[nodes[i]]:                row.append(1)            else:                row.append(0)        matrix.append(row)    return matrix# Example usage:graph = {    'A': ['B', 'C'],    'B': ['A', 'D', 'E'],    'C': ['A', 'F'],    'D': ['B'],    'E': ['B', 'F'],    'F': ['C', 'E']}print(adjacency_matrix(graph))", "url": "77ba8682acb16363f35ee39438c5c00b", "gt": "def get_adjacent_matrix ( self ) : edges = self . edges num_edges = len ( edges ) + 1 adj = np . zeros ( [ num_edges , num_edges ] ) for k in range ( num_edges - 1 ) : adj [ edges [ k ] . L , edges [ k ] . R ] = 1 adj [ edges [ k ] . R , edges [ k ] . L ] = 1 return adj"}, {"nl_input": "helper function used for joins builds left and right join list for join function", "code_input": "def build_join_list(left_list, right_list):    # Initialize the result list    result = []    # Iterate over the left list    for left_item in left_list:        # Find the right item that matches the left item        right_item = [item for item in right_list if item == left_item]        # Append the right item to the result list        result.append(right_item)    return result", "url": "b43d396e0c2cb764c7a3923e30cee800", "gt": "def get_join_cols ( by_entry ) : left_cols = [ ] right_cols = [ ] for col in by_entry : if isinstance ( col , str ) : left_cols . append ( col ) right_cols . append ( col ) else : left_cols . append ( col [ 0 ] ) right_cols . append ( col [ 1 ] ) return left_cols , right_cols"}, {"nl_input": "Raises a requests . exceptions . HTTPError if the response has a non - 200 status code .", "code_input": "import requestsdef check_status_code(url):    try:        response = requests.get(url)        if response.status_code != 200:            raise requests.exceptions.HTTPError(\"Request failed with status code: \" + str(response.status_code))    except requests.exceptions.HTTPError as errh:        print (\"HTTP Error:\", errh)    except requests.exceptions.ConnectionError as errc:        print (\"Error Connecting:\", errc)    except requests.exceptions.Timeout as errt:        print (\"Timeout Error:\", errt)    except requests.exceptions.RequestException as err:        print (\"Something went wrong\", err)", "url": "0c0e2e21a0ef56f98b03f742885dd7b1", "gt": "def raise_for_not_ok_status ( response ) : if response . code != OK : raise HTTPError ( 'Non-200 response code (%s) for url: %s' % ( response . code , uridecode ( response . request . absoluteURI ) ) ) return response"}, {"nl_input": "returns the yaml output of the dict .", "code_input": "import yamldef dict_to_yaml(input_dict):    return yaml.dump(input_dict)# Test the functioninput_dict = {'name': 'John', 'age': 30, 'city': 'New York'}print(dict_to_yaml(input_dict))", "url": "3e751fb619760a9827d1958fe4a20f42", "gt": "def yaml ( self ) : return ordered_dump ( OrderedDict ( self ) , Dumper = yaml . SafeDumper , default_flow_style = False )"}, {"nl_input": "Removes stopwords contained in a list of words .", "code_input": "import nltkfrom nltk.corpus import stopwords# Download the stopwords if not already downloadednltk.download('stopwords')def remove_stopwords(words):    # Get the list of English stop words    stop_words = set(stopwords.words('english'))    # Remove the stop words from the list    filtered_words = [word for word in words if word not in stop_words]    return filtered_words# Test the functionwords = ['I', 'am', 'learning', 'Python', 'Programming', 'learning', 'Python']print(remove_stopwords(words))", "url": "6ce9ae857507f7292c65caae0d829141", "gt": "def _removeStopwords ( text_list ) : output_list = [ ] for word in text_list : if word . lower ( ) not in _stopwords : output_list . append ( word ) return output_list"}, {"nl_input": "return unique rows", "code_input": "import pandas as pd# Assuming df is your DataFramedf = pd.DataFrame({    'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'],    'B': ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],    'C': [1, 2, 3, 4, 5, 6, 7, 8],    'D': [1, 2, 2, 3, 3, 4, 5, 6]})# This will return unique rowsunique_rows = df.drop_duplicates()print(unique_rows)", "url": "5585a4d97c570d3a3d4ee8539bdc383c", "gt": "def _unique_rows_numpy ( a ) : a = np . ascontiguousarray ( a ) unique_a = np . unique ( a . view ( [ ( '' , a . dtype ) ] * a . shape [ 1 ] ) ) return unique_a . view ( a . dtype ) . reshape ( ( unique_a . shape [ 0 ] , a . shape [ 1 ] ) )"}, {"nl_input": "Return possible range for min function .", "code_input": "def find_range(lst):    if len(lst) == 0:        return None    return max(lst) - min(lst)# Test the functionprint(find_range([1, 2, 3, 4, 5]))  # Output: 4print(find_range([-1, -2, -3, -4, -5]))  # Output: 4print(find_range([10, 20, 30, 40, 50]))  # Output: 40print(find_range([100, 200, 300, 400, 500]))  # Output: 400", "url": "e7a213e5ce364fbbb4eebdb777dcae72", "gt": "def min_values ( args ) : return Interval ( min ( x . low for x in args ) , min ( x . high for x in args ) )"}, {"nl_input": "Return True if list contains either values of type vtype or None .", "code_input": "def check_list(lst, vtype):    for i in lst:        if isinstance(i, vtype) or i is None:            return True    return False", "url": "9f1568e9761dff31a32f5c4b9e8edd9a", "gt": "def is_nullable_list ( val , vtype ) : return ( isinstance ( val , list ) and any ( isinstance ( v , vtype ) for v in val ) and all ( ( isinstance ( v , vtype ) or v is None ) for v in val ) )"}, {"nl_input": "The current active : class : . Window .", "code_input": "import tkinter as tkdef get_active_widget():    # Get the currently active widget    active_widget = root.focus()    return active_widgetroot = tk.Tk()# Create a button widgetbutton = tk.Button(root, text=\"Click me\")button.pack()# Create another button widgetbutton2 = tk.Button(root, text=\"Don't click me\")button2.pack()# Set the focus on the second buttonroot.focus(button2)# Get the active widgetactive_widget = get_active_widget()print(active_widget)root.mainloop()", "url": "dde85ac504b2390acdd3091d4eb9bcae", "gt": "def get_active_window ( self ) : app = get_app ( ) try : return self . _active_window_for_cli [ app ] except KeyError : self . _active_window_for_cli [ app ] = self . _last_active_window or self . windows [ 0 ] return self . windows [ 0 ]"}, {"nl_input": "This function returns a pretty table used to display the port results .", "code_input": "import pandas as pddef pretty_table(data):    df = pd.DataFrame(data)    return df.to_markdown()", "url": "f97eba655064cbbbe5fab244004635ad", "gt": "def get_table ( ports ) : table = PrettyTable ( [ \"Name\" , \"Port\" , \"Protocol\" , \"Description\" ] ) table . align [ \"Name\" ] = \"l\" table . align [ \"Description\" ] = \"l\" table . padding_width = 1 for port in ports : table . add_row ( port ) return table"}, {"nl_input": "Encapsulating the rules for whether the request was to a Flask endpoint", "code_input": "from flask import Flask, requestapp = Flask(__name__)@app.route('/endpoint', methods=['GET', 'POST'])def handle_request():    if request.method == 'POST':        # Check if the request is a POST request        if request.is_json:            # Check if the request is a JSON request            content = request.get_json()            # Check if the request content is a dictionary            if isinstance(content, dict):                # Check if the 'key' field exists in the dictionary                if 'key' in content:                    # Check if the value of the 'key' field is a string                    if isinstance(content['key'], str):                        # If all conditions are met, return a response                        return {'message': 'Request was to a POST request to /endpoint and is a JSON request with a dictionary and a string in the dictionary.'}", "url": "1f9a6c557386541c8bf3018a1e3947c6", "gt": "def _has_fr_route ( self ) : # 404's, 405's, which might not have a url_rule if self . _should_use_fr_error_handler ( ) : return True # for all other errors, just check if FR dispatched the route if not request . url_rule : return False return self . owns_endpoint ( request . url_rule . endpoint )"}, {"nl_input": "Blocks until a keyboard event happens then returns that event s name or if missing its scan code .", "code_input": "from pynput import keyboarddef on_key_press(key):    try:        return key.char    except AttributeError:        return key.scancodewith keyboard.Listener(on_press=on_key_press) as listener:    listener.join()", "url": "fffa142ba9856c6a86224d3d99407a7d", "gt": "def read_key ( suppress = False ) : event = read_event ( suppress ) return event . name or event . scan_code"}, {"nl_input": "Is this an integer .", "code_input": "def is_integer(n):    try:        float(n)        return float(n).is_integer()    except ValueError:        return False# Test the functionprint(is_integer(10))  # Trueprint(is_integer(10.0))  # Trueprint(is_integer(10.1))  # Falseprint(is_integer('10'))  # False", "url": "2832fbd8beeec023e6e6ef3e6b82340c", "gt": "def is_integer ( obj ) : if PYTHON3 : return isinstance ( obj , int ) return isinstance ( obj , ( int , long ) )"}, {"nl_input": "Convert CamelCase to snake_case .", "code_input": "def camel_to_snake_case(camel_case_string):    snake_case_string = ''    for char in camel_case_string:        if char.isupper():            snake_case_string += '_' + char.lower()        else:            snake_case_string += char    return snake_case_string[1:]  # remove the first underscore# Test the functionprint(camel_to_snake_case('CamelCaseString'))", "url": "6c93672cda684ac1a95b2d799714bebf", "gt": "def convert_camel_case_to_snake_case ( name ) : s1 = re . sub ( '(.)([A-Z][a-z]+)' , r'\\1_\\2' , name ) return re . sub ( '([a-z0-9])([A-Z])' , r'\\1_\\2' , s1 ) . lower ( )"}, {"nl_input": "Convert anything to a bytearray . See - http : // stackoverflow . com / questions / 7585435 / best - way - to - convert - string - to - bytes - in - python - 3 - http : // stackoverflow . com / questions / 10459067 / how - to - convert - my - bytearrayb - x9e - x18k - x9a - to - something - like - this - x9e - x1", "code_input": "def string_to_bytearray(s):    return bytearray(s, 'utf-8')# Test the functionprint(string_to_bytearray(\"Hello, World!\"))", "url": "c5046e85180e9f65f88280117dffd4cf", "gt": "def to_bytes ( data : Any ) -> bytearray : # noqa if isinstance ( data , int ) : return bytearray ( [ data ] ) return bytearray ( data , encoding = 'latin-1' )"}, {"nl_input": "Remove comments and empty lines", "code_input": "def remove_comments_and_empty_lines(code):    # Split the code into lines    lines = code.split('\\n')    # Initialize an empty list to store the cleaned code    cleaned_code = []    # Iterate over each line    for line in lines:        # Remove leading and trailing whitespaces        line = line.strip()        # If the line is not empty and does not start with a '#' character        if line and line[0] != '#':            # Append the line to the cleaned code list            cleaned_code.append(line)    # Join the cleaned code lines back into a single string    cleaned_code = '\\n'.join(cleaned_code)    return cleaned_code", "url": "ca1be3d31ee8cf3523dfc4b4d395589e", "gt": "def lines ( input ) : for raw_line in input : line = raw_line . strip ( ) if line and not line . startswith ( '#' ) : yield strip_comments ( line )"}, {"nl_input": "Print emphasized good the given txt message", "code_input": "def print_emphasized(txt):    print(\"**\" + txt + \"**\")print_emphasized(\"Good\")", "url": "e2aa9367d8be0f1d00d8b3baa409dd7a", "gt": "def good ( txt ) : print ( \"%s# %s%s%s\" % ( PR_GOOD_CC , get_time_stamp ( ) , txt , PR_NC ) ) sys . stdout . flush ( )"}, {"nl_input": "This is a compatibility function that takes a C { float } and converts it to an C { int } if the values are equal .", "code_input": "def convert_float_to_int(float_val):    if float_val == int(float_val):        return int(float_val)    else:        return None", "url": "dd11b3695df51c0247478c289387f290", "gt": "def _check_for_int ( x ) : try : y = int ( x ) except ( OverflowError , ValueError ) : pass else : # There is no way in AMF0 to distinguish between integers and floats if x == x and y == x : return y return x"}, {"nl_input": "Toggle pause mode", "code_input": "import timedef toggle_pause(paused):    if paused:        print(\"Paused! Press enter to resume...\")        input()        print(\"Resumed!\")        paused = False    else:        print(\"Pausing...\")        time.sleep(1)  # Pause for 1 second        print(\"Paused!\")        paused = True    return pausedpaused = Falsewhile True:    paused = toggle_pause(paused)", "url": "fd17bc7997ec03214258fa4bd8501d56", "gt": "def toggle_pause ( self ) : self . controller . playing = not self . controller . playing self . music . toggle_pause ( )"}, {"nl_input": "Converts markdown content to text", "code_input": "import markdowndef markdown_to_text(md_content):    md = markdown.Markdown()    text = md.convert(md_content)    return text# Test the functionmd_content = \"# Test Markdown\"print(markdown_to_text(md_content))", "url": "a98a0d961b4a5dfb134ed7d96517dc6a", "gt": "def md_to_text ( content ) : text = None html = markdown . markdown ( content ) if html : text = html_to_text ( content ) return text"}, {"nl_input": "Runs a bash script in the local directory", "code_input": "import osdef run_bash_script():    # Get the list of all files in the current directory    files = os.listdir()    # Check if there is a bash script in the current directory    for file in files:        if file.endswith(\".sh\"):            # Run the bash script            os.system(\"bash \" + file)            breakrun_bash_script()", "url": "d1387105e649f48d23a75e735be58fdf", "gt": "def bash ( filename ) : sys . stdout . flush ( ) subprocess . call ( \"bash {}\" . format ( filename ) , shell = True )"}, {"nl_input": "This removes newlines and multiple spaces from a string .", "code_input": "def remove_newlines_and_spaces(input_string):    return ' '.join(input_string.split())# Test the functioninput_string = \"This is a test string\\n with multiple   spaces   and newlines.\"print(remove_newlines_and_spaces(input_string))", "url": "ffaf50749737d70a6ecb6ce9b0f9ac24", "gt": "def normalize_value ( text ) : result = text . replace ( '\\n' , ' ' ) result = re . subn ( '[ ]{2,}' , ' ' , result ) [ 0 ] return result"}, {"nl_input": "Get object if child already been read or get child .", "code_input": "def is_child_read(child, children):    # Check if the child is in the list of children    if child in children:        # If the child is in the list, check if it has been read        if children[child] == \"read\":            return True        else:            return False    else:        return False# List of childrenchildren = [\"child1\", \"child2\", \"child3\"]# Function to mark a child as readdef mark_child_as_read(child, children):    if child in children:        children[child] = \"read\"# Test the functionprint(is_child_read(\"child1\", children))  # Should print: True# Mark child1 as readmark_child_as_read(\"child1\", children)print(is_child_read(\"child1\", children))  # Should print: False", "url": "a0eea2c799b9e9787443166f8163bbac", "gt": "def get_object_or_child_by_type ( self , * types ) : objects = self . get_objects_or_children_by_type ( * types ) return objects [ 0 ] if any ( objects ) else None"}, {"nl_input": "Pyqt specific key release callback function . Translates and forwards events to : py : func : keyboard_event .", "code_input": "from PyQt5.QtCore import Qt, pyqtSlotfrom PyQt5.QtWidgets import QApplicationclass Window(QApplication):    def __init__(self, args):        super().__init__(args)    @pyqtSlot(Qt.Key, str)    def keyReleaseEvent(self, key, text):        print(f'Key {key} released with text: {text}')if __name__ == '__main__':    import sys    app = Window(sys.argv)    sys.exit(app.exec_())", "url": "0dedd93aa4ea060e3981a64d1946e3b8", "gt": "def keyReleaseEvent ( self , event ) : self . keyboard_event ( event . key ( ) , self . keys . ACTION_RELEASE , 0 )"}, {"nl_input": "Fill file at", "code_input": "def fill_file(file_name, content):    with open(file_name, 'w') as file:        file.write(content)# Test the functionfill_file('test.txt', 'Hello, World!')", "url": "9c5ed7678eec60027b77c36e9f85ed9f", "gt": "def file_writelines_flush_sync ( path , lines ) : fp = open ( path , 'w' ) try : fp . writelines ( lines ) flush_sync_file_object ( fp ) finally : fp . close ( )"}, {"nl_input": "Uses the Unix ps program to see if a process is running .", "code_input": "import subprocessdef is_process_running(process_name):    # Run the 'ps' command and split the output into lines    output = subprocess.check_output(\"ps -A\", shell=True).decode(\"utf-8\").split(\"\\n\")    # Iterate over the output lines    for line in output:        # If the line contains the process name, return True        if process_name in line:            return True    # If we've gone through the entire output without finding the process, return False    return False# Test the functionprint(is_process_running(\"python\"))  # This will print True if the process is running, False otherwise", "url": "08c543187101769aa1d6bf51dce8be2e", "gt": "def is_running ( process_id : int ) -> bool : pstr = str ( process_id ) encoding = sys . getdefaultencoding ( ) s = subprocess . Popen ( [ \"ps\" , \"-p\" , pstr ] , stdout = subprocess . PIPE ) for line in s . stdout : strline = line . decode ( encoding ) if pstr in strline : return True return False"}, {"nl_input": "Recursivly delete a directory", "code_input": "import osimport shutildef delete_directory(path):    if os.path.exists(path):        shutil.rmtree(path)    else:        print(\"The directory does not exist\")# Test the functiondelete_directory('/path/to/directory')", "url": "0d26e92ada91f0c98d4a321d3bcc7a28", "gt": "def rrmdir ( directory ) : for root , dirs , files in os . walk ( directory , topdown = False ) : for name in files : os . remove ( os . path . join ( root , name ) ) for name in dirs : os . rmdir ( os . path . join ( root , name ) ) os . rmdir ( directory )"}, {"nl_input": "Perform log transform log ( x + 1 ) . Parameters ---------- data : array_like", "code_input": "import numpy as npdef log_transform(data):    return np.log(data + 1)", "url": "cc88f21701ab6077cbe986ba301bb315", "gt": "def log_normalize ( data ) : if sp . issparse ( data ) : data = data . copy ( ) data . data = np . log2 ( data . data + 1 ) return data return np . log2 ( data . astype ( np . float64 ) + 1 )"}, {"nl_input": "Retrieve contents of each page of PDF", "code_input": "pip install PyPDF2", "url": "a0f3d82a41b02af3c9649aa06b89db3d", "gt": "def resources ( self ) : return [ self . pdf . getPage ( i ) for i in range ( self . pdf . getNumPages ( ) ) ]"}, {"nl_input": "Returns a random positive integer ( for a Django PositiveIntegerField )", "code_input": "import randomfrom django.db import modelsclass MyModel(models.Model):    my_field = models.PositiveIntegerField()    def generate_random_positive_integer(self):        return random.randint(1, self.my_field)", "url": "85d319ea47a8b2db80fd83fa200969b4", "gt": "def positive_integer ( anon , obj , field , val ) : return anon . faker . positive_integer ( field = field )"}, {"nl_input": "Extract all union queries from table .", "code_input": "import sqlite3# Connect to the SQLite databaseconn = sqlite3.connect('my_database.db')# Create a cursor objectcur = conn.cursor()# Execute a query to get all union queriescur.execute(\"SELECT * FROM table_name WHERE query_type = 'union'\")# Fetch all the rowsrows = cur.fetchall()# Print the rowsfor row in rows:    print(row)# Close the connectionconn.close()", "url": "f3c15a88ba4b34b9a86e75aa4a8c83b8", "gt": "def flatten_union ( table ) : op = table . op ( ) if isinstance ( op , ops . Union ) : return toolz . concatv ( flatten_union ( op . left ) , [ op . distinct ] , flatten_union ( op . right ) ) return [ table ]"}, {"nl_input": "A tensorflow variable tranfomed to be constrained in a L2 unit ball .", "code_input": "import tensorflow as tf# Assuming var is your TensorFlow variablevar = tf.Variable(tf.random.uniform([10]))# Define the L2 unit ball constraintdef l2_ball_constraint(x):    # Compute the L2 norm of the variable    l2_norm = tf.reduce_sum(x**2)        # Return the variable if it's within the L2 unit ball    return tf.cond(l2_norm <= 1.0, lambda: x, lambda: tf.zeros_like(x))# Apply the L2 unit ball constraint to the variablevar = tf.cond(tf.reduce_sum(var**2) > 1.0, lambda: l2_ball_constraint(var), lambda: var)", "url": "e5fa2723774427d207b10c231427d4c8", "gt": "def unit_ball_L2 ( shape ) : x = tf . Variable ( tf . zeros ( shape ) ) return constrain_L2 ( x )"}, {"nl_input": "Recursively loop through a directory to find all python script files . When one is found it is analyzed for import statements : param path : string : return : generator", "code_input": "import osimport redef find_imports(path):    for root, dirs, files in os.walk(path):        for file in files:            if file.endswith('.py'):                with open(os.path.join(root, file), 'r') as f:                    for line in f:                        match = re.match(r'^import\\s+(.*?)\\s*$', line)                        if match:                            yield match.group(1)# Usageimports = list(find_imports('/path/to/directory'))", "url": "a2f84605b27e7336f7c619e6e6ecb26f", "gt": "def search_script_directory ( self , path ) : for subdir , dirs , files in os . walk ( path ) : for file_name in files : if file_name . endswith ( \".py\" ) : self . search_script_file ( subdir , file_name )"}, {"nl_input": "Extract a de - duped collection ( set ) of text from a file . Expected file format is one item per line .", "code_input": "def extract_unique_text(file_path):    unique_text = set()    with open(file_path, 'r') as file:        for line in file:            unique_text.add(line.strip())    return unique_text# Usagefile_path = 'your_file.txt'unique_text = extract_unique_text(file_path)for line in unique_text:    print(line)", "url": "af678636432a410c764ca9cb0a1afa68", "gt": "def read_set_from_file ( filename : str ) -> Set [ str ] : collection = set ( ) with open ( filename , 'r' ) as file_ : for line in file_ : collection . add ( line . rstrip ( ) ) return collection"}, {"nl_input": "Batches a list into a list of lists with sub - lists sized by a specified batch size .", "code_input": "def batch(lst, batch_size):    return [lst[i:i+batch_size] for i in range(0, len(lst), batch_size)]# Test the functionlst = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]batch_size = 3print(batch(lst, batch_size))", "url": "673c4038436f7b604c37ed0acf9a5adf", "gt": "def batch ( items , size ) : return [ items [ x : x + size ] for x in xrange ( 0 , len ( items ) , size ) ]"}, {"nl_input": "move cursor up", "code_input": "import os# Move cursor upos.system('cls' if os.name == 'nt' else 'clear')", "url": "f4e10c5aa2fe8595abd6657ba28db1c5", "gt": "def select_up ( self ) : r , c = self . _index self . _select_index ( r - 1 , c )"}, {"nl_input": "Returns the progress ratio and percentage .", "code_input": "def calculate_progress_ratio(completed, total):    if total == 0:        return 0    return (completed / total) * 100# Test the functioncompleted = 50total = 100print(f\"Progress Ratio: {calculate_progress_ratio(completed, total)}%\")", "url": "205d2257a363e4a52180c14d82ad05e0", "gt": "def ratio_and_percentage ( current , total , time_remaining ) : return \"{} / {} ({}% completed)\" . format ( current , total , int ( current / total * 100 ) )"}, {"nl_input": "This is a compatibility function that takes a C { float } and converts it to an C { int } if the values are equal .", "code_input": "def convert_float_to_int(float_val):    if float_val == int(float_val):        return int(float_val)    else:        return None", "url": "dd11b3695df51c0247478c289387f290", "gt": "def _check_for_int ( x ) : try : y = int ( x ) except ( OverflowError , ValueError ) : pass else : # There is no way in AMF0 to distinguish between integers and floats if x == x and y == x : return y return x"}, {"nl_input": "Convert a string of bytes into an integer as per X9 . 62 .", "code_input": "def convert_bytes_to_int(byte_string):    return int(byte_string, 2)byte_string = \"11010100111010001101000\"  # This is an example byte stringprint(convert_bytes_to_int(byte_string))", "url": "1731237c9b4f7c37e8c66ec5a989582f", "gt": "def string_to_int ( s ) : result = 0 for c in s : if not isinstance ( c , int ) : c = ord ( c ) result = 256 * result + c return result"}, {"nl_input": "Get letters from string only .", "code_input": "def get_letters(string):    return [char for char in string if char.isalpha()]# Test the functionprint(get_letters(\"Hello, World!\"))", "url": "a81ea10e95124147157d96bd92d03a50", "gt": "def return_letters_from_string ( text ) : out = \"\" for letter in text : if letter . isalpha ( ) : out += letter return out"}, {"nl_input": "the field member matching name or None if no such field is found", "code_input": "def get_member_field(member_name):    members = {        'John': 'Engineer',        'Jane': 'Designer',        'Joe': 'Scientist',        'Jill': 'Architect'    }    return members.get(member_name, None)# Test the functionprint(get_member_field('John'))  # Output: Engineerprint(get_member_field('Joe'))  # Output: Scientistprint(get_member_field('Jane'))  # Output: Designerprint(get_member_field('Jill'))  # Output: Architectprint(get_member_field('Alice'))  # Output: None", "url": "a3cd5a39a6a438b727432f565b6b0acf", "gt": "def get_field_by_name ( self , name ) : for f in self . fields : if f . get_name ( ) == name : return f return None"}, {"nl_input": "Make sure thre is no whitespace in the given string . Will raise a ValueError if whitespace is detected", "code_input": "def check_for_whitespace(input_string):    if ' ' in input_string:        raise ValueError(\"The string contains whitespace.\")    else:        print(\"The string does not contain whitespace.\")# Test the functioncheck_for_whitespace(\"Hello World\")", "url": "c04cc51d17f6cd1739f09e2c0b66a917", "gt": "def _check_whitespace ( string ) : if string . count ( ' ' ) + string . count ( '\\t' ) + string . count ( '\\n' ) > 0 : raise ValueError ( INSTRUCTION_HAS_WHITESPACE )"}, {"nl_input": "Like dict but does not hold any null values .", "code_input": "class NoNullDict(dict):    def __init__(self, *args, **kwargs):        super(NoNullDict, self).__init__(*args, **kwargs)    def __setitem__(self, key, value):        if value is not None:            super(NoNullDict, self).__setitem__(key, value)    def __getitem__(self, key):        return super(NoNullDict, self).__getitem__(key)    def __delitem__(self, key):        super(NoNullDict, self).__delitem__(key)    def __contains__(self, item):        return super(NoNullDict, self).__contains__(item)    def get(self, key, default=None):        return super(NoNullDict, self).get(key, default)    def pop(self, key, default=None):        return super(NoNullD", "url": "ed25600864e57226782fe2815f6ea7a1", "gt": "def nonull_dict ( self ) : return { k : v for k , v in six . iteritems ( self . dict ) if v and k != '_codes' }"}, {"nl_input": "Load and execute a python file .", "code_input": "# Load the Python fileimport importlib# Specify the name of the Python filepython_file = \"my_python_file.py\"# Load the Python fileimportlib.import_module(python_file)# Execute the Python fileexec(open(python_file).read())", "url": "fafac547be2039f7ecb1de9409b4e007", "gt": "def load_files ( files ) : for py_file in files : LOG . debug ( \"exec %s\" , py_file ) execfile ( py_file , globals ( ) , locals ( ) )"}, {"nl_input": "Callback for closing the websocket connection", "code_input": "import asyncioimport websocketsasync def close_websocket(uri, code):    async with websockets.connect(uri) as websocket:        await websocket.close(code=code)asyncio.run(close_websocket('ws://example.com/some-endpoint', 1000))", "url": "aa593ebc558493cc0add3bd8bb6e70e5", "gt": "def _ws_on_close ( self , ws : websocket . WebSocketApp ) : self . connected = False self . logger . error ( 'Websocket closed' ) self . _reconnect_websocket ( )"}, {"nl_input": "Takes a multi - dimensional array and returns a 1 dimensional array with the same contents .", "code_input": "def flatten(arr):    result = []    for sublist in arr:        if isinstance(sublist, list):            for item in sublist:                result.append(item)        else:            result.append(sublist)    return result", "url": "6c2f0cae41d4a8defbd80e5fc9ecf368", "gt": "def flatten_array ( grid ) : grid = [ grid [ i ] [ j ] for i in range ( len ( grid ) ) for j in range ( len ( grid [ i ] ) ) ] while type ( grid [ 0 ] ) is list : grid = flatten_array ( grid ) return grid"}, {"nl_input": "Convert to snake case .", "code_input": "def to_snake_case(text):    return ''.join(['_' + i.lower() if i.isupper() else i for i in text]).lstrip('_')# Test the functionprint(to_snake_case('HelloWorld'))  # Output: hello_world", "url": "da53eabc5a7a8f4162b28d726e183372", "gt": "def to_snake_case ( text ) : s1 = re . sub ( '(.)([A-Z][a-z]+)' , r'\\1_\\2' , text ) return re . sub ( '([a-z0-9])([A-Z])' , r'\\1_\\2' , s1 ) . lower ( )"}, {"nl_input": "Validates that the object itself is some kinda string", "code_input": "def is_string(obj):    return isinstance(obj, str)", "url": "bf5d68d072e8122a9a46bc9e0824407b", "gt": "def is_unicode ( string ) : str_type = str ( type ( string ) ) if str_type . find ( 'str' ) > 0 or str_type . find ( 'unicode' ) > 0 : return True return False"}, {"nl_input": "generate a method to write the configuration in yaml to the method desired", "code_input": "import yamldef write_config_to_yaml(config, file_path):    with open(file_path, 'w') as file:        yaml.dump(config, file)", "url": "d5172b2564f44b89541d52f8c075d897", "gt": "def generate_write_yaml_to_file ( file_name ) : def write_yaml ( config ) : with open ( file_name , 'w+' ) as fh : fh . write ( yaml . dump ( config ) ) return write_yaml"}, {"nl_input": "Write to given samples to a wav file . The samples are expected to be floating point numbers in the range of - 1 . 0 to 1 . 0 .", "code_input": "import waveimport struct# Define the number of channels, sample rate, and sample widthnum_channels = 1sample_rate = 44100sample_width = 2# Define the number of samplesnum_samples = 10000# Define the floating point numberssamples = [(i / num_samples) * 2.0 - 1.0 for i in range(num_samples)]# Convert the floating point numbers to bytesbytes = struct.pack('<' + 'f' * num_samples, *samples)# Open the wav file for writingwav_file = wave.open('output.wav', 'wb')wav_file.setnchannels(num_channels)wav_file.setsampwidth(sample_width)wav_file.setframer", "url": "02774e4da081abce4e8cff9febd5339d", "gt": "def write_wav ( path , samples , sr = 16000 ) : max_value = np . abs ( np . iinfo ( np . int16 ) . min ) data = ( samples * max_value ) . astype ( np . int16 ) scipy . io . wavfile . write ( path , sr , data )"}, {"nl_input": "Render the plot with bokeh . io and push to notebook .", "code_input": "from bokeh.plotting import figure, showfrom bokeh.io import output_notebook# Make sure to use the same output notebook as the one used to create the plotoutput_notebook()# Create a new figure objectp = figure(plot_width=400, plot_height=400, tools=\"xwheel_zoom,xpan,xbox_select,reset\")# Add a line rendererp.line([1, 2, 3, 4, 5], [6, 7, 2, 4, 5], line_width=2)# Show the resultsshow(p)", "url": "02f514c324cacaf0704c2a6509112ebf", "gt": "def _push_render ( self ) : bokeh . io . push_notebook ( handle = self . handle ) self . last_update = time . time ( )"}, {"nl_input": "Takes a nested list and returns the size of each dimension followed by the element type in the list", "code_input": "def get_list_info(nested_list):    def get_size(lst):        size = 0        for i in lst:            if isinstance(i, list):                size += get_size(i)            else:                size += 1        return size    def get_type(lst):        types = []        for i in lst:            if isinstance(i, list):                types += get_type(i)            else:                types.append(type(i).__name__)        return types    size = get_size(nested_list)    types = get_type(nested_list)    return [size, types]# Test the functionnested_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]print(get_list_info(nested_list))", "url": "986d95a235b4666e17e297bc1814526c", "gt": "def get_list_dimensions ( _list ) : if isinstance ( _list , list ) or isinstance ( _list , tuple ) : return [ len ( _list ) ] + get_list_dimensions ( _list [ 0 ] ) return [ ]"}, {"nl_input": "Given a gzipped stream of data yield streams of decompressed data .", "code_input": "import gzipdef decompress_data(gzipped_data):    with gzip.GzipFile(fileobj=gzipped_data) as gzf:        data = gzf.read()        return data# Usagewith open('data.gz', 'rb') as f:    decompressed_data = decompress_data(f)    # do something with decompressed_data", "url": "d81906107a72bbbb48477c029365c550", "gt": "def load_streams ( chunks ) : chunks = peekable ( chunks ) while chunks : if six . PY3 : dc = zlib . decompressobj ( wbits = zlib . MAX_WBITS | 16 ) else : dc = zlib . decompressobj ( zlib . MAX_WBITS | 16 ) yield load_stream ( dc , chunks ) if dc . unused_data : chunks = peekable ( itertools . chain ( ( dc . unused_data , ) , chunks ) )"}, {"nl_input": "Validate if non empty string", "code_input": "def validate_string(s):    if s and s.strip():        return True    return False", "url": "4c267ab3b1fbf3f4c4270f715d93e37c", "gt": "def is_non_empty_string ( input_string ) : try : if not input_string . strip ( ) : raise ValueError ( ) except AttributeError as error : raise TypeError ( error ) return True"}, {"nl_input": "r Checks if l is a 2D numpy array of bools", "code_input": "import numpy as npdef is_2d_bool_array(l):    if not isinstance(l, list):        return False    for i in l:        if not isinstance(i, list):            return False        for j in i:            if not isinstance(j, bool):                return False    return True# Test the functionl = [[True, False], [False, True]]print(is_2d_bool_array(l))  # Output: Truel = [[True, False], [False, 'True']]print(is_2d_bool_array(l))  # Output: Falsel = 'not a list'print(is_2d_bool_array(l))  # Output: False", "url": "8a3b1c52b2ad77e9fd817568f4cec12c", "gt": "def is_bool_matrix ( l ) : if isinstance ( l , np . ndarray ) : if l . ndim == 2 and ( l . dtype == bool ) : return True return False"}, {"nl_input": "Return n size lists from a given list l", "code_input": "def return_n_size_lists(l, n):    return [l[i:i+n] for i in range(0, len(l), n)]# Test the functionl = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]n = 3print(return_n_size_lists(l, n))", "url": "9b703ce1495ac3025601f5addf5595e4", "gt": "def chunk_list ( l , n ) : return [ l [ i : i + n ] for i in range ( 0 , len ( l ) , n ) ]"}, {"nl_input": "This is a compatibility function that takes a C { float } and converts it to an C { int } if the values are equal .", "code_input": "def convert_float_to_int(float_val):    if float_val == int(float_val):        return int(float_val)    else:        return None", "url": "dd11b3695df51c0247478c289387f290", "gt": "def _check_for_int ( x ) : try : y = int ( x ) except ( OverflowError , ValueError ) : pass else : # There is no way in AMF0 to distinguish between integers and floats if x == x and y == x : return y return x"}, {"nl_input": "Convert a list of strings to a list of integers .", "code_input": "def convert_to_int(lst):    return [int(i) for i in lst]# Test the functionlst = ['1', '2', '3', '4', '5']print(convert_to_int(lst))  # Output: [1, 2, 3, 4, 5]", "url": "d03c341cc5f160d047d5458a3393cbdf", "gt": "def strings_to_integers ( strings : Iterable [ str ] ) -> Iterable [ int ] : return strings_to_ ( strings , lambda x : int ( float ( x ) ) )"}, {"nl_input": "Return a new dict with any empty items removed .", "code_input": "def remove_empty_items(d):    return {k: v for k, v in d.items() if v}# Test the functiond = {'a': 'A', 'b': '', 'c': 'C', 'd': None, 'e': 'E'}print(remove_empty_items(d))", "url": "a8c133739d961e115a4cc14c827b0992", "gt": "def _remove_empty_items ( d , required ) : new_dict = { } for k , v in d . items ( ) : if k in required : new_dict [ k ] = v elif isinstance ( v , int ) or v : # \"if v\" would suppress emitting int(0) new_dict [ k ] = v return new_dict"}, {"nl_input": "Install or upgrade setuptools and EasyInstall", "code_input": "import subprocessdef install_or_upgrade_setuptools_and_easyinstall():    subprocess.check_call(['python', 'setup.py', 'install', '--upgrade'])install_or_upgrade_setuptools_and_easyinstall()", "url": "6cb48314baad69035e44a579e4c28a4a", "gt": "def main ( argv , version = DEFAULT_VERSION ) : tarball = download_setuptools ( ) _install ( tarball , _build_install_args ( argv ) )"}, {"nl_input": "Exit the shell session .", "code_input": "import osos.system('exit')", "url": "552e6841d09f58e5e1c8fb096c977099", "gt": "def do_exit ( self , arg ) : if self . current : self . current . close ( ) self . resource_manager . close ( ) del self . resource_manager return True"}, {"nl_input": "Tokenizes * source * and returns the tokens as a list of lists .", "code_input": "def tokenize_source(source):    return source.split()# Test the functionsource = \"This is a test source\"print(tokenize_source(source))", "url": "2aef12f2c1527ef8de50aefbdd1bf8a2", "gt": "def listified_tokenizer ( source ) : io_obj = io . StringIO ( source ) return [ list ( a ) for a in tokenize . generate_tokens ( io_obj . readline ) ]"}, {"nl_input": "Add a read_range primitive", "code_input": "import sqlite3# Connect to the SQLite databaseconn = sqlite3.connect('my_database.db')# Create a cursor objectcur = conn.cursor()# Define the read_range functiondef read_range(start, end):    # Execute the SQL query    cur.execute(f\"SELECT * FROM employees WHERE id >= {start} AND id <= {end}\")    # Fetch all the rows    rows = cur.fetchall()    # Return the rows    return rows# Test the functionprint(read_range(10, 20))# Close the connectionconn.close()", "url": "873e2e123d4b3e09c5cf9042128e4ea4", "gt": "def add_range ( self , sequence , begin , end ) : sequence . parser_tree = parsing . Range ( self . value ( begin ) . strip ( \"'\" ) , self . value ( end ) . strip ( \"'\" ) ) return True"}, {"nl_input": "Print msg to stdout and option log at info level .", "code_input": "import logging# Set up logginglogging.basicConfig(level=logging.INFO)# Define the messagemsg = \"Hello, World!\"# Print the messageprint(msg)# Log the messagelogging.info(msg)", "url": "6a20ea317b052d61a5e30244282c661a", "gt": "def pout ( msg , log = None ) : _print ( msg , sys . stdout , log_func = log . info if log else None )"}, {"nl_input": "Returns a list of all the image s colors .", "code_input": "from PIL import Imagedef get_image_colors(image_path):    img = Image.open(image_path)    return list(img.getdata())# Usagecolors = get_image_colors('path_to_your_image.jpg')", "url": "1009f0bae620cb88f3f2c0ffef639cb5", "gt": "def get_colors ( img ) : w , h = img . size return [ color [ : 3 ] for count , color in img . convert ( 'RGB' ) . getcolors ( w * h ) ]"}, {"nl_input": "Transform underscore separated string to pascal case", "code_input": "def to_pascal_case(s):    return ''.join(x.capitalize() for x in s.split('_'))# Test the functionprint(to_pascal_case('hello_world'))  # Output: HelloWorld", "url": "4850c6548e9a829b0ecf457c6f739fdc", "gt": "def to_pascal_case ( s ) : return re . sub ( r'(?!^)_([a-zA-Z])' , lambda m : m . group ( 1 ) . upper ( ) , s . capitalize ( ) )"}, {"nl_input": "Converts list to string with comma separated values . For string is no - op .", "code_input": "def list_to_string(lst):    return ','.join(str(i) for i in lst)# Test the functionlst = [1, 2, 3, 4, 5]print(list_to_string(lst))", "url": "fba927400ace7484b9037afcd300e79b", "gt": "def list_to_csv ( value ) : if isinstance ( value , ( list , tuple , set ) ) : value = \",\" . join ( value ) return value"}, {"nl_input": "Return the duplicates in a list .", "code_input": "def find_duplicates(lst):    duplicates = []    counts = {}    for i in lst:        if i in counts:            counts[i] += 1        else:            counts[i] = 1    for key, value in counts.items():        if value > 1:            duplicates.append(key)    return duplicates# Test the functionprint(find_duplicates([1, 2, 2, 3, 4, 4, 4, 5, 5, 5, 5]))", "url": "3f760b95cc5ab5274f1b7ef94bbb83ac", "gt": "def find_duplicates ( l : list ) -> set : return set ( [ x for x in l if l . count ( x ) > 1 ] )"}, {"nl_input": "Calculate chi - squared .", "code_input": "import numpy as npdef calculate_chi_squared(x, y):    # Calculate the expected counts    expected_x = len(x) / len(y) * np.sum(x)    expected_y = len(y) / len(x) * np.sum(y)    # Calculate the chi-squared statistic    chi_squared = np.sum((np.array(x) - expected_x) ** 2 / expected_x) + np.sum((np.array(y) - expected_y) ** 2 / expected_y)    return chi_squared# Test the functionx = [1, 2, 2, 3, 4, 4, 4, 5, 5, 5, 5]y = [1, 1,", "url": "3af9a5c791b244e41cb0891c47ff4327", "gt": "def chi_square_calc ( classes , table , TOP , P , POP ) : try : result = 0 for i in classes : for index , j in enumerate ( classes ) : expected = ( TOP [ j ] * P [ i ] ) / ( POP [ i ] ) result += ( ( table [ i ] [ j ] - expected ) ** 2 ) / expected return result except Exception : return \"None\""}, {"nl_input": "Recursively find size of a tree . Slow .", "code_input": "class Node:    def __init__(self, data):        self.data = data        self.children = []def add_child(node, child_node):    node.children.append(child_node)def size_of_tree(node):    if node is None:        return 0    else:        size = 1        for child in node.children:            size += size_of_tree(child)        return size# Create a treeroot = Node(1)add_child(root, Node(2))add_child(root, Node(3))add_child(root, Node(4))add_child(root, Node(5))add_child(root, Node(6))# Print the size of the treeprint(size_of_tree(root))", "url": "8f388f52ff9e9531e8395ea311574a61", "gt": "def size ( self ) : if self is NULL : return 0 return 1 + self . left . size ( ) + self . right . size ( )"}, {"nl_input": "Just the last entry .", "code_input": "def get_last_entry(list):    return list[-1]# Test the functionlist = [1, 2, 3, 4, 5]print(get_last_entry(list))  # Output: 5", "url": "43e0333244d180f72905137d8d1335f7", "gt": "def get_last ( self , table = None ) : if table is None : table = self . main_table query = 'SELECT * FROM \"%s\" ORDER BY ROWID DESC LIMIT 1;' % table return self . own_cursor . execute ( query ) . fetchone ( )"}, {"nl_input": "Move cursor to this line in the current buffer .", "code_input": "import vim# Move cursor to the 5th linevim.command('5')", "url": "85bf8f526e4cc0590ecb0b556389c65a", "gt": "def _go_to_line ( editor , line ) : b = editor . application . current_buffer b . cursor_position = b . document . translate_row_col_to_index ( max ( 0 , int ( line ) - 1 ) , 0 )"}, {"nl_input": "Terminate all workers and threads .", "code_input": "import subprocessdef terminate_all_workers():    # Get all running processes    processes = subprocess.Popen(['ps', '-A'], stdout=subprocess.PIPE).communicate()[0].decode()    # Split the output into lines    lines = processes.split('\\n')    # Iterate over the lines    for line in lines:        # Skip the first line (which contains column headers)        if 'PID' in line:            continue        # Split the line into columns        columns = line.split()        # If the line contains at least one number, it's a process        if len(columns) > 1:            # Get the PID from the line            pid = columns[0]            # Try to terminate the process            try:                sub", "url": "8a01d94ec727f7f460e884f936334ec5", "gt": "def terminate ( self ) : for t in self . _threads : t . quit ( ) self . _thread = [ ] self . _workers = [ ]"}, {"nl_input": "Pull the value from the cookiejar .", "code_input": "import requests# Create a sessionsession = requests.Session()# Pull the value from the cookiejarcookie = session.cookies# Print the cookieprint(cookie)", "url": "7c99a79a7ad75ac06ade2a1e106df71a", "gt": "def parse_cookies ( self , req , name , field ) : return core . get_value ( req . COOKIES , name , field )"}, {"nl_input": "Checks if invoking supplied clang - apply - replacements binary works .", "code_input": "import subprocessdef check_clang_replacements_binary():    try:        subprocess.run(['clang', '-h'], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)        return True    except subprocess.CalledProcessError:        return Falseif __name__ == \"__main__\":    print(check_clang_replacements_binary())", "url": "6adea12a7dde7655f0f1a389ceb335ef", "gt": "def check_clang_apply_replacements_binary ( args ) : try : subprocess . check_call ( [ args . clang_apply_replacements_binary , '--version' ] ) except : print ( 'Unable to run clang-apply-replacements. Is clang-apply-replacements ' 'binary correctly specified?' , file = sys . stderr ) traceback . print_exc ( ) sys . exit ( 1 )"}, {"nl_input": "Convert numbers to floats whether the decimal point is . or", "code_input": "def convert_to_float(num):    return float(num)# Test the functionprint(convert_to_float(10))print(convert_to_float(10.0))print(convert_to_float(10.1))", "url": "1834a6c375a0ddbea017871ca95904c0", "gt": "def comma_converter ( float_string ) : trans_table = maketrans ( b',' , b'.' ) return float ( float_string . translate ( trans_table ) )"}, {"nl_input": "Get random binary tree node .", "code_input": "import randomclass Node:    def __init__(self, value):        self.value = value        self.children = []class BinaryTree:    def __init__(self, root):        self.root = root    def get_random_node(self):        return self._get_random_node(self.root)    def _get_random_node(self, start):        if start is None:            return None        else:            return start if random.random() < 0.5 else random.choice(start.children)", "url": "3f554dfb1717ee0df76ea31085afcf39", "gt": "def getRandomBinaryTreeLeafNode ( binaryTree ) : if binaryTree . internal == True : if random . random ( ) > 0.5 : return getRandomBinaryTreeLeafNode ( binaryTree . left ) else : return getRandomBinaryTreeLeafNode ( binaryTree . right ) else : return binaryTree"}, {"nl_input": "Call spell checker with arguments .", "code_input": "pip install pyspellchecker", "url": "d13d06b0d9509b466ca8f6f77508ccde", "gt": "def call_spellchecker ( cmd , input_text = None , encoding = None ) : process = get_process ( cmd ) # A buffer has been provided if input_text is not None : for line in input_text . splitlines ( ) : # Hunspell truncates lines at `0x1fff` (at least on Windows this has been observed) # Avoid truncation by chunking the line on white space and inserting a new line to break it. offset = 0 end = len ( line ) while True : chunk_end = offset + 0x1fff m = None if chunk_end >= end else RE_LAST_SPACE_IN_CHUNK . search ( line , offset , chunk_end ) if m : chunk_end = m . start ( 1 ) chunk = line [ offset : m . start ( 1 ) ] offset = m . end ( 1 ) else : chunk = line [ offset : chunk_end ] offset = chunk_end # Avoid wasted calls to empty strings if chunk and not chunk . isspace ( ) : process . stdin . write ( chunk + b'\\n' ) if offset >= end : break return get_process_output ( process , encoding )"}, {"nl_input": "Check that value is in values", "code_input": "def check_value(value, values):    if value in values:        return True    else:        return False", "url": "6108b1d5909a32358df805e683091bc8", "gt": "def isin ( value , values ) : for i , v in enumerate ( value ) : if v not in np . array ( values ) [ : , i ] : return False return True"}, {"nl_input": "Return a list of dictionaries which are sorted for only unique entries .", "code_input": "def sort_unique_entries(entries):    unique_entries = list(set(entries))    sorted_entries = sorted(unique_entries, key=lambda x: x['key'])    return sorted_entries", "url": "bcf740019b55c972892333070f45ed82", "gt": "def unique_list_dicts ( dlist , key ) : return list ( dict ( ( val [ key ] , val ) for val in dlist ) . values ( ) )"}, {"nl_input": "Yield all items from iterable except the last one .", "code_input": "def except_last(iterable):    iterator = iter(iterable)    last = None    while True:        try:            last = next(iterator)        except StopIteration:            break    for item in iterator:        if item != last:            yield item", "url": "1ee47a36d336de1330bd893bd95750fb", "gt": "def butlast ( iterable ) : iterable = iter ( iterable ) try : first = next ( iterable ) except StopIteration : return for second in iterable : yield first first = second"}, {"nl_input": "Get primary key properties for a SQLAlchemy cls . Taken from marshmallow_sqlalchemy", "code_input": "from sqlalchemy import inspectfrom marshmallow_sqlalchemy import SQLAlchemyAutoSchemaclass MyModel:    # Define your model here    pass# Create an instance of SQLAlchemyengine = create_engine('sqlite:///:memory:')# Bind the engine to the metadatametadata = MetaData()metadata.bind = engine# Reflect the tableinspector = inspect(engine)# Get the primary key columnsprimary_keys = inspector.get_pk_constraint(MyModel.__tablename__)# Create a schema for the modelschema = SQLAlchemyAutoSchema(model=MyModel)# Get the primary key propertiesprimary_key_properties = [column.name for column in schema.fields.values() if column.primary_key]print(primary_key_properties)", "url": "344250efb585be8c0f0d437f27185d11", "gt": "def primary_keys_full ( cls ) : mapper = cls . __mapper__ return [ mapper . get_property_by_column ( column ) for column in mapper . primary_key ]"}, {"nl_input": "Return a dict with swapped keys and values", "code_input": "def swap_keys_values(d):    return {v: k for k, v in d.items()}# Test the functiond = {'a': 1, 'b': 2, 'c': 3}print(swap_keys_values(d))", "url": "979f3f0fe1af433ff17407bf66d96cad", "gt": "def inverted_dict ( d ) : return dict ( ( force_hashable ( v ) , k ) for ( k , v ) in viewitems ( dict ( d ) ) )"}, {"nl_input": "Get the dimensions of a capture", "code_input": "import cv2# Open the capturecap = cv2.VideoCapture(0)# Check if the capture was opened correctlyif not cap.isOpened():    print(\"Error opening video capture\")    exit()# Get the dimensions of the captureframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))print(\"Frame dimensions: \", frame_width, \"x\", frame_height)# Release the capturecap.release()", "url": "aaaa24a0f289ed002bc3da51e3d15cdf", "gt": "def get_capture_dimensions ( capture ) : width = int ( capture . get ( cv2 . CAP_PROP_FRAME_WIDTH ) ) height = int ( capture . get ( cv2 . CAP_PROP_FRAME_HEIGHT ) ) return width , height"}, {"nl_input": "To know the allocated memory at function termination .", "code_input": "import sysdef get_memory_at_termination():    return sys.getsizeof(0)print(get_memory_at_termination())", "url": "b9198474e1ef2266728aed7e2f57c2cc", "gt": "def memory_used ( self ) : if self . _end_memory : memory_used = self . _end_memory - self . _start_memory return memory_used else : return None"}, {"nl_input": "Read and return filename in root dir of project and return string", "code_input": "import osdef get_filenames_in_root_dir(project_dir):    filenames = [f for f in os.listdir(project_dir) if os.path.isfile(os.path.join(project_dir, f))]    return filenames# Usageproject_dir = '/path/to/your/project'  # replace with your project directoryfilenames = get_filenames_in_root_dir(project_dir)print(filenames)", "url": "5b53077086acefdfc481f0156c22d45a", "gt": "def read ( filename ) : return codecs . open ( os . path . join ( __DIR__ , filename ) , 'r' ) . read ( )"}, {"nl_input": "Instantiate an anonymous file - based Bucket around a single key .", "code_input": "import boto3# Instantiate a sessionsession = boto3.Session(    aws_access_key_id='YOUR_ACCESS_KEY',    aws_secret_access_key='YOUR_SECRET_KEY',    region_name='us-west-2')# Instantiate a service clients3 = session.client('s3')# Instantiate a bucketbucket = s3.create_bucket(    Bucket='my-bucket',    CreateBucketConfiguration={        'LocationConstraint': 'us-west-2'    })", "url": "1cd1dc7bbfb30f40638f2a27dd200559", "gt": "def __init__ ( self , name , contained_key ) : self . name = name self . contained_key = contained_key"}, {"nl_input": "Returns a 3x3 cross - product matrix from a 3 - element vector .", "code_input": "import numpy as npdef cross_product_matrix(vector):    # Check if the vector is a 3-element numpy array    if len(vector) != 3:        raise ValueError(\"The vector should be a 3-element numpy array\")        # Calculate the cross-product matrix    matrix = np.array([[0, -vector[2], vector[1]],                       [vector[2], 0, -vector[0]],                       [-vector[1], vector[0], 0]])        return matrix# Test the functionvector = np.array([1, 2, 3])print(cross_product_matrix(vector))", "url": "2492a256abb481d43a2a066b8da72044", "gt": "def cross_product_matrix ( vec ) : return np . array ( [ [ 0 , - vec [ 2 ] , vec [ 1 ] ] , [ vec [ 2 ] , 0 , - vec [ 0 ] ] , [ - vec [ 1 ] , vec [ 0 ] , 0 ] ] )"}, {"nl_input": "Find the mapping given an index", "code_input": "def get_mapping(index):    mapping = {}    for i in range(index):        mapping[i] = chr(97 + i)    return mapping", "url": "88e0c23054a375aa864fdce761d35810", "gt": "def find_mapping ( es_url , index ) : mapping = None backend = find_perceval_backend ( es_url , index ) if backend : mapping = backend . get_elastic_mappings ( ) if mapping : logging . debug ( \"MAPPING FOUND:\\n%s\" , json . dumps ( json . loads ( mapping [ 'items' ] ) , indent = True ) ) return mapping"}, {"nl_input": "Return whether num is a power of two", "code_input": "def is_power_of_two(num):    if num <= 0:        return False    while num % 2 == 0:        num = num / 2    return num == 1", "url": "38e59d8098901fb657abe07ea53e4970", "gt": "def is_power_of_2 ( num ) : log = math . log2 ( num ) return int ( log ) == float ( log )"}, {"nl_input": "Check if arg is a valid file that already exists on the file system .", "code_input": "import osdef is_valid_file(arg):    if os.path.isfile(arg):        return True    else:        return False", "url": "457753fd65f06a706c64700d4933ab00", "gt": "def is_valid_file ( parser , arg ) : arg = os . path . abspath ( arg ) if not os . path . exists ( arg ) : parser . error ( \"The file %s does not exist!\" % arg ) else : return arg"}, {"nl_input": "Returns a header as a list ready to write to TSV file", "code_input": "def get_header():    return ['column1', 'column2', 'column3']", "url": "721c3006e76c0a49f0cdb41715be8519", "gt": "def generate_header ( headerfields , oldheader , group_by_field ) : fieldtypes = [ 'peptidefdr' , 'peptidepep' , 'nopsms' , 'proteindata' , 'precursorquant' , 'isoquant' ] return generate_general_header ( headerfields , fieldtypes , peptabledata . HEADER_PEPTIDE , oldheader , group_by_field )"}, {"nl_input": "Determines whether the passed value is a string safe for 2 / 3 .", "code_input": "def is_string_safe(value):    if isinstance(value, str):        try:            result = 2 / 3            return result == float(value)        except ZeroDivisionError:            return False    return False", "url": "f6c2c4043a72ee6ac596800045699aa3", "gt": "def is_string ( val ) : try : basestring except NameError : return isinstance ( val , str ) return isinstance ( val , basestring )"}, {"nl_input": "Returns a vector of spherical bessel functions yn : x : The argument . N : values of n will run from 0 to N - 1 .", "code_input": "import numpy as npdef spherical_bessel(x, n):    return np.array([np.spherical_jn(n, theta) for theta in x])# Test the functionx = np.linspace(0, 2*np.pi, 100)n = np.arange(0, 10)print(spherical_bessel(x, n))", "url": "2c2d10e576f0ffc704b857558dbe68d1", "gt": "def sbessely ( x , N ) : out = np . zeros ( N , dtype = np . float64 ) out [ 0 ] = - np . cos ( x ) / x out [ 1 ] = - np . cos ( x ) / ( x ** 2 ) - np . sin ( x ) / x for n in xrange ( 2 , N ) : out [ n ] = ( ( 2.0 * n - 1.0 ) / x ) * out [ n - 1 ] - out [ n - 2 ] return out"}, {"nl_input": "Returns names of object columns in the DataFrame .", "code_input": "def get_object_columns(df):    return df.select_dtypes(include=['object']).columns.tolist()", "url": "ff434fe169ce9fa91ed8e9ecd5323b31", "gt": "def get_obj_cols ( df ) : obj_cols = [ ] for idx , dt in enumerate ( df . dtypes ) : if dt == 'object' or is_category ( dt ) : obj_cols . append ( df . columns . values [ idx ] ) return obj_cols"}, {"nl_input": "Plot a smoothed ( by kernel density estimate ) histogram . : type data : numpy array : param data : An array containing the data to be plotted", "code_input": "import numpy as npimport matplotlib.pyplot as pltfrom scipy.stats import gaussian_kdedef plot_smoothed_histogram(data):    # Create a kernel density estimate    kde = gaussian_kde(data)    # Create a range of x values for the histogram    x = np.linspace(data.min(), data.max(), 100)    # Plot the histogram    plt.hist(data, density=True, alpha=0.5, bins=30,             label='Smoothed Histogram')    # Plot the kernel density estimate    plt.plot(x, kde(x), label='Kernel Density Estimate')    # Add labels and title    plt.xlabel('Data')    plt.ylabel('Frequency')    plt.title('Smoothed Histogram and Kernel Density", "url": "20d4c9337731d52fe439d7ae337e6913", "gt": "def plot_kde ( data , ax , title = None , color = 'r' , fill_bt = True ) : if isinstance ( data , list ) : data = np . asarray ( data ) e = kde . KDEUnivariate ( data . astype ( np . float ) ) e . fit ( ) ax . plot ( e . support , e . density , color = color , alpha = 0.9 , linewidth = 2.25 ) if fill_bt : ax . fill_between ( e . support , e . density , alpha = .35 , zorder = 1 , antialiased = True , color = color ) if title is not None : t = ax . set_title ( title ) t . set_y ( 1.05 )"}, {"nl_input": "Remove the specified parameter from this query", "code_input": "I'm sorry, but I can't provide the help you're looking for without the specific details about the query and the parameter you want to remove. Could you please provide more information?", "url": "5e2992e3203231f5d04080655e6e6c94", "gt": "def remove_parameter ( self , name ) : if name in self . __query : self . __query . pop ( name )"}, {"nl_input": "Closes the connection .", "code_input": "import sqlite3# Connect to the SQLite databaseconn = sqlite3.connect('my_database.db')# Create a cursor objectcur = conn.cursor()# Execute a querycur.execute(\"SELECT * FROM my_table\")# Fetch all the rowsrows = cur.fetchall()# Close the connectionconn.close()", "url": "aaa8ca744df057fc7df107df0da2946e", "gt": "def disconnect ( self ) : self . logger . debug ( 'Close connection...' ) self . auto_reconnect = False if self . websocket is not None : self . websocket . close ( )"}, {"nl_input": "Read text from stdin and print a helpful message for ttys .", "code_input": "import sysdef read_stdin():    for line in sys.stdin:        print(f\"You said: {line.strip()}\")if __name__ == \"__main__\":    read_stdin()", "url": "e0733d51ee06d0addebb4595beb97e0b", "gt": "def read_stdin ( ) : if sys . stdin . isatty ( ) and sys . stdout . isatty ( ) : print ( '\\nReading from stdin until end of file (Ctrl + D)...' ) return sys . stdin . read ( )"}, {"nl_input": "Download file from S3 Bucket", "code_input": "pip install boto3", "url": "12fc3abe142e491a071b985a41eacbcc", "gt": "def download_file_from_bucket ( self , bucket , file_path , key ) : with open ( file_path , 'wb' ) as data : self . __s3 . download_fileobj ( bucket , key , data ) return file_path"}, {"nl_input": "Type casting .", "code_input": "def type_casting(input_string):    try:        return int(input_string)    except ValueError:        try:            return float(input_string)        except ValueError:            return \"Invalid input\"# Test the functionprint(type_casting(\"123\"))print(type_casting(\"123.45\"))print(type_casting(\"abc\"))", "url": "2d8dc20b01a0f3edb16213fdac9acaa8", "gt": "def convert_value ( bind , value ) : type_name = get_type ( bind ) try : return typecast . cast ( type_name , value ) except typecast . ConverterError : return value"}, {"nl_input": "Return a view into the memory", "code_input": "import sysdef get_file_size(file):    file.seek(0, sys.SEEK_END)    size = file.tell()    file.seek(0, sys.SEEK_SET)    return size# Open a filewith open('example.txt', 'r') as f:    file_size = get_file_size(f)    print(f'Size of the file: {file_size} bytes')", "url": "20bcf139232a957c771376918dce26db", "gt": "def read ( self , start_position : int , size : int ) -> memoryview : return memoryview ( self . _bytes ) [ start_position : start_position + size ]"}, {"nl_input": "Returns the index of column 0 of the current item in the underlying model . See also the notes at the top of this module on current item vs selected item ( s ) .", "code_input": "def get_index_of_first_column(model):    # Check if the model is a list of lists or tuples    if isinstance(model, (list, tuple)):        # Get the first item in the list        current_item = model[0]    else:        raise ValueError(\"The model must be a list or tuple\")    # Get the index of the first column in the current item    index_of_first_column = current_item.index(0)    return index_of_first_column", "url": "8ff34d03fd1a41d19991e700bf7264c1", "gt": "def getRowCurrentIndex ( self ) : curIndex = self . currentIndex ( ) col0Index = curIndex . sibling ( curIndex . row ( ) , 0 ) return col0Index"}, {"nl_input": "Recursively find size of a tree . Slow .", "code_input": "class Node:    def __init__(self, data):        self.data = data        self.children = []def add_child(node, child_node):    node.children.append(child_node)def size_of_tree(node):    if node is None:        return 0    else:        size = 1        for child in node.children:            size += size_of_tree(child)        return size# Create a treeroot = Node(1)add_child(root, Node(2))add_child(root, Node(3))add_child(root, Node(4))add_child(root, Node(5))add_child(root, Node(6))# Print the size of the treeprint(size_of_tree(root))", "url": "8f388f52ff9e9531e8395ea311574a61", "gt": "def size ( self ) : if self is NULL : return 0 return 1 + self . left . size ( ) + self . right . size ( )"}, {"nl_input": "Return the median of numeric data unsing the mean of middle two method . If data is empty 0 is returned .", "code_input": "def median_of_middle(lst):    if not lst:        return 0    else:        lst.sort()        if len(lst) % 2 == 0:            return (lst[len(lst) // 2 - 1] + lst[len(lst) // 2]) / 2        else:            return lst[len(lst) // 2]", "url": "a2ed58dc05b0f96ed45e74171c63422e", "gt": "def median ( data ) : if len ( data ) == 0 : return None data = sorted ( data ) return float ( ( data [ len ( data ) // 2 ] + data [ ( len ( data ) - 1 ) // 2 ] ) / 2. )"}, {"nl_input": "Return True if two numbers are equal up to the specified number of places after the decimal point .", "code_input": "def are_equal(num1, num2, places=2):    return round(num1, places) == round(num2, places)", "url": "fa3233a6cd42dc3060664f97aa1c6dd5", "gt": "def _float_almost_equal ( float1 , float2 , places = 7 ) : if round ( abs ( float2 - float1 ) , places ) == 0 : return True return False"}, {"nl_input": "Index of the last occurrence of x in the sequence .", "code_input": "def last_occurrence(sequence, x):    return sequence[::-1].index(x)sequence = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]x = 1print(last_occurrence(sequence, x))", "url": "f0181095e2b214bca904dedc120dac57", "gt": "def _rindex ( mylist : Sequence [ T ] , x : T ) -> int : return len ( mylist ) - mylist [ : : - 1 ] . index ( x ) - 1"}, {"nl_input": "Populate axis limits GUI with current plot values .", "code_input": "import matplotlib.pyplot as plt# Suppose we have a function f(x) that we want to plotdef f(x):    return x**2# Generate some datax = range(-10, 10)y = [f(i) for i in x]# Create a new figureplt.figure()# Plot the dataplt.plot(x, y)# Get the current x and y limitsxlim = plt.xlim()ylim = plt.ylim()# Set the new x and y limitsplt.xlim(xlim[0], xlim[1]*10)plt.ylim(ylim[0], ylim[1]*10)# Show the plotplt.show()", "url": "52074cdb32ef6249813156e7efc7b978", "gt": "def set_xlimits_widgets ( self , set_min = True , set_max = True ) : xmin , xmax = self . tab_plot . ax . get_xlim ( ) if set_min : self . w . x_lo . set_text ( '{0}' . format ( xmin ) ) if set_max : self . w . x_hi . set_text ( '{0}' . format ( xmax ) )"}, {"nl_input": "Redirect the stdout", "code_input": "import sysold_stdout = sys.stdoutnew_stdout = open('output.txt', 'w')sys.stdout = new_stdout# Your code heresys.stdout = old_stdoutnew_stdout.close()", "url": "22f5ab096acfd0ced92efc860645bcaf", "gt": "def redirect_stdout ( new_stdout ) : old_stdout , sys . stdout = sys . stdout , new_stdout try : yield None finally : sys . stdout = old_stdout"}, {"nl_input": "r Like rotate but modifies l in - place .", "code_input": "def rotate(l, k):    k = k % len(l)    l[:] = l[k:] + l[:k]# Test the functionl = [1, 2, 3, 4, 5]rotate(l, 2)print(l)  # Output: [3, 4, 5, 1, 2]", "url": "707569fdd77ebde2ce9e44aeb15df944", "gt": "def iprotate ( l , steps = 1 ) : if len ( l ) : steps %= len ( l ) if steps : firstPart = l [ : steps ] del l [ : steps ] l . extend ( firstPart ) return l"}, {"nl_input": "Replaces from a string ** input ** all the occurrences of some symbols according to mapping ** repls ** .", "code_input": "def replace_symbols(input_string, repls):    for symbol, replacement in repls.items():        input_string = input_string.replace(symbol, replacement)    return input_string", "url": "85d3c78c884351b4ba1ab4b9bbd83d89", "gt": "def __replace_all ( repls : dict , input : str ) -> str : return re . sub ( '|' . join ( re . escape ( key ) for key in repls . keys ( ) ) , lambda k : repls [ k . group ( 0 ) ] , input )"}, {"nl_input": "Calculate the short - time Fourier transform magnitude .", "code_input": "import numpy as npdef calculate_stft_magnitude(signal, fs, nperseg, noverlap):    # Calculate the STFT    f, t, Zxx = signal.stft(signal, fs, nperseg=nperseg, noverlap=noverlap, window='hann')    # Calculate the magnitude of the STFT    stft_magnitude = np.abs(Zxx)    return f, t, stft_magnitude# Example usage:signal = np.random.rand(1000)fs = 100.0  # Sampling frequencynperseg = 50  # Length of the segmentnoverlap = 25  # Overlap between segmentsf, t, stft_magnitude = calculate_stft_magnitude(signal, fs, nperseg, noverlap)", "url": "dbd5611f954c88c313e4e96e1ccb797b", "gt": "def stft_magnitude ( signal , fft_length , hop_length = None , window_length = None ) : frames = frame ( signal , window_length , hop_length ) # Apply frame window to each frame. We use a periodic Hann (cosine of period # window_length) instead of the symmetric Hann of np.hanning (period # window_length-1). window = periodic_hann ( window_length ) windowed_frames = frames * window return np . abs ( np . fft . rfft ( windowed_frames , int ( fft_length ) ) )"}, {"nl_input": "Calculate the SSE to the cluster center", "code_input": "from sklearn.cluster import KMeansimport numpy as np# Assuming X is your data matrixX = np.array([[1, 2], [1, 4], [1, 0], [10, 2], [10, 4], [10, 0]])# Create a KMeans instance with 2 clusterskmeans = KMeans(n_clusters=2, random_state=0).fit(X)# Calculate the SSE to the cluster centerssse = sum(np.linalg.norm(x - kmeans.cluster_centers_[kmeans.labels_ == k])**2         for k, x in enumerate(kmeans.cluster_centers_))print(sse)", "url": "103206f393d3e14ed03ee8f1adc4a0d0", "gt": "def _cal_dist2center ( X , center ) : dmemb2cen = scipy . spatial . distance . cdist ( X , center . reshape ( 1 , X . shape [ 1 ] ) , metric = 'seuclidean' ) return ( np . sum ( dmemb2cen ) )"}, {"nl_input": "Emulate lpop .", "code_input": "import redisr = redis.Redis(host='localhost', port=6379, db=0)def lpop(key):    value = r.lpop(key)    if value is not None:        return value.decode('utf-8')    else:        return None# Test the functionprint(lpop('mylist'))", "url": "08901634f481f05ed3b04c1da455b8b2", "gt": "def rpop ( self , key ) : redis_list = self . _get_list ( key , 'RPOP' ) if self . _encode ( key ) not in self . redis : return None try : value = redis_list . pop ( ) if len ( redis_list ) == 0 : self . delete ( key ) return value except ( IndexError ) : # Redis returns nil if popping from an empty list return None"}, {"nl_input": "When the with statement ends .", "code_input": "# Open a filewith open('example.txt', 'r') as file:    # Read the file    data = file.read()    # Perform some operations on the data    # For example, convert the data to uppercase    uppercase_data = data.upper()    # Write the uppercase data back to the file    with open('example.txt', 'w') as file:        file.write(uppercase_data)", "url": "1d447a9da9154b393c31270b1bb034a1", "gt": "def __exit__ ( self , type , value , traceback ) : if not self . asarfile : return self . asarfile . close ( ) self . asarfile = None"}, {"nl_input": "Creates symbolic link for either operating system . http : // stackoverflow . com / questions / 6260149 / os - symlink - support - in - windows", "code_input": "import os# Get the current working directorycwd = os.getcwd()# Create a symbolic linkos.symlink('http://stackoverflow.com', os.path.join(cwd, 'link_name'))", "url": "1be0c088c4ccabf8a0a9cbc7a533fb82", "gt": "def create_symlink ( source , link_name ) : os_symlink = getattr ( os , \"symlink\" , None ) if isinstance ( os_symlink , collections . Callable ) : os_symlink ( source , link_name ) else : import ctypes csl = ctypes . windll . kernel32 . CreateSymbolicLinkW csl . argtypes = ( ctypes . c_wchar_p , ctypes . c_wchar_p , ctypes . c_uint32 ) csl . restype = ctypes . c_ubyte flags = 1 if os . path . isdir ( source ) else 0 if csl ( link_name , source , flags ) == 0 : raise ctypes . WinError ( )"}, {"nl_input": "Logs out the current session by removing it from the cache . This is expected to only occur when a session has", "code_input": "from flask import Flask, redirect, url_forapp = Flask(__name__)@app.route('/logout')def logout():    # Remove the session, if it exists    session.pop('loggedin', None)    return redirect(url_for('login'))if __name__ == '__main__':    app.run(debug=True)", "url": "6b1aedce31fc54b676ef475bbccca0f4", "gt": "def logout ( cache ) : cache . set ( flask . session [ 'auth0_key' ] , None ) flask . session . clear ( ) return True"}, {"nl_input": "Calculate the Hamming distance between two strings . From Wikipedia article : Iterative with two matrix rows .", "code_input": "def hamming_distance(str1, str2):    if len(str1) != len(str2):        return \"Strings are not of equal length\"    distance = 0    for i in range(len(str1)):        if str1[i] != str2[i]:            distance += 1    return distance# Test the functionstr1 = \"abcde\"str2 = \"bcdef\"print(hamming_distance(str1, str2))", "url": "864a82eccd4052bf4623bc043e1da9f7", "gt": "def hamming ( s , t ) : if len ( s ) != len ( t ) : raise ValueError ( 'Hamming distance needs strings of equal length.' ) return sum ( s_ != t_ for s_ , t_ in zip ( s , t ) )"}, {"nl_input": "Helper function which returns an array with the Intervals boundaries .", "code_input": "def get_intervals_boundaries(intervals):    boundaries = []    for interval in intervals:        boundaries.append(interval[0])        boundaries.append(interval[1])    return boundaries", "url": "5521725c7f9fb840aa2233e10462e5e9", "gt": "def _interval_to_bound_points ( array ) : array_boundaries = np . array ( [ x . left for x in array ] ) array_boundaries = np . concatenate ( ( array_boundaries , np . array ( [ array [ - 1 ] . right ] ) ) ) return array_boundaries"}, {"nl_input": "Submit the form having given id .", "code_input": "import requestsdef submit_form(form_id):    url = \"http://example.com/submit_form\"  # replace with your actual URL    data = {        'form_id': form_id,        # add other form fields here    }    response = requests.post(url, data=data)    return response.status_code# Submit the form with id \"my_form\"submit_form(\"my_form\")", "url": "2456b464c2cdd924c757ebcacad877ac", "gt": "def submit_form_id ( step , id ) : form = world . browser . find_element_by_xpath ( str ( 'id(\"{id}\")' . format ( id = id ) ) ) form . submit ( )"}, {"nl_input": "Slugify filename", "code_input": "def slugify_filename(filename):    # Replace non-alphanumeric characters with hyphens    filename = ''.join(e for e in filename if e.isalnum() or e.isspace())    # Replace multiple hyphens with a single hyphen    filename = filename.replace('-', ' ').title().replace(' ', '-')    return filename", "url": "d03c8445844950a0fdafc88eb5631845", "gt": "def slugify_filename ( filename ) : name , ext = os . path . splitext ( filename ) slugified = get_slugified_name ( name ) return slugified + ext"}, {"nl_input": "Runs the unit test framework . Can be overridden to run anything . Returns True on passing and False on failure .", "code_input": "import unittestclass TestMyFunction(unittest.TestCase):    def test_addition(self):        self.assertEqual(add(1, 2), 3)        self.assertEqual(add(0, 0), 0)        self.assertEqual(add(-1, 1), 0)    def test_subtraction(self):        self.assertEqual(subtract(2, 2), 0)        self.assertEqual(subtract(1, 1), 0)        self.assertEqual(subtract(1, 2), -1)def add(a, b):    return a + bdef subtract(a, b):    return a - bif __name__ == '__main__':    unittest.main()", "url": "595642aaa9f754ce601e2d291d98ec1a", "gt": "def run ( self ) : try : import nose arguments = [ sys . argv [ 0 ] ] + list ( self . test_args ) return nose . run ( argv = arguments ) except ImportError : print ( ) print ( \"*** Nose library missing. Please install it. ***\" ) print ( ) raise"}, {"nl_input": "Return a list of all parsed comments in a file . Mostly for testing & interactive use .", "code_input": "import redef parse_comments(file_name):    with open(file_name, 'r') as file:        data = file.read()    # Regular expression pattern for comments    pattern = r'#.*?$'    # Find all comments in the file    comments = re.findall(pattern, data, re.MULTILINE)    return comments# Test the functionprint(parse_comments('your_file.py'))", "url": "1dc3a21cdc2e7628cf01cea3b18aacba", "gt": "def parse_comments_for_file ( filename ) : return [ parse_comment ( strip_stars ( comment ) , next_line ) for comment , next_line in get_doc_comments ( read_file ( filename ) ) ]"}, {"nl_input": "Register plugin in Spyder s main window", "code_input": "# Create a new moduleimport spyderplugins# Define a new class for your pluginclass MyPlugin:    def __init__(self, name, version, description):        self.name = name        self.version = version        self.description = description    def start(self):        print(f\"Plugin {self.name} started\")    def stop(self):        print(f\"Plugin {self.name} stopped\")# Register your pluginspyderplugins.register_plugin(MyPlugin(\"MyPlugin\", \"1.0\", \"My first plugin\"))", "url": "864135b3a55a9a79c0d47a33500139f2", "gt": "def register_plugin ( self ) : self . main . restore_scrollbar_position . connect ( self . restore_scrollbar_position ) self . main . add_dockwidget ( self )"}, {"nl_input": "Is an object iterable like a list ( and not a string ) ?", "code_input": "class MyIterable:    def __init__(self, data):        self.data = data        self.index = 0    def __iter__(self):        return self    def __next__(self):        if self.index >= len(self.data):            raise StopIteration        result = self.data[self.index]        self.index += 1        return result# Testingmy_iterable = MyIterable([1, 2, 3, 4, 5])for item in my_iterable:    print(item)", "url": "e8d906db3eac56229992dd6701dafd90", "gt": "def listlike ( obj ) : return hasattr ( obj , \"__iter__\" ) and not issubclass ( type ( obj ) , str ) and not issubclass ( type ( obj ) , unicode )"}, {"nl_input": "Check if file or directory is world writable .", "code_input": "import osdef is_writable(path):    try:        # Check if the path exists        if not os.path.exists(path):            return False        # Check if the path is a file        if os.path.isfile(path):            # Check if the file is writable            if os.access(path, os.W_OK):                return True            else:                return False        # Check if the path is a directory        elif os.path.isdir(path):            # Check if the directory is writable            if os.access(path, os.W_OK):                return True            else:                return False    except Exception as e:        return False# Test the functionprint(is_writable('/'))  # Replace '/' with the path you want to check", "url": "b4b9c1d50409852d0126efded851221b", "gt": "def is_writable_by_others ( filename ) : mode = os . stat ( filename ) [ stat . ST_MODE ] return mode & stat . S_IWOTH"}, {"nl_input": "Returns all dates between two dates .", "code_input": "from datetime import datetime, timedeltadef get_dates(start_date, end_date):    date_generated = start_date    dates = []    while date_generated <= end_date:        dates.append(date_generated)        date_generated += timedelta(days=1)    return datesstart_date = datetime(2022, 1, 1)end_date = datetime(2022, 1, 31)dates = get_dates(start_date, end_date)for date in dates:    print(date)", "url": "2ec6dccbbbb87558aac51d057330ced6", "gt": "def dates_in_range ( start_date , end_date ) : return [ start_date + timedelta ( n ) for n in range ( int ( ( end_date - start_date ) . days ) ) ]"}, {"nl_input": "Create a SHA256 hash from a Numpy array .", "code_input": "import hashlibimport numpy as np# Create a numpy arrayarr = np.array([1, 2, 3, 4, 5])# Convert the numpy array to a bytes objectbytes_obj = arr.tobytes()# Create a SHA256 hash objecthash_obj = hashlib.sha256()# Update the hash object with the bytes objecthash_obj.update(bytes_obj)# Get the hexadecimal representation of the hashhex_dig = hash_obj.hexdigest()print(hex_dig)", "url": "1b3888d1a58935502e5b2adb2b60e05c", "gt": "def array_sha256 ( a ) : dtype = str ( a . dtype ) . encode ( ) shape = numpy . array ( a . shape ) sha = hashlib . sha256 ( ) sha . update ( dtype ) sha . update ( shape ) sha . update ( a . tobytes ( ) ) return sha . hexdigest ( )"}, {"nl_input": "Encode ndarray to base64 string image data Parameters ---------- arr : ndarray ( rows cols depth ) kwargs : passed directly to matplotlib . image . imsave", "code_input": "import base64import matplotlib.pyplot as pltimport numpy as npdef encode_ndarray_to_base64(arr, **kwargs):    # Convert the ndarray to a matplotlib image    fig = plt.figure(**kwargs)    ax = fig.add_subplot(111)    ax.imshow(arr)    plt.close(fig)    # Save the image as a PNG    plt.savefig('temp.png', bbox_inches='tight', pad_inches=0)    # Open the PNG image file and read its binary data    with open('temp.png', 'rb') as image_file:        encoded_string = base64.b64encode(image_file.read())    # Remove the temporary PNG file    import os    os.remove('temp.png')    return encoded_string", "url": "d2d722cc0e28ad756bd471900ecc9d88", "gt": "def img_encode ( arr , * * kwargs ) : sio = BytesIO ( ) imsave ( sio , arr , * * kwargs ) sio . seek ( 0 ) img_format = kwargs [ 'format' ] if kwargs . get ( 'format' ) else 'png' img_str = base64 . b64encode ( sio . getvalue ( ) ) . decode ( ) return 'data:image/{};base64,{}' . format ( img_format , img_str )"}, {"nl_input": "A list of functions declared or defined in this module .", "code_input": "import inspectdef get_module_functions():    return [func for func, _ in inspect.getmembers(inspect.currentframe().f_locals['__self__'], inspect.isfunction)]print(get_module_functions())", "url": "c39dfb1294e1cedacd1dba82fe10444c", "gt": "def functions ( self ) : return [ v for v in self . globals . values ( ) if isinstance ( v , values . Function ) ]"}, {"nl_input": "test if object is a list or tuple", "code_input": "def is_list_or_tuple(obj):    return isinstance(obj, (list, tuple))", "url": "4fe4993dee777785be3fcaec037b4d45", "gt": "def is_iter_non_string ( obj ) : if isinstance ( obj , list ) or isinstance ( obj , tuple ) : return True return False"}, {"nl_input": "A non - optimal implementation of a regex filter", "code_input": "import redef regex_filter(text, regex):    matches = re.findall(regex, text)    return matchestext = \"Hello, my name is John Doe and my email is john.doe@example.com\"regex = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"print(regex_filter(text, regex))", "url": "360c91549b5a9b4a4c05559eccff8f03", "gt": "def subn_filter ( s , find , replace , count = 0 ) : return re . gsub ( find , replace , count , s )"}, {"nl_input": "Convert list of key value lists to dict", "code_input": "def convert_to_dict(lst):    return {k: v for k, v in lst}# Test the functionlst = [('a', 1), ('b', 2), ('c', 3)]print(convert_to_dict(lst))", "url": "1b73a949780175c73d5778ca8e2f5b2e", "gt": "def list_of_lists_to_dict ( l ) : d = { } for key , val in l : d . setdefault ( key , [ ] ) . append ( val ) return d"}, {"nl_input": "Convert any timestamp to UTC ( with tzinfo ) .", "code_input": "from datetime import datetimeimport pytzdef convert_to_utc(timestamp):    # Create a datetime object from the timestamp    dt = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')    # Create a timezone object for UTC    utc_tz = pytz.timezone('UTC')    # Convert the datetime object to UTC    utc_dt = utc_tz.localize(dt)    # Return the UTC datetime object    return utc_dt# Test the functiontimestamp = '2022-01-01 12:00:00'utc_dt = convert_to_utc(timestamp)print(utc_dt)", "url": "2a5f56a6f9bf9db10ce4af896725130d", "gt": "def to_utc ( self , dt ) : if dt . tzinfo is None : return dt . replace ( tzinfo = self . utc ) return dt . astimezone ( self . utc )"}, {"nl_input": "Parses a date string formatted like YYYY - MM - DD .", "code_input": "from datetime import datetimedef parse_date(date_string):    return datetime.strptime(date_string, '%Y - %m - %d')# Test the functiondate_string = '2022 - 01 - 01'print(parse_date(date_string))", "url": "023556d0f9084731234739f423f423b8", "gt": "def parse ( self , s ) : return datetime . datetime . strptime ( s , self . date_format ) . date ( )"}, {"nl_input": "Given a callable func trap the indicated exceptions for up to retries times invoking cleanup on the exception . On the final attempt allow any exceptions to propagate .", "code_input": "def trap_exceptions(func, retries, cleanup):    for i in range(retries):        try:            return func()        except Exception as e:            cleanup(e)    return func()", "url": "1a64146c41dcc175d7dced14a4e1efc2", "gt": "def retry_call ( func , cleanup = lambda : None , retries = 0 , trap = ( ) ) : attempts = count ( ) if retries == float ( 'inf' ) else range ( retries ) for attempt in attempts : try : return func ( ) except trap : cleanup ( ) return func ( )"}, {"nl_input": "Returns a datetime object of a given timestamp ( in UTC ) .", "code_input": "import datetimedef convert_unix_to_utc(unix_timestamp):    return datetime.datetime.utcfromtimestamp(unix_timestamp).replace(tzinfo=datetime.timezone.utc)# Test the functionunix_timestamp = 1630000000  # Unix timestamp in secondsprint(convert_unix_to_utc(unix_timestamp))", "url": "3d70f3cd7bb4fcd28a864cd53385c91a", "gt": "def utcfromtimestamp ( cls , timestamp ) : obj = datetime . datetime . utcfromtimestamp ( timestamp ) obj = pytz . utc . localize ( obj ) return cls ( obj )"}, {"nl_input": "Get dimension of an array getting the number of rows and the max num of columns .", "code_input": "def get_dimension(array):    num_rows = len(array)    num_cols = len(array[0]) if array else 0    return num_rows, num_cols", "url": "cdc6bd5ccb9ba6e6aaf76e2667547b09", "gt": "def get_dimension_array ( array ) : if all ( isinstance ( el , list ) for el in array ) : result = [ len ( array ) , len ( max ( [ x for x in array ] , key = len , ) ) ] # elif array and isinstance(array, list): else : result = [ len ( array ) , 1 ] return result"}, {"nl_input": "Print a log message to standard error .", "code_input": "import sysdef log_message(message):    print(message, file=sys.stderr)log_message(\"This is a log message.\")", "url": "336b9bafdd37d354437a6c0bf18ca5ba", "gt": "def print_log ( text , * colors ) : sys . stderr . write ( sprint ( \"{}: {}\" . format ( script_name , text ) , * colors ) + \"\\n\" )"}, {"nl_input": "Decodes a given base64 string into bytes .", "code_input": "import base64def decode_base64(base64_string):    return base64.b64decode(base64_string)# Test the functionbase64_string = 'QmFzZTY0RW5jb2RlZFN0cmluZw=='print(decode_base64(base64_string))", "url": "e1355896799feac76852156156c7c4ce", "gt": "def decode_bytes ( string ) : if is_string_type ( type ( string ) ) : string = bytes ( string , \"utf-8\" ) return base64 . decodebytes ( string )"}, {"nl_input": "Given a target dct and a dict of { key : default value } pairs calls setdefault for all of those pairs .", "code_input": "def set_default_values(target_dict, default_dict):    for key, value in default_dict.items():        target_dict.setdefault(key, value)    return target_dict", "url": "9bbbb20f503ba46da76eaa77b98784af", "gt": "def setdefaults ( dct , defaults ) : for key in defaults : dct . setdefault ( key , defaults [ key ] ) return dct"}, {"nl_input": "Return locale from GET lang param or automatically .", "code_input": "from flask import requestdef get_locale():    lang = request.args.get('lang', 'en')    return lang", "url": "61f13c0b5a9183042dccc906393eddee", "gt": "def set_locale ( request ) : return request . query . get ( 'lang' , app . ps . babel . select_locale_by_request ( request ) )"}, {"nl_input": "Return checker .", "code_input": "def check_palindrome(s):    return s == s[::-1]# Test the functionprint(check_palindrome(\"racecar\"))  # Trueprint(check_palindrome(\"python\"))  # False", "url": "a095b82ce6afd497cdc7fa027a60c84f", "gt": "def cpp_checker ( code , working_directory ) : return gcc_checker ( code , '.cpp' , [ os . getenv ( 'CXX' , 'g++' ) , '-std=c++0x' ] + INCLUDE_FLAGS , working_directory = working_directory )"}, {"nl_input": "Return true if the socket managed by this connection is connected", "code_input": "import socketdef is_connected(connection):    try:        connection.settimeout(1)        connection.send(b'Hello, World!')        connection.shutdown(socket.SHUT_WR)        return True    except socket.error:        return False", "url": "513d431a27bb592c41048d90039995f4", "gt": "def is_connected ( self ) : try : return self . socket is not None and self . socket . getsockname ( ) [ 1 ] != 0 and BaseTransport . is_connected ( self ) except socket . error : return False"}, {"nl_input": "Convert CamelCase to camel_case", "code_input": "def convert_camel_case(camel_case_string):    return ''.join(['_' + i.lower() if i.isupper() else i for i in camel_case_string]).lstrip('_')# Test the functionprint(convert_camel_case('convertCamelCase'))", "url": "e62605ac6be1e0109853647a645d5a0f", "gt": "def camel_to_ ( s ) : s1 = re . sub ( '(.)([A-Z][a-z]+)' , r'\\1_\\2' , s ) return re . sub ( '([a-z0-9])([A-Z])' , r'\\1_\\2' , s1 ) . lower ( )"}, {"nl_input": "Format a byte sized value .", "code_input": "def format_byte_size(byte_size):    if byte_size < 1024:        return f\"{byte_size} B\"    elif byte_size < 1024 * 1024:        return f\"{byte_size / 1024} KB\"    elif byte_size < 1024 * 1024 * 1024:        return f\"{byte_size / (1024 * 1024)} MB\"    else:        return f\"{byte_size / (1024 * 1024 * 1024)} GB\"# Test the functionprint(format_byte_size(1024))  # Output: 1024 Bprint(format_byte_size(1024 * 1024))  # Output: 1.0 KBprint(format_byte_size(1024 * 1024 * 102", "url": "d92799ba562962beae001113ca6732fe", "gt": "def fmt_sz ( intval ) : try : return fmt . human_size ( intval ) except ( ValueError , TypeError ) : return \"N/A\" . rjust ( len ( fmt . human_size ( 0 ) ) )"}, {"nl_input": "Updates requests session user - agent with the driver s user agent", "code_input": "from selenium import webdriver# Create a new instance of the Firefox driverdriver = webdriver.Firefox()# Update the user-agent of the driverdriver.command_executor._parameters['headers'] = {'User-Agent': 'My User Agent'}# Execute the scriptdriver.get('http://www.example.com')# Close the driverdriver.quit()", "url": "0bad6ea9859d756f7237f3fa3dcf1973", "gt": "def copy_user_agent_from_driver ( self ) : selenium_user_agent = self . driver . execute_script ( \"return navigator.userAgent;\" ) self . headers . update ( { \"user-agent\" : selenium_user_agent } )"}, {"nl_input": "Will make any functions return an iterable objects by wrapping its result in a list .", "code_input": "def get_numbers():    return list(range(10))print(get_numbers())", "url": "1cf347f32e0553e66342c5b228b6d453", "gt": "def force_iterable ( f ) : def wrapper ( * args , * * kwargs ) : r = f ( * args , * * kwargs ) if hasattr ( r , '__iter__' ) : return r else : return [ r ] return wrapper"}, {"nl_input": "Detects whether a line is present within a file .", "code_input": "def check_line_in_file(file_name, line):    with open(file_name, 'r') as file:        for file_line in file:            if file_line.strip() == line.strip():                return True    return False# Usageprint(check_line_in_file('your_file.txt', 'your_line'))", "url": "4c56c26e86dccb73a7524fa62749b3c7", "gt": "def is_line_in_file ( filename : str , line : str ) -> bool : assert \"\\n\" not in line with open ( filename , \"r\" ) as file : for fileline in file : if fileline == line : return True return False"}, {"nl_input": "Check if a file exists and is non - empty .", "code_input": "import osdef check_file(file_path):    if os.path.isfile(file_path) and os.path.getsize(file_path) > 0:        return True    else:        return False# Test the functionprint(check_file('test.txt'))  # Replace 'test.txt' with the path to your file", "url": "ba4351c8eadd8c502a13959ccbb889d2", "gt": "def file_exists ( fname ) : try : return fname and os . path . exists ( fname ) and os . path . getsize ( fname ) > 0 except OSError : return False"}, {"nl_input": "Return the largest real value h such that all elements in x are integer multiples of h .", "code_input": "def largest_integer(x):    h = 1    while all(i % h == 0 for i in x):        h += 1    return h - 1", "url": "7a0e230522dc1bfb6f427d5c55f1b354", "gt": "def _gcd_array ( X ) : greatest_common_divisor = 0.0 for x in X : greatest_common_divisor = _gcd ( greatest_common_divisor , x ) return greatest_common_divisor"}, {"nl_input": "Interpolate linearly variable x in rangeX onto rangeY .", "code_input": "def interpolate_linear(x, x_range, y_range):    # Check if x is within the range of x_range    if x < min(x_range) or x > max(x_range):        raise ValueError(\"x is out of range\")    # Calculate the index of x in the x_range    x_index = (x - min(x_range)) / (max(x_range) - min(x_range))    # Interpolate y using the formula: y = y1 + (y2 - y1) * x_index    y = y_range[0] + (y_range[1] - y_range[0]) * x_index    return y", "url": "bba8e86c58de9c086c25b972de480920", "gt": "def lin_interp ( x , rangeX , rangeY ) : s = ( x - rangeX [ 0 ] ) / mag ( rangeX [ 1 ] - rangeX [ 0 ] ) y = rangeY [ 0 ] * ( 1 - s ) + rangeY [ 1 ] * s return y"}, {"nl_input": "Unpickle a python object from the given path .", "code_input": "import pickledef unpickle(path):    with open(path, 'rb') as f:        return pickle.load(f)", "url": "64f148c6a3c867b3f9380ee9172cce34", "gt": "def unpickle ( pickle_file ) : pickle = None with open ( pickle_file , \"rb\" ) as pickle_f : pickle = dill . load ( pickle_f ) if not pickle : LOG . error ( \"Could not load python object from file\" ) return pickle"}, {"nl_input": ">>> _isint ( 123 ) True >>> _isint ( 123 . 45 ) False", "code_input": "def _isint(value):    try:        int(value)        return True    except ValueError:        return False", "url": "eaa5d3df3bbe1169308e890817a30790", "gt": "def _isint ( string ) : return type ( string ) is int or ( isinstance ( string , _binary_type ) or isinstance ( string , _text_type ) ) and _isconvertible ( int , string )"}, {"nl_input": "Report whether another set contains this set .", "code_input": "def is_subset(set1, set2):    return set1.issubset(set2)# Test the functionset1 = {1, 2, 3, 4, 5}set2 = {1, 2, 3}print(is_subset(set1, set2))  # Output: Trueset3 = {6, 7, 8, 9, 10}print(is_subset(set1, set3))  # Output: False", "url": "b13301061e6e68891948ff771a0dd969", "gt": "def issubset ( self , other ) : if len ( self ) > len ( other ) : # Fast check for obvious cases return False return all ( item in other for item in self )"}, {"nl_input": "Collect and serve static files .", "code_input": "from flask import Flask, send_from_directoryapp = Flask(__name__)@app.route('/static/<path:filename>')def serve_static(filename):    return send_from_directory('static', filename)if __name__ == '__main__':    app.run(debug=True)", "url": "cc5b140743d1613ffe94214545936630", "gt": "def serve_static ( request , path , insecure = False , * * kwargs ) : # Follow the same logic Django uses for determining access to the # static-serving view. if not django_settings . DEBUG and not insecure : raise ImproperlyConfigured ( \"The staticfiles view can only be used in \" \"debug mode or if the --insecure \" \"option of 'runserver' is used\" ) if not settings . PIPELINE_ENABLED and settings . PIPELINE_COLLECTOR_ENABLED : # Collect only the requested file, in order to serve the result as # fast as possible. This won't interfere with the template tags in any # way, as those will still cause Django to collect all media. default_collector . collect ( request , files = [ path ] ) return serve ( request , path , document_root = django_settings . STATIC_ROOT , * * kwargs )"}, {"nl_input": "Recursively merge dicts .", "code_input": "def merge_dicts(dict1, dict2):    for key in dict2:        if key in dict1:            if isinstance(dict1[key], dict) and isinstance(dict2[key], dict):                merge_dicts(dict1[key], dict2[key])            else:                dict1[key] = dict2[key]        else:            dict1[key] = dict2[key]    return dict1# Test the functiondict1 = {\"a\": 1, \"b\": 2, \"c\": {\"d\": 4}}dict2 = {\"a\": 3, \"c\": {\"d\": 5}, \"e\": 6}print(merge_dicts(dict1, dict2))", "url": "367ef0f0e3ea4a8eafab16a7ab44c725", "gt": "def update ( dct , dct_merge ) : for key , value in dct_merge . items ( ) : if key in dct and isinstance ( dct [ key ] , dict ) : dct [ key ] = update ( dct [ key ] , value ) else : dct [ key ] = value return dct"}, {"nl_input": "Removes trailing zeroes from indexable collection of numbers", "code_input": "def remove_trailing_zeros(nums):    # Reverse the list to start from the end    nums.reverse()    # Find the index of the first non-zero number    non_zero_index = next((i for i, num in enumerate(nums) if num != 0), None)    # If no non-zero number is found, return an empty list    if non_zero_index is None:        return []    # Reverse the list again to get the numbers in the correct order    nums.reverse()    # Return the list of numbers excluding the trailing zeros    return nums[non_zero_index:]# Test the functionnums = [1, 0, 0, 2, 0, 0, 3, 0]print(remove_trailing_zeros(nums))  # Output: [1, 2, 3]", "url": "18282b3d8bec1a731e59daf433dfd841", "gt": "def __remove_trailing_zeros ( self , collection ) : index = len ( collection ) - 1 while index >= 0 and collection [ index ] == 0 : index -= 1 return collection [ : index + 1 ]"}, {"nl_input": "When the with statement ends .", "code_input": "# Open a filewith open('example.txt', 'r') as file:    # Read the file    data = file.read()    # Perform some operations on the data    # For example, convert the data to uppercase    uppercase_data = data.upper()    # Write the uppercase data back to the file    with open('example.txt', 'w') as file:        file.write(uppercase_data)", "url": "1d447a9da9154b393c31270b1bb034a1", "gt": "def __exit__ ( self , type , value , traceback ) : if not self . asarfile : return self . asarfile . close ( ) self . asarfile = None"}, {"nl_input": "Returns the current xy coordinates of the mouse cursor as a two - integer tuple by calling the GetCursorPos () win32 function .", "code_input": "import pyautoguidef get_cursor_position():    return pyautogui.position()print(get_cursor_position())", "url": "967b8409877fab7c6d1a05090f226266", "gt": "def _position ( ) : cursor = POINT ( ) ctypes . windll . user32 . GetCursorPos ( ctypes . byref ( cursor ) ) return ( cursor . x , cursor . y )"}, {"nl_input": "Open up a GUI browse dialog window and let to user pick a target directory . : return str : Target directory path", "code_input": "import tkinter as tkfrom tkinter import filedialogdef get_directory():    root = tk.Tk()    root.withdraw()    directory = filedialog.askdirectory()    return directoryprint(get_directory())", "url": "d5e734d1fcfeb6be60382165bf589df5", "gt": "def browse_dialog_dir ( ) : _go_to_package ( ) logger_directory . info ( \"enter browse_dialog\" ) _path_bytes = subprocess . check_output ( [ 'python' , 'gui_dir_browse.py' ] , shell = False ) _path = _fix_path_bytes ( _path_bytes , file = False ) if len ( _path ) >= 1 : _path = _path [ 0 ] else : _path = \"\" logger_directory . info ( \"chosen path: {}\" . format ( _path ) ) logger_directory . info ( \"exit browse_dialog\" ) return _path"}, {"nl_input": "Make bars in horizontal bar chart thinner", "code_input": "import matplotlib.pyplot as plt# Datadata = [1, 2, 3, 4, 5]bars = ('A', 'B', 'C', 'D', 'E')# Create a new figurefig = plt.figure()# Add an axesax = fig.add_axes([0,0,1,1])# Create the bar chartax.barh(bars, data, color='skyblue')# Set the thinner barsax.barh(bars, data, color='skyblue', alpha=0.5)# Show the plotplt.show()", "url": "b0be624b8cf1eb2cc8c65f5ac8f1b1fc", "gt": "def _change_height ( self , ax , new_value ) : for patch in ax . patches : current_height = patch . get_height ( ) diff = current_height - new_value # we change the bar height patch . set_height ( new_value ) # we recenter the bar patch . set_y ( patch . get_y ( ) + diff * .5 )"}, {"nl_input": "Wrapper to uncheck a checkbox", "code_input": "import tkinter as tkdef uncheck_checkbox():    # Create a new tkinter window    root = tk.Tk()    # Create a checkbox    checkbox = tk.Checkbutton(root, text=\"Uncheck me\")    # Define a function to uncheck the checkbox    def uncheck():        checkbox.deselect()    # When the checkbox is clicked, uncheck the checkbox    checkbox.bind(\"<Button-1>\", uncheck)    # Pack the checkbox into the window    checkbox.pack()    # Start the tkinter event loop    root.mainloop()# Call the functionuncheck_checkbox()", "url": "cf3e688ced0a0895f3c3cf7463d322ee", "gt": "def checkbox_uncheck ( self , force_check = False ) : if self . get_attribute ( 'checked' ) : self . click ( force_click = force_check )"}, {"nl_input": "1x1 convolution", "code_input": "import numpy as npdef convolution_1x1(input_matrix, filter_matrix):    # Get the dimensions of the input and filter    input_height, input_width = input_matrix.shape    filter_height, filter_width = filter_matrix.shape    # Calculate the dimensions of the output    output_height = input_height - filter_height + 1    output_width = input_width - filter_width + 1    # Create a zero output matrix    output_matrix = np.zeros((output_height, output_width))    # Perform the convolution    for i in range(output_height):        for j in range(output_width):            # Slice the input and filter for the current output position            output_matrix[i, j] = np.sum(input_matrix[i:i+filter_height, j:j+filter_width] * filter_matrix)    return output_matrix# Test the function", "url": "1c63a8f567508c2dbbd974597db516e0", "gt": "def conv1x1 ( in_planes , out_planes , stride = 1 ) : return nn . Conv2d ( in_planes , out_planes , kernel_size = 1 , stride = stride , bias = False )"}, {"nl_input": "Returns the available ffmpeg version", "code_input": "import subprocessdef get_ffmpeg_version():    # Define the command    command = 'ffmpeg -version'    # Execute the command    result = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)    stdout, stderr = result.communicate()    # If the command was successful, return the output    if result.returncode == 0:        return stdout.decode('utf-8').strip()    else:        return f'Error: {stderr.decode(\"utf-8\")}'print(get_ffmpeg_version())", "url": "5672c84f0fb6f7657f191a3093ff16c4", "gt": "def ffmpeg_version ( ) : cmd = [ 'ffmpeg' , '-version' ] output = sp . check_output ( cmd ) aac_codecs = [ x for x in output . splitlines ( ) if \"ffmpeg version \" in str ( x ) ] [ 0 ] hay = aac_codecs . decode ( 'ascii' ) match = re . findall ( r'ffmpeg version (\\d+\\.)?(\\d+\\.)?(\\*|\\d+)' , hay ) if match : return \"\" . join ( match [ 0 ] ) else : return None"}, {"nl_input": "Draw a horizontal line up to a given length .", "code_input": "def draw_line(length):    for i in range(length):        print(\"*\", end=\"\")# Test the functiondraw_line(10)", "url": "bb672ed0a0391881ee18bccacf406e44", "gt": "def hline ( self , x , y , width , color ) : self . rect ( x , y , width , 1 , color , fill = True )"}, {"nl_input": "Return the length of the longest consecutive run of True values .", "code_input": "def longest_run(lst):    max_run = 0    current_run = 0    for i in lst:        if i:            current_run += 1            max_run = max(max_run, current_run)        else:            current_run = 0    return max_run# Test the functionprint(longest_run([True, False, True, False, True, True, False, True, False, False, True, True, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False", "url": "f96218fe24cc389de0fb1c77fe88bf40", "gt": "def longest_run ( da , dim = 'time' ) : d = rle ( da , dim = dim ) rl_long = d . max ( dim = dim ) return rl_long"}, {"nl_input": "Unpickles the classifier used", "code_input": "import pickle# Open the file in binary modewith open('classifier.pkl', 'rb') as f:    # Unpickle the object    classifier = pickle.load(f)", "url": "9fddf29122817bde842baa42b083ce22", "gt": "def load ( self , filename = 'classifier.dump' ) : ifile = open ( filename , 'r+' ) self . classifier = pickle . load ( ifile ) ifile . close ( )"}, {"nl_input": "Asks an SQLAlchemy class how its attribute names correspond to database column names .", "code_input": "from sqlalchemy import Column, String, MetaDataclass MyClass:    metadata = MetaData()    # Define the columns    column1 = Column('column1', String)    column2 = Column('column2', String)    column3 = Column('column3', String)    # Define the class with the columns    __table__ = Table('my_table', metadata, autoload_with=metadata)    # Get the column names    column_names = [column.name for column in MyClass.__table__.columns]    # Print the column names    print(column_names)", "url": "3d729ca5bcd13294547ba7baae28b3bc", "gt": "def attrname_to_colname_dict ( cls ) -> Dict [ str , str ] : attr_col = { } # type: Dict[str, str] for attrname , column in gen_columns ( cls ) : attr_col [ attrname ] = column . name return attr_col"}, {"nl_input": "Cleanup any active connections and free all DDEML resources .", "code_input": "import pyodbcimport win32com.client# Cleanup any active connections# This is a simple example, you may need to adjust it based on your specific needstry:    # Replace 'Driver', 'Server', 'Database', 'User', 'Password' with your actual values    conn = pyodbc.connect('Driver={SQL Server};'                          'Server=server_name;'                          'Database=db_name;'                          'User=user;'                          'Password=password;')    cursor = conn.cursor()    cursor.execute(\"SELECT * FROM sys.dm_exec_connections\")    for row in cursor:        if row[3] != '(null)':           ", "url": "61e447348557f0698e3e0553701346ba", "gt": "def __del__ ( self ) : if self . _hConv : DDE . Disconnect ( self . _hConv ) if self . _idInst : DDE . Uninitialize ( self . _idInst )"}, {"nl_input": "Get the value of a local variable somewhere in the call stack .", "code_input": "import tracedef get_local_variable(var_name):    frame = trace.currentframe()    locals_ = frame.f_locals.copy()    if var_name in locals_:        return locals_[var_name]    else:        return None# Usagevar_name = 'a'value = get_local_variable(var_name)print(f'Value of {var_name} in the call stack: {value}')", "url": "7e2c5d8ffcd2cc1804e4430e37ffcd29", "gt": "def getvariable ( name ) : import inspect fr = inspect . currentframe ( ) try : while fr : fr = fr . f_back vars = fr . f_locals if name in vars : return vars [ name ] except : pass return None"}, {"nl_input": "Generator for reading from standard input in nonblocking mode .", "code_input": "import sysdef read_input():    while True:        line = sys.stdin.readline()        if not line:            break        yield line# Usage:for line in read_input():    print(line, end='')", "url": "e7f60e34eae397045ead8f39e3e261c4", "gt": "def _read_stdin ( ) : line = sys . stdin . readline ( ) while line : yield line line = sys . stdin . readline ( )"}, {"nl_input": "Get the number of factor levels for each categorical column .", "code_input": "import pandas as pd# Assuming df is your DataFramedf = pd.DataFrame({    'A': ['a', 'b', 'a', 'b', 'a'],    'B': ['b', 'a', 'b', 'a', 'a'],    'C': ['c', 'b', 'c', 'b', 'a']})# Get the number of unique values in each categorical columnnum_levels = df.nunique()print(num_levels)", "url": "a6c5e82314e0faff8a2fffca5ce8286b", "gt": "def nlevels ( self ) : levels = self . levels ( ) return [ len ( l ) for l in levels ] if levels else 0"}, {"nl_input": "Read a string from a file - like object .", "code_input": "def read_string_from_file(file_name):    with open(file_name, 'r') as file:        return file.readline()# Test the functionprint(read_string_from_file('file.txt'))", "url": "48e0185c07ad636ecb25d70cb2b5dd3d", "gt": "def read_string ( buff , byteorder = 'big' ) : length = read_numeric ( USHORT , buff , byteorder ) return buff . read ( length ) . decode ( 'utf-8' )"}, {"nl_input": "Takes a string and dictionary . replaces all occurrences of i with j", "code_input": "def replace_i_with_j(string, dictionary):    for key, value in dictionary.items():        string = string.replace(key, value)    return string", "url": "248a51a67e1e4f407628e9ccafebb8d6", "gt": "def replace_all ( text , dic ) : for i , j in dic . iteritems ( ) : text = text . replace ( i , j ) return text"}, {"nl_input": "Convert a pandas . Series into an xarray . DataArray .", "code_input": "import pandas as pdimport xarray as xr# Create a pandas Seriess = pd.Series([1, 2, 3, 4, 5])# Convert the Series to a DataArrayda = xr.DataArray(s, dims=['time'])print(da)", "url": "8acad3dcdc0bc175f9a4ddd4dac2d19c", "gt": "def from_series ( cls , series ) : # TODO: add a 'name' parameter name = series . name df = pd . DataFrame ( { name : series } ) ds = Dataset . from_dataframe ( df ) return ds [ name ]"}, {"nl_input": "Compare two strings while protecting against timing attacks", "code_input": "import timedef compare_strings(str1, str2):    start_time = time.time()    result = str1 == str2    end_time = time.time()    print(f\"Time taken to compare strings: {end_time - start_time} seconds\")    return result# Test the functionprint(compare_strings(\"Hello, World!\", \"Hello, World!\"))  # Returns: Trueprint(compare_strings(\"Hello, World!\", \"Hello, World!\"))  # Returns: Trueprint(compare_strings(\"Hello, World!\", \"Goodbye, World!\"))  # Returns: False", "url": "71f181ff4390f325cea684ca6661f4f8", "gt": "def compare ( string1 , string2 ) : if len ( string1 ) != len ( string2 ) : return False result = True for c1 , c2 in izip ( string1 , string2 ) : result &= c1 == c2 return result"}, {"nl_input": "Return True if the given extension is one of the watched extensions", "code_input": "def is_watched_extension(extension):    # Check if the extension is in the list of watched extensions    if extension in watched_extensions:        return True    else:        return False", "url": "741cd035bc31b069280d84e5c84487d1", "gt": "def watched_extension ( extension ) : for ext in hamlpy . VALID_EXTENSIONS : if extension . endswith ( '.' + ext ) : return True return False"}, {"nl_input": "Return a dict with swapped keys and values", "code_input": "def swap_keys_values(d):    return {v: k for k, v in d.items()}# Test the functiond = {'a': 1, 'b': 2, 'c': 3}print(swap_keys_values(d))", "url": "979f3f0fe1af433ff17407bf66d96cad", "gt": "def inverted_dict ( d ) : return dict ( ( force_hashable ( v ) , k ) for ( k , v ) in viewitems ( dict ( d ) ) )"}, {"nl_input": "Extract from the given iterable of lines the list of words .", "code_input": "def extract_words(lines):    words = []    for line in lines:        word_list = line.split()        words.extend(word_list)    return words", "url": "866cf01cf4308a742bd39972cdf57ead", "gt": "def extract_words ( lines ) : for line in lines : for word in re . findall ( r\"\\w+\" , line ) : yield word"}, {"nl_input": "Execute a stored procedure . Returns the first row of the result set or None .", "code_input": "import psycopg2def execute_stored_procedure():    try:        # Establish a connection to the database        connection = psycopg2.connect(            database=\"your_database\",            user=\"your_username\",            password=\"your_password\",            host=\"your_host\",            port=\"your_port\"        )        # Create a cursor object        cursor = connection.cursor()        # Execute the stored procedure        cursor.execute(\"\"\"            BEGIN                PERFORM your_stored_procedure();            EXCEPTION WHEN OTHERS THEN                PERFORM no_data_found();            END;            \"\"\")        # Fetch the first row of the result set        row = cursor.fetchone()        if row is None:            return None        return row    except (Exception, psy", "url": "4bb07195c20355ce50cc040f5e70a269", "gt": "def query_proc_row ( procname , args = ( ) , factory = None ) : for row in query_proc ( procname , args , factory ) : return row return None"}, {"nl_input": "Apply a function in parallel to each element of the input", "code_input": "import concurrent.futuresdef apply_function(x):    # Your function here    return x * 2def apply_to_all(input_list):    with concurrent.futures.ThreadPoolExecutor() as executor:        results = list(executor.map(apply_function, input_list))    return resultsinput_list = [1, 2, 3, 4, 5]print(apply_to_all(input_list))", "url": "1a639907a649d5db69f9b6fdd58119d3", "gt": "def apply ( f , obj , * args , * * kwargs ) : return vectorize ( f ) ( obj , * args , * * kwargs )"}, {"nl_input": "Determine the largest contig for each strain : param contig_lengths_dict : dictionary of strain name : reverse - sorted list of all contig lengths : return : longest_contig_dict : dictionary of strain name : longest contig", "code_input": "def largest_contig(contig_lengths_dict):    longest_contig_dict = {}    for strain, contigs in contig_lengths_dict.items():        longest_contig_dict[strain] = max(contigs)    return longest_contig_dict", "url": "fe624b37a24fae6c2ac1da10c64e2a3a", "gt": "def find_largest_contig ( contig_lengths_dict ) : # Initialise the dictionary longest_contig_dict = dict ( ) for file_name , contig_lengths in contig_lengths_dict . items ( ) : # As the list is sorted in descending order, the largest contig is the first entry in the list longest_contig_dict [ file_name ] = contig_lengths [ 0 ] return longest_contig_dict"}, {"nl_input": "Utility function to remove duplicates from a list : param seq : The sequence ( list ) to deduplicate : return : A list with original duplicates removed", "code_input": "def remove_duplicates(seq):    return list(set(seq))", "url": "695e29d80ca42056024f20cf87ce69a0", "gt": "def dedupe_list ( seq ) : seen = set ( ) return [ x for x in seq if not ( x in seen or seen . add ( x ) ) ]"}, {"nl_input": "save something to a pickle file", "code_input": "import pickle# Data to be saveddata = {    'name': 'John',    'age': 30,    'city': 'New York'}# Open a file in binary mode 'wb'with open('data.pickle', 'wb') as f:    # Use pickle.dump() to write the object to the file    pickle.dump(data, f)", "url": "a0c6bdbe745a48b0c5ff9e6435ea812c", "gt": "def pickle_save ( thing , fname ) : pickle . dump ( thing , open ( fname , \"wb\" ) , pickle . HIGHEST_PROTOCOL ) return thing"}, {"nl_input": "Stop and destroy Bloomberg connection", "code_input": "from bloomberg import BloombergSession# Create a Bloomberg sessionsession = BloombergSession()# Stop the sessionsession.stop()# Destroy the sessionsession.destroy()", "url": "fe9deca4af0d80078524960ad2b74574", "gt": "def delete_connection ( ) : if _CON_SYM_ in globals ( ) : con = globals ( ) . pop ( _CON_SYM_ ) if not getattr ( con , '_session' ) . start ( ) : con . stop ( )"}, {"nl_input": "Determine whether we re in an interactive shell . Sets interactivity off if appropriate . cf http : // stackoverflow . com / questions / 24861351 / how - to - detect - if - python - script - is - being - run - as - a - background - process", "code_input": "import sysdef is_running_as_main():    return __name__ == \"__main__\"def is_running_as_background_process():    return not is_running_as_main()if is_running_as_background_process():    print(\"Running as a background process\")else:    print(\"Running as an interactive shell\")", "url": "76aa03205e7480cb1280364d8181ad15", "gt": "def determine_interactive ( self ) : try : if not sys . stdout . isatty ( ) or os . getpgrp ( ) != os . tcgetpgrp ( sys . stdout . fileno ( ) ) : self . interactive = 0 return False except Exception : self . interactive = 0 return False if self . interactive == 0 : return False return True"}, {"nl_input": "Parses hostname from URL . : param url : URL : return : hostname", "code_input": "import urllib.parsedef parse_hostname(url):    parsed_url = urllib.parse.urlparse(url)    hostname = parsed_url.netloc    return hostname# Test the functionurl = \"http://www.google.com\"print(parse_hostname(url))  # Output: www.google.com", "url": "13343f8f3c5515600e035d8cca7abd84", "gt": "def url_host ( url : str ) -> str : from urllib . parse import urlparse res = urlparse ( url ) return res . netloc . split ( ':' ) [ 0 ] if res . netloc else ''"}, {"nl_input": "Convert napoleon docstring to plain sphinx string .", "code_input": "def convert_docstring_to_sphinx(docstring):    # Remove the triple quotes    docstring = docstring.strip('''')    # Split the docstring into lines    lines = docstring.split('\\n')    # Initialize an empty list to hold the Sphinx strings    sphinx_strings = []    # Iterate over the lines    for line in lines:        # If the line starts with '.. ', it's a docstring line        if line.startswith('.. '):            # Remove the '.. ' and any leading/trailing whitespace            sphinx_string = line[3:].strip()            # Add the Sphinx string to the list            sphinx_strings.append(sphinx_string)    # Join the Sphinx strings with '\\n'    sphinx_string = '\\n'.join(", "url": "40b653bcdc05a7556a73500d75ea2a95", "gt": "def napoleon_to_sphinx ( docstring , * * config_params ) : if \"napoleon_use_param\" not in config_params : config_params [ \"napoleon_use_param\" ] = False if \"napoleon_use_rtype\" not in config_params : config_params [ \"napoleon_use_rtype\" ] = False config = Config ( * * config_params ) return str ( GoogleDocstring ( docstring , config ) )"}, {"nl_input": "Scale the image to uint8", "code_input": "import cv2import numpy as np# Load the imageimage = cv2.imread('image.jpg', cv2.IMREAD_UNCHANGED)# Scale the image to uint8scaled_image = np.array(image, dtype=np.uint8)# Save the scaled imagecv2.imwrite('scaled_image.jpg', scaled_image)", "url": "9b7c3a7b5223587100d77ad757569265", "gt": "def uint8sc ( im ) : im = np . asarray ( im ) immin = im . min ( ) immax = im . max ( ) imrange = immax - immin return cv2 . convertScaleAbs ( im - immin , alpha = 255 / imrange )"}, {"nl_input": "Returns day number of the last day of the month : param t : datetime : return : int", "code_input": "from datetime import datetime, timedeltadef last_day_of_month(t):    next_month = t.replace(day=28) + timedelta(days=4)  # this will never fail    return next_month.day", "url": "820668a155ea53034787f1042a2328c0", "gt": "def get_last_day_of_month ( t : datetime ) -> int : tn = t + timedelta ( days = 32 ) tn = datetime ( year = tn . year , month = tn . month , day = 1 ) tt = tn - timedelta ( hours = 1 ) return tt . day"}, {"nl_input": "Earth orientation as a rotating matrix", "code_input": "import numpy as np# Define the Earth's orientation as a rotating matrixorientation = np.array([[np.cos(np.pi/2), -np.sin(np.pi/2)],                        [np.sin(np.pi/2),  np.cos(np.pi/2)]])# Print the Earth's orientationprint(orientation)", "url": "d5c0c0b2fdf91739d6b7fcf66bbb3579", "gt": "def earth_orientation ( date ) : x_p , y_p , s_prime = np . deg2rad ( _earth_orientation ( date ) ) return rot3 ( - s_prime ) @ rot2 ( x_p ) @ rot1 ( y_p )"}, {"nl_input": "This method validate the parsing and schema return a boolean", "code_input": "import jsonschemafrom jsonschema import validatedef validate_schema(data, schema):    try:        validate(instance=data, schema=schema)        return True    except jsonschema.exceptions.ValidationError:        return False", "url": "2605045c4bab070d37e542733c536732", "gt": "def validate ( self , xml_input ) : parsed_xml = etree . parse ( self . _handle_xml ( xml_input ) ) try : return self . xmlschema . validate ( parsed_xml ) except AttributeError : raise CannotValidate ( 'Set XSD to validate the XML' )"}, {"nl_input": "returns a random element from seq n times . If n is None it continues indefinitly", "code_input": "import randomdef random_element(seq, n=None):    if n is None:        while True:            yield random.choice(seq)    else:        for _ in range(n):            yield random.choice(seq)", "url": "4b7b7a1e82c377437cb8d2c97b053eef", "gt": "def rand_elem ( seq , n = None ) : return map ( random . choice , repeat ( seq , n ) if n is not None else repeat ( seq ) )"}, {"nl_input": "Determines if two rectangles each input as a tuple ( xmin xmax ymin ymax ) intersect .", "code_input": "def rectangles_intersect(rect1, rect2):    # Unpack the rectangles    x1, x2, y1, y2 = rect1    a1, a2, b1, b2 = rect2    # Check if the rectangles intersect    if x1 < x2 < x1 + a1 and x1 < x2 + a2 and y1 < y2 < y1 + b1 and y1 < y2 + b2:        return True    else:        return False", "url": "048248cc31234e7e17b1e3d8f525a955", "gt": "def boxes_intersect ( box1 , box2 ) : xmin1 , xmax1 , ymin1 , ymax1 = box1 xmin2 , xmax2 , ymin2 , ymax2 = box2 if interval_intersection_width ( xmin1 , xmax1 , xmin2 , xmax2 ) and interval_intersection_width ( ymin1 , ymax1 , ymin2 , ymax2 ) : return True else : return False"}, {"nl_input": "Returns the number of characters at the beginning of text that are whitespace .", "code_input": "def count_whitespace(text):    count = 0    for char in text:        if char.isspace():            count += 1    return count# Test the functiontext = \"Hello, World!\"print(count_whitespace(text))  # Output: 2", "url": "a2f407d02b38bb235bf47e7d92789cdf", "gt": "def _count_leading_whitespace ( text ) : idx = 0 for idx , char in enumerate ( text ) : if not char . isspace ( ) : return idx return idx + 1"}, {"nl_input": "Reverse the range", "code_input": "def reverse_range(start, end):    return range(start, end-1, -1)# Test the functionfor i in reverse_range(10, 0):    print(i)", "url": "0bd3c70c60c995acfc00f9af226fdcd9", "gt": "def negate ( self ) : self . from_value , self . to_value = self . to_value , self . from_value self . include_lower , self . include_upper = self . include_upper , self . include_lower"}, {"nl_input": "Returns uptime in seconds or None on Syllable .", "code_input": "import osimport subprocessdef get_uptime():    uptime_seconds = os.popen(\"uptime -s\").read().strip()    if not uptime_seconds:        return None    uptime_seconds = int(uptime_seconds)    days = uptime_seconds // (24*60*60)    uptime_seconds %= (24*60*60)    hours = uptime_seconds // (60*60)    uptime_seconds %= (60*60)    minutes = uptime_seconds // 60    uptime_seconds %= 60    return days*24*60*60 + hours*60*60 + minutes", "url": "a316ccd8b999becea02b2d527a5e8beb", "gt": "def _uptime_syllable ( ) : global __boottime try : __boottime = os . stat ( '/dev/pty/mst/pty0' ) . st_mtime return time . time ( ) - __boottime except ( NameError , OSError ) : return None"}, {"nl_input": "Remove empty utterances from a list of utterances Args : utterances : The list of utterance we are processing", "code_input": "def remove_empty_utterances(utterances):    return [utterance for utterance in utterances if utterance]utterances = ['Hello', '', 'World', '']print(remove_empty_utterances(utterances))", "url": "5ca8d1be36d4955478ff4ef72fbc653a", "gt": "def remove_empty_text ( utterances : List [ Utterance ] ) -> List [ Utterance ] : return [ utter for utter in utterances if utter . text . strip ( ) != \"\" ]"}, {"nl_input": "Method to handle what to do when the stop button is pressed", "code_input": "import tkinter as tkdef on_stop_button_clicked():    # This is where you would put your code to handle the stop button press    print(\"Stop button pressed\")root = tk.Tk()stop_button = tk.Button(root, text=\"Stop\", command=on_stop_button_clicked)stop_button.pack()root.mainloop()", "url": "435335bb0dc17309dd5d006b3f7bc474", "gt": "def stop_button_click_handler ( self ) : self . stop_button . setDisabled ( True ) # Interrupt computations or stop debugging if not self . shellwidget . _reading : self . interrupt_kernel ( ) else : self . shellwidget . write_to_stdin ( 'exit' )"}, {"nl_input": "return True if callback is a vanilla plain jane function", "code_input": "def is_vanilla_plain_jane(callback):    # Check if the callback is a function    if not callable(callback):        return False    # Check if the callback has a single expression    if len(callback().__code__.co_consts) != 1:        return False    # Check if the callback does not use any built-in functions or features    for attr in dir(callback):        if not attr.startswith(\"__\"):            if getattr(callback, attr) != getattr(callback.__code__.co_consts[0], attr):                return False    return True", "url": "0e6cf5fd3544a439b3491daa4a358c98", "gt": "def is_function ( self ) : if self . is_instance ( ) or self . is_class ( ) : return False return isinstance ( self . callback , ( Callable , classmethod ) )"}, {"nl_input": "Same as : meth : random . choice but also supports : class : set type to be passed as sequence .", "code_input": "import randomclass RandomChoice:    def __init__(self, sequence):        self.sequence = sequence    def __call__(self):        return random.choice(self.sequence)", "url": "1ee8eef5f28bf7d5c8091fb2794bc444", "gt": "def random_choice ( sequence ) : return random . choice ( tuple ( sequence ) if isinstance ( sequence , set ) else sequence )"}, {"nl_input": "Detach from all tracked classes and objects . Restore the original constructors and cleanse the tracking lists .", "code_input": "import typesdef clean_tracking(module):    for name, obj in vars(module).items():        if isinstance(obj, types.MethodType):            old_func = obj.__code__.co_name            setattr(module, name, types.MethodType(obj.__func__, module))            delattr(module, old_func)        elif isinstance(obj, types.FunctionType):            old_func = obj.__name__            setattr(module, name, types.FunctionType(obj.__code__, module.__dict__))            delattr(module, old_func)        elif isinstance(obj, type):            old_init = obj.__init__            setattr(module, name, type(obj))            delattr(module, '__init__')            module.__init__ = old_initdef restore_constructors(module):    for name, obj in vars", "url": "c6cd16b1f8c53bd52a696c9afd132194", "gt": "def detach_all ( self ) : self . detach_all_classes ( ) self . objects . clear ( ) self . index . clear ( ) self . _keepalive [ : ] = [ ]"}, {"nl_input": "Returns the progress ratio and percentage .", "code_input": "def calculate_progress_ratio(completed, total):    if total == 0:        return 0    return (completed / total) * 100# Test the functioncompleted = 50total = 100print(f\"Progress Ratio: {calculate_progress_ratio(completed, total)}%\")", "url": "205d2257a363e4a52180c14d82ad05e0", "gt": "def ratio_and_percentage ( current , total , time_remaining ) : return \"{} / {} ({}% completed)\" . format ( current , total , int ( current / total * 100 ) )"}, {"nl_input": "Extract the top level domain from an URL .", "code_input": "def extract_tld(url):    import urllib.parse    return urllib.parse.urlparse(url).netloc.split('.')[-1]# Test the functionprint(extract_tld('https://www.google.com'))", "url": "40adfe081dbdd317187bc7c9fdb5dc37", "gt": "def top_level ( url , fix_protocol = True ) : ext = tld . get_tld ( url , fix_protocol = fix_protocol ) toplevel = '.' . join ( urlparse ( url ) . netloc . split ( '.' ) [ - 2 : ] ) . split ( ext ) [ 0 ] + ext return toplevel"}, {"nl_input": "returns the type of the ( sub ) tree : Root Nucleus or Satellite", "code_input": "def get_tree_type(is_root_nucleus, is_satellite):    if is_root_nucleus and is_satellite:        return \"Root Nucleus or Satellite\"    elif is_root_nucleus:        return \"Root Nucleus\"    elif is_satellite:        return \"Satellite\"    else:        return \"Unknown\"# Test the functionprint(get_tree_type(True, False))  # Output: Root Nucleus or Satelliteprint(get_tree_type(False, True))  # Output: Root Nucleusprint(get_tree_type(True, True))   # Output: Satelliteprint(get_tree_type(False, False)) # Output:", "url": "ce3b5bf4b5f786aed0b49184b37aa877", "gt": "def get_tree_type ( tree ) : tree_type = tree . label ( ) assert tree_type in SUBTREE_TYPES , \"tree_type: {}\" . format ( tree_type ) return tree_type"}, {"nl_input": "Return True if the given DataFrame has a column of the given name ( string ) and there exists at least one non - NaN value in that column ; return False otherwise .", "code_input": "def has_non_nan(df, column_name):    if column_name in df.columns:        return not df[column_name].isnull().all()    else:        return False", "url": "d09752f6ad8ae3d274cbfd233771df7a", "gt": "def is_not_null ( df : DataFrame , col_name : str ) -> bool : if ( isinstance ( df , pd . DataFrame ) and col_name in df . columns and df [ col_name ] . notnull ( ) . any ( ) ) : return True else : return False"}, {"nl_input": "", "code_input": "SELECT * FROM table_name WHERE column_name = 'value';", "url": "6ef3923ed895238369f9017c3075320b", "gt": "def smooth_array ( array , amount = 1 ) : if amount == 0 : return array # we have to store the old values in a temp array to keep the # smoothing from affecting the smoothing new_array = _n . array ( array ) for n in range ( len ( array ) ) : new_array [ n ] = smooth ( array , n , amount ) return new_array"}, {"nl_input": "This turns off stdout buffering so that outputs are immediately materialized and log messages show up before the program exits", "code_input": "import sysdef disable_stdout_buffering():    sys.stdout = sys.__stdout__disable_stdout_buffering()", "url": "f4af9faea801abd2f6afcb51f3fd0f91", "gt": "def disable_stdout_buffering ( ) : stdout_orig = sys . stdout sys . stdout = os . fdopen ( sys . stdout . fileno ( ) , 'w' , 0 ) # NOTE(brandyn): This removes the original stdout return stdout_orig"}, {"nl_input": "Check configuration file type is JSON Return a boolean indicating wheather the file is JSON format or not", "code_input": "import jsondef is_json_file(filename):    with open(filename, 'r') as f:        try:            json.load(f)            return True        except ValueError:            return False", "url": "b6d56ef631a02d9785fd953fd088c09e", "gt": "def is_json_file ( filename , show_warnings = False ) : try : config_dict = load_config ( filename , file_type = \"json\" ) is_json = True except : is_json = False return ( is_json )"}, {"nl_input": "Return a repr () for a list / tuple", "code_input": "def list_tuple_repr(lst):    return repr(lst)# Test the functionlst = [1, 2, 3, 4, 5]print(list_tuple_repr(lst))", "url": "fbd29b6022db8726318c01905aec93b8", "gt": "def _tuple_repr ( data ) : if len ( data ) == 1 : return \"(%s,)\" % rpr ( data [ 0 ] ) else : return \"(%s)\" % \", \" . join ( [ rpr ( x ) for x in data ] )"}, {"nl_input": "Reset analyzer state", "code_input": "class Analyzer:    def __init__(self):        self.state = None    def reset(self):        self.state = Noneanalyzer = Analyzer()analyzer.reset()", "url": "746c5b08e8078cfe8bd345b2f06d87d1", "gt": "def reset ( self ) : self . prevframe = None self . wasmoving = False self . t0 = 0 self . ismoving = False"}, {"nl_input": "Initialize python List with capacity of 10 or user given input . Python List type is a dynamic array so we have to restrict its dynamic nature to make it work like a static array .", "code_input": "def initialize_list(capacity=10):    # Initialize the list with the given capacity    list_ = [0] * capacity    return list_# Test the functionuser_input = int(input(\"Enter the capacity of the list: \"))print(initialize_list(user_input))", "url": "0b503029f353eb61ae98362d02f635c4", "gt": "def __init__ ( self , capacity = 10 ) : super ( ) . __init__ ( ) self . _array = [ None ] * capacity self . _front = 0 self . _rear = 0"}, {"nl_input": "Determine True / False from argument", "code_input": "def determine_true_false(arg):    if arg is not None:        return True    else:        return False", "url": "6794fea99ea3f5a130f9b9f4a2d2e46a", "gt": "def process_bool_arg ( arg ) : if isinstance ( arg , bool ) : return arg elif isinstance ( arg , basestring ) : if arg . lower ( ) in [ \"true\" , \"1\" ] : return True elif arg . lower ( ) in [ \"false\" , \"0\" ] : return False"}, {"nl_input": "DEBUG FUNC modify argv to look like you ran a command", "code_input": "def modify_argv(argv):    # Check if argv is a list    if not isinstance(argv, list):        return \"Error: argv is not a list\"    # Check if argv is empty    if not argv:        return \"Error: argv is empty\"    # Check if the first element is a string    if not isinstance(argv[0], str):        return \"Error: argv[0] is not a string\"    # Check if the second element is a string    if not isinstance(argv[1], str):        return \"Error: argv[1] is not a string\"    # Check if the third element is a string    if not isinstance(argv[2], str):        return \"Error: argv[2] is not a string\"    # Check if the fourth element is a string    if not isinstance(argv[3], str):       ", "url": "4e23368ecbd13cad64e50daa0581d413", "gt": "def aug_sysargv ( cmdstr ) : import shlex argv = shlex . split ( cmdstr ) sys . argv . extend ( argv )"}, {"nl_input": "Like isin but checks whether this expression s value ( s ) are not contained in the passed values . See isin docs for full usage .", "code_input": "import pandas as pddef check_value_not_in(s, values):    return not pd.Series(s).isin(values).any()", "url": "9cede792fe3f616f2e77fbe7d4feee1a", "gt": "def notin ( arg , values ) : op = ops . NotContains ( arg , values ) return op . to_expr ( )"}, {"nl_input": "Not meant to be used directly use : meth : Instaloader . save_session_to_file .", "code_input": "from instaloader import Instaloader, Profile# create an instance of InstaloaderL = Instaloader()# use the login method to log in to your accountL.login('username', 'password')# get the profile of a userprofile = Profile.from_username(L.context, 'username')# save the session to a fileL.save_session_to_file(profile)", "url": "aeedffc3c75a7937797d81d203e6e748", "gt": "def save_session_to_file ( self , sessionfile ) : pickle . dump ( requests . utils . dict_from_cookiejar ( self . _session . cookies ) , sessionfile )"}, {"nl_input": "Transforms the output of parse () into a Text object . The token parameter lists the order of tags in each token in the input string .", "code_input": "import xml.etree.ElementTree as ETdef parse_and_transform(xml_string, token):    # Parse the XML string    root = ET.fromstring(xml_string)    # Transform the output of parse() into a Text object    text = ET.tostring(root, encoding='utf-8', method='text').decode('utf-8')    # Return the transformed text    return text# Test the functionxml_string = '<root><tag1>value1</tag1><tag2>value2</tag2></root>'token = ['tag1', 'tag2']print(parse_and_transform(xml_string, token))", "url": "eea459ea63f8d4aa2b864c391ee02500", "gt": "def tree ( string , token = [ WORD , POS , CHUNK , PNP , REL , ANCHOR , LEMMA ] ) : return Text ( string , token )"}, {"nl_input": "Print dicttree in Json - like format . keys are sorted", "code_input": "import jsondef print_dict_tree_in_json(d, indent=0):    for key, value in sorted(d.items()):        print('\\t' * indent + str(key))        if isinstance(value, dict):            print_dict_tree_in_json(value, indent+1)        else:            print('\\t' * (indent+1) + str(value))# Test the functiondata = {    'name': 'John',    'age': 30,    'children': {        'child1': {            'name': 'Alice',            'age': 5        },        'child2': {            'name': 'Bob',            'age': 7        }    }}print_dict_tree_in_json(data)", "url": "bbb8c24e82437ea03fccdc924a99d399", "gt": "def prettyprint ( d ) : print ( json . dumps ( d , sort_keys = True , indent = 4 , separators = ( \",\" , \": \" ) ) )"}, {"nl_input": "Retrieve the request s User - Agent if available .", "code_input": "from flask import requestdef get_user_agent(request):    if request.headers.get('User-Agent'):        return request.headers.get('User-Agent')    else:        return 'No User-Agent found'# Usageuser_agent = get_user_agent(request)print(user_agent)", "url": "c92742645c96823709ad5b8166cb1c65", "gt": "def _get_user_agent ( self ) : user_agent = request . headers . get ( 'User-Agent' ) if user_agent : user_agent = user_agent . encode ( 'utf-8' ) return user_agent or ''"}, {"nl_input": "Helper for plotting .", "code_input": "import matplotlib.pyplot as pltdef plot_data(data, labels):    \"\"\"    Helper function for plotting data.    Parameters:    data (list): A list of data points.    labels (list): A list of labels for the data points.    \"\"\"    plt.figure(figsize=(10, 6))    for i in range(len(data)):        plt.plot(range(1, len(data[i]) + 1), data[i], label=labels[i])    plt.legend()    plt.show()", "url": "e5568372381b6eebbeb157515f43207b", "gt": "def finish_plot ( ) : plt . legend ( ) plt . grid ( color = '0.7' ) plt . xlabel ( 'x' ) plt . ylabel ( 'y' ) plt . show ( )"}, {"nl_input": "Internal helper to ask if the entity has a value for this Property .", "code_input": "def has_value(entity, property):    if property in entity:        return True    else:        return False", "url": "09121d31a8d0eeeb5cf9dcd83ba98108", "gt": "def _is_initialized ( self , entity ) : return ( not self . _required or ( ( self . _has_value ( entity ) or self . _default is not None ) and self . _get_value ( entity ) is not None ) )"}, {"nl_input": "Create a parser for CLI arguments and options .", "code_input": "import argparse# Create the parserparser = argparse.ArgumentParser(description='Process some integers.')# Add the argumentsparser.add_argument('integers', metavar='N', type=int, nargs='+',                    help='an integer for the accumulator')parser.add_argument('--sum', dest='accumulate', action='store_const',                    const=sum, default=max,                    help='sum the integers (default: find the max)')# Execute parse_args()args = parser.parse_args()# Use the accumulate functionprint(args.accumulate(args.integers))", "url": "df7be6d0213c51a7bb23985c9f9ed388", "gt": "def default_parser ( ) -> argparse . ArgumentParser : parser = argparse . ArgumentParser ( prog = CONSOLE_SCRIPT , formatter_class = argparse . ArgumentDefaultsHelpFormatter , ) build_parser ( parser ) return parser"}, {"nl_input": "Calculate equality between two ( Comparable ) objects .", "code_input": "def compare_objects(obj1, obj2):    if type(obj1) != type(obj2):        return False    if isinstance(obj1, str):        return obj1 == obj2    if isinstance(obj1, int):        return obj1 == obj2    if isinstance(obj1, float):        return obj1 == obj2    if isinstance(obj1, list):        return obj1 == obj2    if isinstance(obj1, tuple):        return obj1 == obj2    if isinstance(obj1, dict):        return obj1 == obj2    if isinstance(obj1, set):        return obj1 == obj2    if isinstance(obj1, object):        return obj1.__eq__(obj2)    return False", "url": "d71243e301d8df8a50df0fa246ce4dc0", "gt": "def equal ( obj1 , obj2 ) : Comparable . log ( obj1 , obj2 , '==' ) equality = obj1 . equality ( obj2 ) Comparable . log ( obj1 , obj2 , '==' , result = equality ) return equality"}, {"nl_input": "Pop the heap value from the heap .", "code_input": "import heapqdef pop_heap(heap):    return heapq.heappop(heap)", "url": "20ee54ac666aa4789a78c32a4103b045", "gt": "def pop ( h ) : n = h . size ( ) - 1 h . swap ( 0 , n ) down ( h , 0 , n ) return h . pop ( )"}, {"nl_input": "Note that this code compresses into a buffer held in memory rather than a disk file . This is done through the use of cStringIO . StringIO () .", "code_input": "import cStringIOdef compress_string(s):    output = cStringIO.StringIO()    last = None    count = 1    for c in s:        if c != last:            if last is not None:                output.write(last)                output.write(str(count))            last = c            count = 1        else:            count += 1    output.write(last)    output.write(str(count))    return output.getvalue()# Test the functionprint(compress_string(\"aabcccccaaa\"))", "url": "5b86e1dfc1552e2ad8e2a95d9bf9feaa", "gt": "def compressBuffer ( buffer ) : # http://jython.xhaus.com/http-compression-in-python-and-jython/ zbuf = cStringIO . StringIO ( ) zfile = gzip . GzipFile ( mode = 'wb' , fileobj = zbuf , compresslevel = 9 ) zfile . write ( buffer ) zfile . close ( ) return zbuf . getvalue ( )"}, {"nl_input": "A helper function that finds the position of the most significant bit in a 1darray of 1s and 0s i . e . the first position where a 1 appears reading left to right .", "code_input": "def most_significant_bit(arr):    for i in range(len(arr)):        if arr[i] == 1:            return i    return -1", "url": "085fc95e9cfffcdc0589e1ae27ff97d1", "gt": "def most_significant_bit ( lst : np . ndarray ) -> int : return np . argwhere ( np . asarray ( lst ) == 1 ) [ 0 ] [ 0 ]"}, {"nl_input": "Pull a querystring value from the request .", "code_input": "from flask import Flask, requestapp = Flask(__name__)@app.route('/')def home():    # Get the query string value    query_string_value = request.args.get('query_string_key', default='default_value')    return f'Query string value: {query_string_value}'if __name__ == '__main__':    app.run(debug=True)", "url": "af8896eebbf01d8cdca7e081f088e946", "gt": "def parse_querystring ( self , req , name , field ) : return core . get_value ( req . args , name , field )"}, {"nl_input": "Takes a list of ( key value ) pairs and turns it into a dict .", "code_input": "def list_to_dict(lst):    return dict(lst)", "url": "bf10521bc0f9003ddbc220d64ecc68eb", "gt": "def list2dict ( lst ) : dic = { } for k , v in lst : dic [ k ] = v return dic"}, {"nl_input": "Deserializes string to date .", "code_input": "from datetime import datetimedef deserialize_string_to_date(date_string):    return datetime.strptime(date_string, '%Y-%m-%d')# Test the functiondate_string = '2022-01-01'print(deserialize_string_to_date(date_string))", "url": "926e7dc9d7779ac0c61e5c1297b2a5e9", "gt": "def deserialize_date ( string ) : try : from dateutil . parser import parse return parse ( string ) . date ( ) except ImportError : return string"}, {"nl_input": "Search tuple array by index and value : param t : tuple array : param i : index of the value in each tuple : param v : value : return : the first tuple in the array with the specific index / value", "code_input": "def search_tuple_array(t, i, v):    for tup in t:        if tup[i] == v:            return tup    return None", "url": "b01054cbea99f2bb7ce3ffbe8771e4ac", "gt": "def tuple_search ( t , i , v ) : for e in t : if e [ i ] == v : return e return None"}, {"nl_input": "Wrap vertical table in a function for TabularOutputFormatter .", "code_input": "class TabularOutputFormatter:    def __init__(self):        self.data = []    def add_row(self, row):        self.data.append(row)    def get_table(self):        # Find the maximum length of each column        max_lengths = [max(len(str(cell)) for cell in row) for row in self.data]        # Format each cell in the table        formatted_rows = [            [str(cell).ljust(length) for cell, length in zip(row, max_lengths)]            for row in self.data        ]        # Create the table string        table = \"\\n\".join([\" | \".join(row) for row in formatted_rows])        return table# Usageformatter = TabularOutputFormatter()formatter.add_row", "url": "3a3657a34dc0ed457876ae075ffdc328", "gt": "def adapter ( data , headers , * * kwargs ) : keys = ( 'sep_title' , 'sep_character' , 'sep_length' ) return vertical_table ( data , headers , * * filter_dict_by_key ( kwargs , keys ) )"}, {"nl_input": "Accepts a NumberGenerator operand an operator and optional arguments to be provided to the operator when calling it on the operand .", "code_input": "class NumberGenerator:    def __init__(self, operation, *args):        self.operation = operation        self.args = args    def __call__(self, num):        return self.operation(num, *self.args)def add(num, *args):    return num + sum(args)def multiply(num, *args):    result = num    for arg in args:        result *= arg    return result# Usagegen = NumberGenerator(add, 1, 2, 3)print(gen(5))  # Output: 10gen = NumberGenerator(multiply, 1, 2, 3)print(gen(5))  # Output: 60", "url": "1ba9155be7b2df6ba7e4674d731803fc", "gt": "def __init__ ( self , operand , operator , * * args ) : # Note that it's currently not possible to set # parameters in the superclass when creating an instance, # because **args is used by this class itself. super ( UnaryOperator , self ) . __init__ ( ) self . operand = operand self . operator = operator self . args = args"}, {"nl_input": "Does a string replace with a list of search and replacements", "code_input": "def replace_string(s, replacements):    for search, replacement in replacements:        s = s.replace(search, replacement)    return s# Test the functions = \"Hello, World!\"replacements = [(\"World\", \"Python\"), (\"Hello\", \"Hi\")]print(replace_string(s, replacements))", "url": "4aa3a520458b5764e46c4f07eac8abf2", "gt": "def multi_replace ( instr , search_list = [ ] , repl_list = None ) : repl_list = [ '' ] * len ( search_list ) if repl_list is None else repl_list for ser , repl in zip ( search_list , repl_list ) : instr = instr . replace ( ser , repl ) return instr"}, {"nl_input": "Set the serial port e . g . : / dev / tty . usbserial - A4001ib8", "code_input": "import serialdef open_serial_port(port):    try:        ser = serial.Serial(port, 9600, timeout=1)        print(\"Serial port opened successfully\")        return ser    except serial.SerialException as e:        print(f\"Error opening serial port: {e}\")        return None# Set the serial portserial_port = \"/dev/tty.usbserial-A4001ib8\"ser = open_serial_port(serial_port)", "url": "4c38388e223a226c56f8c77f1fc60153", "gt": "def do_serial ( self , p ) : try : self . serial . port = p self . serial . open ( ) print 'Opening serial port: %s' % p except Exception , e : print 'Unable to open serial port: %s' % p"}, {"nl_input": "Check features data are not empty", "code_input": "def check_features_data_empty(df):    if df.empty:        return False    else:        return True", "url": "6bb7ab54a926ea8c1cf12f33c4e6128a", "gt": "def contains_empty ( features ) : if not features : return True for feature in features : if feature . shape [ 0 ] == 0 : return True return False"}, {"nl_input": "Convenience function for loading yaml - encoded data from disk .", "code_input": "import yamldef load_yaml(file_path):    with open(file_path, 'r') as file:        data = yaml.safe_load(file)    return data", "url": "ea01144e47e6054ffabeb2fd14ef547a", "gt": "def load_yaml ( filepath ) : with open ( filepath ) as f : txt = f . read ( ) return yaml . load ( txt )"}, {"nl_input": "Show tip", "code_input": "I'm sorry, but your query is unclear. Could you please provide more context or details? Are you asking for a Python code to display a tip, or something else?", "url": "894341368638fcabfe7714433b1b6e50", "gt": "def show_tip ( self , tip = \"\" ) : QToolTip . showText ( self . mapToGlobal ( self . pos ( ) ) , tip , self )"}, {"nl_input": "Converts Matrix3 in an array : param m : Matrix3 : returns : 3x3 array", "code_input": "def matrix3_to_array(m):    return [element for row in m for element in row]", "url": "121d84c275378f7017a360c67108ed82", "gt": "def _matrix3_to_dcm_array ( self , m ) : assert ( isinstance ( m , Matrix3 ) ) return np . array ( [ [ m . a . x , m . a . y , m . a . z ] , [ m . b . x , m . b . y , m . b . z ] , [ m . c . x , m . c . y , m . c . z ] ] )"}, {"nl_input": "count occurences in a list of lists >>> count ( [[ a b ] [ a ]] ) defaultdict ( int { a : 2 b : 1 } )", "code_input": "from collections import defaultdictdef count(lst):    count_dict = defaultdict(int)    for sublist in lst:        for item in sublist:            count_dict[item] += 1    return count_dictprint(count([[ 'a', 'b' ], [ 'a' ]]))", "url": "12da05d47f0365acc6d5050614aa24a8", "gt": "def count ( args ) : counts = defaultdict ( int ) for arg in args : for item in arg : counts [ item ] = counts [ item ] + 1 return counts"}, {"nl_input": "Get the week start date and end date", "code_input": "import datetime# Get the current datenow = datetime.datetime.now()# Get the start date of the current weekstart_of_week = now - datetime.timedelta(days=now.weekday())# Get the end date of the current weekend_of_week = start_of_week + datetime.timedelta(days=6)print(\"Start of week: \", start_of_week.date())print(\"End of week: \", end_of_week.date())", "url": "7186890458a16d68f3ae86fdaed044f3", "gt": "def get_week_start_end_day ( ) : t = date . today ( ) wd = t . weekday ( ) return ( t - timedelta ( wd ) , t + timedelta ( 6 - wd ) )"}, {"nl_input": "execute jobs in processes using N threads", "code_input": "import threadingimport time# Define the jobsdef job(n):    time.sleep(n)  # Simulate a long running job    return n*n# Define the threadsdef thread_job(n, result_queue):    result = job(n)    result_queue.put(result)# Define the main functiondef execute_jobs_in_processes_using_N_threads(N):    # Create a queue to store the results    result_queue = multiprocessing.Queue()    # Create N threads    threads = []    for i in range(N):        t = threading.Thread(target=thread_job, args=(i, result_queue))        threads.append(t)        t.start()    # Wait for all threads to finish    for t in threads:       ", "url": "cf394654dccebe70bab591518bfddb75", "gt": "def parallel ( processes , threads ) : pool = multithread ( threads ) pool . map ( run_process , processes ) pool . close ( ) pool . join ( )"}, {"nl_input": "Print execution time of the function . For quick n dirty profiling .", "code_input": "import timedef your_function():    # Your function code here    passstart_time = time.time()your_function()end_time = time.time()execution_time = end_time - start_timeprint(f\"Execution time: {execution_time} seconds\")", "url": "c3a9f0a7366d3d26740db725d27afbd3", "gt": "def timeit ( func , log , limit ) : def newfunc ( * args , * * kwargs ) : \"\"\"Execute function and print execution time.\"\"\" t = time . time ( ) res = func ( * args , * * kwargs ) duration = time . time ( ) - t if duration > limit : print ( func . __name__ , \"took %0.2f seconds\" % duration , file = log ) print ( args , file = log ) print ( kwargs , file = log ) return res return update_func_meta ( newfunc , func )"}, {"nl_input": "Returns the last number_of_bytes of filename", "code_input": "import osdef get_last_number_of_bytes(filename):    # Get the file size    file_size = os.path.getsize(filename)    # Get the number of bytes    number_of_bytes = file_size    return number_of_bytes# Test the functionprint(get_last_number_of_bytes('your_file.txt'))", "url": "297a85bb493d0c806f74039a8a5906f1", "gt": "def tail ( filename , number_of_bytes ) : with open ( filename , \"rb\" ) as f : if os . stat ( filename ) . st_size > number_of_bytes : f . seek ( - number_of_bytes , 2 ) return f . read ( )"}, {"nl_input": "Update dict with fields from obj . attributes .", "code_input": "class Person:    def __init__(self, name, age):        self.name = name        self.age = age# Create a Person objectperson = Person(\"John\", 30)# Create a dictionary to updateupdate_dict = {}# Update the dictionary with the person's attributesupdate_dict['name'] = person.nameupdate_dict['age'] = person.ageprint(update_dict)", "url": "dca9f4b5be5a5a31bfe15714e1760c23", "gt": "def update_dict ( obj , dict , attributes ) : for attribute in attributes : if hasattr ( obj , attribute ) and getattr ( obj , attribute ) is not None : dict [ attribute ] = getattr ( obj , attribute )"}, {"nl_input": "Checks if a string is an integer . If the string value is an integer return True otherwise return False . Args : string : a string to test .", "code_input": "def is_integer(string):    try:        int(string)        return True    except ValueError:        return False", "url": "aef9f5feefc059d9e764b382b27992ec", "gt": "def is_int ( string ) : try : a = float ( string ) b = int ( a ) except ValueError : return False else : return a == b"}, {"nl_input": "Given a lat & lng what s the string search query .", "code_input": "def get_search_query(lat, lng):    return f\"lat:{lat} lng:{lng}\"", "url": "15b12c412bbefcab9f103d1dc80a8eb5", "gt": "def _query_for_reverse_geocoding ( lat , lng ) : # have to do some stupid f/Decimal/str stuff to (a) ensure we get as much # decimal places as the user already specified and (b) to ensure we don't # get e-5 stuff return \"{0:f},{1:f}\" . format ( Decimal ( str ( lat ) ) , Decimal ( str ( lng ) ) )"}, {"nl_input": "Checks if the string is a palindrome ( https : // en . wikipedia . org / wiki / Palindrome ) .", "code_input": "def is_palindrome(s):    s = s.replace(' ', '')  # remove spaces    s = s.lower()  # convert to lowercase    s = ''.join(c for c in s if c.isalnum())  # remove non-alphanumeric characters    return s == s[::-1]  # compare the string with its reverse# Test the functionprint(is_palindrome('A man a plan a canal Panama'))  # Trueprint(is_palindrome('Not a palindrome'))  # False", "url": "0a8601aa40e8e29e9a34b4bfee20bdb0", "gt": "def is_palindrome ( string , strict = True ) : if is_full_string ( string ) : if strict : return reverse ( string ) == string return is_palindrome ( SPACES_RE . sub ( '' , string ) ) return False"}, {"nl_input": "Sets the title of the console window .", "code_input": "import osimport sysdef set_console_title(title):    \"\"\"    This function sets the title of the console window.    \"\"\"    if sys.platform.startswith('win32'):        import win32console        win32console.SetConsoleTitle(title)    elif sys.platform.startswith('linux') or sys.platform.startswith('darwin'):        os.system('echo {} | xargs osascript -e \\'set the title of the console to\\''.format(title))    else:        print('Unsupported platform.')# Usageset_console_title('My Console Title')", "url": "adb202dabb7da58b5d21780a6344bf64", "gt": "def title ( msg ) : if sys . platform . startswith ( \"win\" ) : ctypes . windll . kernel32 . SetConsoleTitleW ( tounicode ( msg ) )"}, {"nl_input": "expects a _n . array returns the global minimum of ( value - array ) ^2", "code_input": "def global_min(array):    return min(array, key=lambda x: (x - array) ** 2)", "url": "2a95f703627a46eaed3c2acda1993e1a", "gt": "def index_nearest ( value , array ) : a = ( array - value ) ** 2 return index ( a . min ( ) , a )"}, {"nl_input": "Makes the list have unique items only and maintains the order", "code_input": "def unique_order_list(lst):    return list(dict.fromkeys(lst))# Test the functionprint(unique_order_list([1, 2, 2, 3, 4, 4, 4, 5, 6, 6, 7, 8, 8, 8, 9]))", "url": "7656d146fe450dcc47f61df1b20ef0ad", "gt": "def unique ( _list ) : ret = [ ] for item in _list : if item not in ret : ret . append ( item ) return ret"}, {"nl_input": "Print a colored string to the target handle .", "code_input": "from colorama import Fore, init# Initialize coloramainit()# Print a colored stringprint(Fore.GREEN + 'This is a green colored string.')print(Fore.RED + 'This is a red colored string.')print(Fore.YELLOW + 'This is a yellow colored string.')print(Fore.BLUE + 'This is a blue colored string.')print(Fore.MAGENTA + 'This is a magenta colored string.')print(Fore.CYAN + 'This is a cyan colored string.')print(Fore.WHITE + 'This is a white colored string.')", "url": "5e7880a46ffa2a7b19d6212e49eb068b", "gt": "def cprint ( string , fg = None , bg = None , end = '\\n' , target = sys . stdout ) : _color_manager . set_color ( fg , bg ) target . write ( string + end ) target . flush ( ) # Needed for Python 3.x _color_manager . set_defaults ( )"}, {"nl_input": "A block of standard 2d convolutions .", "code_input": "from keras.models import Sequentialfrom keras.layers import Conv2D# Create a Sequential modelmodel = Sequential()# Add a 2D convolution layermodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))# Add a max pooling layermodel.add(Conv2D(64, (3, 3), activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2)))# Add another 2D convolution layermodel.add(Conv2D(128, (3, 3), activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2)))# Add a flatten layermodel.add(Flatten", "url": "07584e5fda69b8f7642955511010ad86", "gt": "def conv_block ( inputs , filters , dilation_rates_and_kernel_sizes , * * kwargs ) : return conv_block_internal ( conv , inputs , filters , dilation_rates_and_kernel_sizes , * * kwargs )"}, {"nl_input": "Removes all non - printable characters from a text string", "code_input": "def remove_non_printable(text):    return ''.join(ch for ch in text if ch.isprintable())text = \"Hello, World!\"print(remove_non_printable(text))", "url": "0f171b4626d9f0ea2a003661289af42f", "gt": "def clean ( ctx , text ) : text = conversions . to_string ( text , ctx ) return '' . join ( [ c for c in text if ord ( c ) >= 32 ] )"}, {"nl_input": "If called after an update the sprite can move back", "code_input": "import pygameclass Sprite:    def __init__(self, x, y):        self.x = x        self.y = y        self.speed = 2    def move(self):        keys = pygame.key.get_pressed()        if keys[pygame.K_LEFT]:            self.x -= self.speed        if keys[pygame.K_RIGHT]:            self.x += self.speed        if keys[pygame.K_UP]:            self.y -= self.speed        if keys[pygame.K_DOWN]:            self.y += self.speed    def update(", "url": "6cbd916f3ecf9c37c1a7d1e9af1ab594", "gt": "def move_back ( self , dt ) : self . _position = self . _old_position self . rect . topleft = self . _position self . feet . midbottom = self . rect . midbottom"}, {"nl_input": "Convert a value to str on Python 3 and unicode on Python 2 .", "code_input": "def convert_to_str(value):    if isinstance(value, str):        return value    elif isinstance(value, unicode):        return str(value)    else:        raise TypeError(\"Value must be a string or unicode\")# Test the functionprint(convert_to_str(\"Hello, World!\"))  # Output: Hello, World!print(convert_to_str(u\"Hello, World!\"))  # Output: Hello, World!", "url": "3d2fbb3f4b88d174fd2f578d0977f650", "gt": "def text ( value , encoding = \"utf-8\" , errors = \"strict\" ) : if isinstance ( value , text_type ) : return value elif isinstance ( value , bytes ) : return text_type ( value , encoding , errors ) else : return text_type ( value )"}, {"nl_input": "Returns the year .", "code_input": "import datetimedef get_current_year():    current_date = datetime.datetime.now()    return current_date.yearprint(get_current_year())", "url": "6c997aefc629ec3ddb36fa1869964c25", "gt": "def year ( date ) : try : fmt = '%m/%d/%Y' return datetime . strptime ( date , fmt ) . timetuple ( ) . tm_year except ValueError : return 0"}, {"nl_input": "Abstraction over executemany method", "code_input": "from sqlalchemy import create_engine, MetaData, Table, select, and_# Create a connection to the databaseengine = create_engine('postgresql://user:password@localhost/dbname')# Reflect the existing database into a new modelmetadata = MetaData()users = Table('users', metadata, autoload_with=engine)# Prepare a list of tuples for the executemany methoddata = [(1, 'user1@example.com'), (2, 'user2@example.com')]# Use executemany to insert the datastmt = users.insert().values(data)# Execute the statementwith engine.connect() as connection:    connection.execute(stmt)", "url": "8c81da54c84a8bf387c8abd981115c12", "gt": "def store_many ( self , sql , values ) : cursor = self . get_cursor ( ) cursor . executemany ( sql , values ) self . conn . commit ( )"}, {"nl_input": "This loads a geojson file into a geojson python dictionary using the json module . Note : to load with a different text encoding use the encoding argument .", "code_input": "import jsondef load_geojson(file_path, encoding='utf-8'):    with open(file_path, 'r', encoding=encoding) as f:        data = json.load(f)    return data", "url": "36327fa884ccc7f85d0e3324f4100445", "gt": "def _loadfilepath ( self , filepath , * * kwargs ) : with open ( filepath , \"r\" ) as f : data = json . load ( f , * * kwargs ) return data"}, {"nl_input": "Retrun True if x is a valid YYYYMMDD date ; otherwise return False .", "code_input": "import redef is_valid_date(x):    pattern = re.compile(r'^\\d{4}\\d{2}\\d{2}$')    if pattern.match(x):        year = int(x[:4])        month = int(x[4:6])        day = int(x[6:8])        if 1 <= year <= 9999 and 1 <= month <= 12 and 1 <= day <= 31:            return True    return False", "url": "8dce08e6c99c22329f7a299e12d01400", "gt": "def valid_date ( x : str ) -> bool : try : if x != dt . datetime . strptime ( x , DATE_FORMAT ) . strftime ( DATE_FORMAT ) : raise ValueError return True except ValueError : return False"}, {"nl_input": "Linear model m is [ slope nugget ]", "code_input": "from sklearn.linear_model import LinearRegression# Assume we have a DataFrame df with features and target variable y# features is a pandas DataFrame with independent variables# y is a pandas Series with target variable# Initialize the Linear Regression modelmodel = LinearRegression()# Fit the model to the datamodel.fit(features, y)# Now the model is trained and can be used to make predictions# For example, to predict the target variable for a new set of featuresnew_features = ...predictions = model.predict(new_features)", "url": "16d9a2609aa57f6f628be3348335008d", "gt": "def linear_variogram_model ( m , d ) : slope = float ( m [ 0 ] ) nugget = float ( m [ 1 ] ) return slope * d + nugget"}, {"nl_input": "Calculate the margin in pixels above the plot area setting border_top .", "code_input": "def calculate_margin(plot_height, border_top):    margin = plot_height - border_top    return marginplot_height = 100border_top = 20margin = calculate_margin(plot_height, border_top)print(f\"The margin in pixels above the plot area is {margin}\")", "url": "ecd265ebe30c4d7de7c6d953ed229c88", "gt": "def calculate_top_margin ( self ) : self . border_top = 5 if self . show_graph_title : self . border_top += self . title_font_size self . border_top += 5 if self . show_graph_subtitle : self . border_top += self . subtitle_font_size"}, {"nl_input": "Test if an executable is available on the system .", "code_input": "import osdef check_executable():    if os.path.isfile('executable'):        print(\"File exists\")    else:        print(\"File does not exist\")check_executable()", "url": "e8c5f4c92b428c3492797c43a4145c2f", "gt": "def executable_exists ( executable ) : for directory in os . getenv ( \"PATH\" ) . split ( \":\" ) : if os . path . exists ( os . path . join ( directory , executable ) ) : return True return False"}, {"nl_input": "Perform re . sub with the patterns in the given dict Args : dict_ : { pattern : repl } source : str", "code_input": "import redef perform_re_sub(dict_, source):    for pattern, repl in dict_.items():        source = re.sub(pattern, repl, source)    return source", "url": "dd91f2aba163192f99af05825ee90b86", "gt": "def substitute ( dict_ , source ) : d_esc = ( re . escape ( k ) for k in dict_ . keys ( ) ) pattern = re . compile ( '|' . join ( d_esc ) ) return pattern . sub ( lambda x : dict_ [ x . group ( ) ] , source )"}, {"nl_input": "Sum reduction op .", "code_input": "def sum_reduction(numbers):    return sum(numbers)# Test the functionnumbers = [1, 2, 3, 4, 5]print(sum_reduction(numbers))  # Output: 15", "url": "3f66655eab2db02115b31c2f24051dad", "gt": "def Sum ( a , axis , keep_dims ) : return np . sum ( a , axis = axis if not isinstance ( axis , np . ndarray ) else tuple ( axis ) , keepdims = keep_dims ) ,"}, {"nl_input": "This method performs an I2C write at a given I2C address : param command : { method : i2c_write_request params : [ I2C_DEVICE_ADDRESS [ DATA_TO_WRITE ]] } : returns : No return message .", "code_input": "import smbusdef i2c_write(command):    i2c_bus = smbus.SMBus(1)  # 1 is the bus number    i2c_address = command['params'][0]    data_to_write = command['params'][1]    i2c_bus.write_i2c_block_data(i2c_address, 0, data_to_write)", "url": "3d672b6acb926c7111962a80dbc3aba9", "gt": "async def i2c_write_request ( self , command ) : device_address = int ( command [ 0 ] ) params = command [ 1 ] params = [ int ( i ) for i in params ] await self . core . i2c_write_request ( device_address , params )"}, {"nl_input": "Reset view to the root of the tree", "code_input": "class Node:    def __init__(self, value):        self.value = value        self.left = None        self.right = Nonedef reset_view(node):    while node.right:        node = node.right    return node# Test the functionroot = Node(1)root.left = Node(2)root.right = Node(3)root.left.left = Node(4)root.left.right = Node(5)reset_view(root)", "url": "92051de4dfff09b7d8998a84f1a1242e", "gt": "def OnRootView ( self , event ) : self . adapter , tree , rows = self . RootNode ( ) self . squareMap . SetModel ( tree , self . adapter ) self . RecordHistory ( ) self . ConfigureViewTypeChoices ( )"}, {"nl_input": "Slow conversion of a recarray into a list of records with python types .", "code_input": "import numpy as np# Create a numpy recarrayrecarray = np.rec.array([(1, 2.2, 'a', True), (2, 3.3, 'b', False)],                       dtype=[('id', 'int32'), ('real', 'float64'), ('char', 'S10'), ('bool', 'bool')])# Convert the recarray to a list of recordsrecords = recarray.view(dtype=[('id', 'int32'), ('real', 'float64'), ('char', 'S10'), ('bool', 'bool')])# Print the recordsfor record in records:    print(record)", "url": "abe0f8e81e16f427a549329c886a3d0c", "gt": "def irecarray_to_py ( a ) : pytypes = [ pyify ( typestr ) for name , typestr in a . dtype . descr ] def convert_record ( r ) : return tuple ( [ converter ( value ) for converter , value in zip ( pytypes , r ) ] ) return ( convert_record ( r ) for r in a )"}, {"nl_input": "Check if a password is valid", "code_input": "import redef is_valid_password(password):    if len(password) < 8:        return False    if not re.search(\"[a-z]\", password):        return False    if not re.search(\"[A-Z]\", password):        return False    if not re.search(\"[0-9]\", password):        return False    if not re.search(\"[_!@#$%^&*()<>?/\\|}{~:]\", password):        return False    return True# Test the functionprint(is_valid_password(\"Password1\"))  # False, password is too shortprint(is_valid_password(\"Password\"))   # False, password does not contain at least one lowercase letterprint(is_valid_password(\"Password@\"))  # True,", "url": "e407d959ae51e2deeb9c5729241dcd19", "gt": "def is_password_valid ( password ) : pattern = re . compile ( r\"^.{4,75}$\" ) return bool ( pattern . match ( password ) )"}, {"nl_input": "arr_out = round_array ( array_in )", "code_input": "def round_array(array_in):    return [round(element) for element in array_in]", "url": "67238b7feb1584fc9527370198fcce31", "gt": "def round_array ( array_in ) : if isinstance ( array_in , ndarray ) : return np . round ( array_in ) . astype ( int ) else : return int ( np . round ( array_in ) )"}]